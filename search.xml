<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[FrontFirst]]></title>
    <url>%2F2020%2F02%2F18%2FFrontFirst%2F</url>
    <content type="text"><![CDATA[HTML基本结构12345678910111213141516&lt;!-- 声明H5页面 --&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;!-- 元数据，utf-8和GBK支持中文 --&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;我的第一个标题&lt;/h1&gt; &lt;p&gt;我的第一个段落。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 标签基本标签html manifest：规定文档的缓存 manifest 的位置。可能的值： 绝对 URL - 指向另一个网站（比如 href=”http://www.example.com/demo.appcache&quot;） 相对 URL - 指向网站内的一个文件（比如 href=”demo.appcache”） xmlns：只有XHTML支持，规定namespace属性。 pbrhrh1h6titlebody 格式标签blockquote：定义摘自另一个源的块引用 cite：URL，规定引用的来源。 q：定义一个短的引用。 cite：URL，规定引用的来源。 address：定义文档作者/所有者的联系信息 cite：定义作品（比如书籍、歌曲、电影、电视节目、绘画、雕塑等等）的标题 bdi：设置一段文本，使其脱离其父元素的文本方向设置 bdo：文字显示方向 dir：规定文字的文本方向 值：ltr，rtl abbr：表示一个缩写词或者首字母缩略词 b：加粗 i：斜体 u：下划线 mark：带星号文本 small：定义小型文本（和旁注）。 sub：下标 sup：上标 del：删除 cite：URL，规定一个解释了文本被删除的原因的文档的 URL datetime：YYYY-MM-DDThh:mm:ssTZD，规定文本删除时间 ins：插入文本 cite：URL，规定一个解释了文本被删除的原因的文档的 URL datetime：YYYY-MM-DDThh:mm:ssTZD，规定文本删除时间 wbr：单词换行分割 s：对那些不正确、不准确或者没有用的文本进行标识。 em：呈现为被强调的文本。 strong：定义重要的文本。 code：定义计算机代码文本。 dfn：一个短语标签，用来定义一个定义项目。 samp：定义样本文本。 kbd：定义键盘文本。它表示文本是从键盘上键入的。它经常用在与计算机相关的文档或手册中。 var：定义变量。可以将此标签与 pre 及 code 标签配合使用。 pre：定义预格式化的文本。被包围在pre标签元素中的文本通常会保留空格和换行符。而文本也会呈现为等宽字体。 ruby：定义 ruby 注释（中文注音或字符）。 rp：在 ruby 注释中使用，以定义不支持 ruby 元素的浏览器所显示的内容。 rt：标签定义字符（中文注音或字符）的解释或发音。 meter：定义度量衡（磁盘空间使用情况等）。类似于进度条，但不是。 form：form_id，规定 meter 元素所属的一个或多个表单。 high：number，规定被界定为高的值的范围。 low：number，规定被界定为低的值的范围。 max：number，规定范围的最大值。 min：number，规定范围的最小值。 optimum：number，规定度量的最优值。 value：number，必需。规定度量的当前值。 progress：定义进度条。 max：需要完成的最大值 value：当前值 time：定义公历的时间（24 小时制）或日期，时间和时区偏移是可选的。 datetime：datetime，规定日期/时间。 pubdate：datetime，指示 time 元素中的日期 / 时间是文档（或最近的前辈 article 元素）的发布日期 表单标签form：表单 accept-charset：character_set，规定服务器可处理的表单数据字符集。 action：URL，规定当提交表单时向何处发送表单数据。 autocomplete：on/off，规定是否启用表单的自动完成功能。 enctype：规定在向服务器发送表单数据之前如何对其进行编码。（适用于 method=”post” 的情况） application/x-www-form-urlencoded multipart/form-data text/plain method：get/post，规定用于发送表单数据的 HTTP 方法。 name：text，规定表单的名称。 novalidate：novalidate，如果使用该属性，则提交表单时不进行验证。 target：规定在何处打开 action URL。 _blank _self _parent _top label：为 input 元素定义标注（标记）。 for：element_id，规定 label 与哪个表单元素绑定。 form：form_id，规定 label 字段所属的一个或多个表单。 input：规定了用户可以在其中输入数据的输入字段。 accept：audio/* video/* image/* MIME_type，规定通过文件上传来提交的文件的类型。 (只针对type=”file”) alt：定义图像输入的替代文本。 (只针对type=”image”) autocomplete：on off，规定输入字段是否应该启用自动完成功能。 autofocus：属性规定当页面加载时元素应该自动获得焦点。 checked：规定在页面加载时应该被预先选定的input元素。 (只针对 type=”checkbox” 或者 type=”radio”) disabled：规定应该禁用的 input 元素。 width：pixels，宽度(只针对type=”image”) height：pixels，高度(只针对type=”image”) name：元素的名称。 max：number / date，元素的最大值。 min：元素的最小值。 maxlenght：允许的最大字符数。 multiple：允许用户输入到元素的多个值。 pattern：用于验证元素的值的正则表达式。 placeholder：描述输入字段预期值的简短的提示信息 。 readonly：输入字段是只读的。 required：规定必需在提交表单之前填写输入字段。 size：规定以字符数计的元素的可见宽度。 src：URL，规定显示为提交按钮的图像的 URL。 (只针对 type=”image”) step：合法数字间隔。 value：值。 list：datalist_id，属性引用 datalist 元素，其中包含 input 元素的预定义选项。 type：元素的类型。 radio：单选按钮 checkbox：复选框 range：用于精确值不重要的输入数字的控件 color：拾色器 file：文件选择字段和 “浏览…” 按钮，供文件上传 hidden：隐藏输入字段 date：date 控件 datetime：date 和 time 控件，基于UTC时区 datetime-local：date 和 time 控件，不带时区 time：输入时间的控件 week：week 和 year 控件 month：month 和 year 控件 text：默认 url：输入 URL 的字段 tel：输入电话号码的字段 email：用于 e-mail 地址的字段 number：用于输入数字的字段 password：密码字段 search：输入搜索字符串的文本字段 submit：提交按钮 button：按钮 reset：重置按钮 image：图像作为提交按钮 form：form_id，规定元素所属的一个或多个表单。 formaction：URL，属性规定当表单提交时处理输入控件的文件的 URL。(只针对 type=”submit” 和 type=”image”) formenctype：属性规定当表单数据提交到服务器时如何编码(只适合 type=”submit” 和 type=”image”)。 application/x-www-form-urlencoded multipart/form-data text/plain formmethod：定义发送表单数据到 action URL 的 HTTP 方法。 (只适合 type=”submit” 和 type=”image”) formnovalidate：覆盖form元素的 novalidate 属性。 formtarget：规定表示提交表单后在哪里显示接收到响应的名称或关键词。(只适合 type=”submit” 和 type=”image”) _blank _self _parent _top framename textarea：一个多行的文本输入控件 autofocus：规定当页面加载时，文本区域自动获得焦点。 cols：文本区域内可见的宽度。 disabled：禁用文本区域。 name placeholder readonly required form：form_id maxlength：最大字符数。 rows：可见的行数。 wrap：当提交表单时，文本区域中的文本应该怎样换行。 button： autofocus：规定当页面加载时，文本区域自动获得焦点。 disabled：禁用文本区域。 form：form_id name value：按钮初试值 type：类型 button reset submit form：form_id，规定元素所属的一个或多个表单。 formaction：URL，属性规定当表单提交时处理输入控件的文件的 URL。(只针对 type=”submit” 和 type=”image”) formenctype：属性规定当表单数据提交到服务器时如何编码(只适合 type=”submit” 和 type=”image”)。 application/x-www-form-urlencoded multipart/form-data text/plain formmethod：定义发送表单数据到 action URL 的 HTTP 方法。 (只适合 type=”submit” 和 type=”image”) formnovalidate：覆盖form元素的 novalidate 属性。 formtarget：规定表示提交表单后在哪里显示接收到响应的名称或关键词。(只适合 type=”submit” 和 type=”image”) _blank _self _parent _top framename select：用来创建下拉列表 autofocus：规定当页面加载时，文本区域自动获得焦点。 disabled：禁用文本区域。 form：form_id name required size：下拉列表中的可见数目 multiple：为true时，可以多选 optgroup：用于把相关的选项组合在一起 disabled：禁用 label：描述 option：定义下拉列表中的一个选项（一个条目）。作为select，optgroup，datalist的元素使用 disabled：禁用文本区域。 selected：被选中 value：送往服务器的值 label使用optgroup时的标注 fieldset：将表单内的相关元素分组。 disabled：禁用文本区域。 name form legend：为fieldset元素定义标题。 datalist：规定了 input 元素可能的选项列表。使用 input 元素的 list 属性来绑定 datalist 元素。 output：作为计算结果输出显示 for：描述计算中使用的元素与计算结果之间的关系。 form name 框架iframe：规定一个内联框架。 height：高度 width：宽度 src：URL，显示的文档 name seamless：规定 iframe 看起来像是父文档中的一部分。 srcdoc：HTML_code，规定页面中的 HTML 内容显示在 iframe 中。 sandbox：定义一系列额外的限制。 “”：启用所有限制条件 allow-forms：允许将内容作为普通来源对待。 allow-same-origin：嵌入的页面的上下文可以导航（加载）内容到顶级的浏览上下文环境 allow-scripts：允许表单提交。 allow-top-navigation：允许脚本执行。 图像img：插入一个图像 alt：代替文本 src：URL，图像链接 width：宽度 height：高度 crossorigin：图像的跨域属性 anonymous use-credentials ismap：将图像规定为服务器端图像映射 usemap：mapname，将图像定义为客户器端图像映射。 map：用于客户端图像映射。图像映射指带有可点击区域的一幅图像。 name：为 image-map 规定的名称。 area：定义图像映射内部的区域 alt：替代文本 coords：规定区域的坐标。 shape：形状 default：全部区域 rect：矩形 circle：圆形 poly：多边形 type：MIME_type，规定目标 URL 的 MIME 类型。 media：规定目标 URL 是为何种媒介/设备优化的。默认：all。 href：URL hreflang：language_code target：打开目标 URL _blank _parent _self _top framename rel：规定当前文档与目标 URL 之间的关系。 alternate：文档的替代版本（比如打印页、翻译或镜像）。 author：链接到文档的作者。 bookmark：用于书签的永久网址 help：链接到帮助文档 license：链接到文档的版权信息。 next：选项中的下一个文档 nofollow：是一个HTML标签的属性值。这个标签的意义是告诉搜索引擎”不要追踪此网页上的链接”或”不要追踪此特定链接。 noreferrer：如果用户点击链接指定浏览不要发送 HTTP referer 头部信息。 prefetch：指定的目标文件应该被缓存 prev：选项中的前一个文档 search：文档链接到搜索工具 tag：当前文档的标签(关键词) canvas：通过脚本（通常是 JavaScript）来绘制图形 height width figcaption：为 figure 元素定义标题。 figure：规定独立的流内容（图像、图表、照片、代码等等）。元素的内容应该与主内容相关，同时元素的位置相对于主内容是独立的。 audio：定义声音，比如音乐或其他音频流。 autoplay：音频在就绪后马上播放 controls：向用户显示音频控件 loop：每当音频结束时重新开始播放 muted：音频输出为静音 src：音频文件的 URL preload：音频是否默认被加载以及如何被加载 auto：页面加载后载入整个音频 metadata：页面加载后只载入元数据 none：页面加载后不载入音频 source：为媒体元素（比如 video 和 audio）定义媒体资源 media：media_query，媒体资源的类型，供浏览器决定是否下载 src：URL type：MIME_type，媒体资源的 MIME 类型 track：为媒体元素（比如 audio and video）规定外部文本轨道，这个元素用于规定字幕文件或其他包含文本的文件，当媒体播放时，这些文件是可见的。 default：该轨道是默认的 label：文本轨道的标签和标题 src：URL srclang：language_code，轨道文本数据的语言 kind：文本轨道的文本类型 captions：该轨道定义将在播放器中显示的简短说明。 chapters：该轨道定义章节，用于导航媒介资源。 descriptions：该轨道定义描述，用于通过音频描述媒介的内容，假如内容不可播放或不可见。 metadata：该轨道定义脚本使用的内容。 subtitles：该轨道定义字幕，用于在视频中显示字幕。 video：义视频，比如电影片段或其他视频流，支持三种视频格式：MP4、WebM、Ogg。 autoplay：音频在就绪后马上播放 controls：向用户显示音频控件 loop：每当音频结束时重新开始播放 muted：音频输出为静音 height：高度 width：宽度 poster：URL，规定视频正在下载时显示的图像，直到用户点击播放按钮。 src：音频文件的 URL preload：音频是否默认被加载以及如何被加载 auto：页面加载后载入整个音频 metadata：页面加载后只载入元数据 none：页面加载后不载入音频 链接nav：定义导航链接的部分，内部使用a标签 main：用于指定文档的主体内容，至多使用一次 a：超链接 href：URL hreflang：language_code media：media_query，规定目标 URL 的媒介类型。 download：filename，指定下载链接 type：MIME_type，规定目标 URL 的 MIME 类型。 target：在何处打开URL _blank _parent _self _top framename rel：规定当前文档与目标 URL 之间的关系。 alternate：文档的替代版本（比如打印页、翻译或镜像）。 author：链接到文档的作者。 bookmark：用于书签的永久网址 help：链接到帮助文档 license：链接到文档的版权信息。 next：选项中的下一个文档 nofollow：是一个HTML标签的属性值。这个标签的意义是告诉搜索引擎”不要追踪此网页上的链接”或”不要追踪此特定链接。 noreferrer：如果用户点击链接指定浏览不要发送 HTTP referer 头部信息。 prefetch：指定的目标文件应该被缓存 prev：选项中的前一个文档 search：文档链接到搜索工具 tag：当前文档的标签(关键词) link：定义文档与外部资源的关系，link 元素是空元素，它仅包含属性，只能存在于 head 部分。 href hreflang media：media_query，规定被链接文档将显示在什么设备上。 sizes：定义了链接属性大小，只对属性 rel=”icon” 起作用。 type：MIME_type rel：规定当前文档与目标 URL 之间的关系。 alternate：文档的替代版本（比如打印页、翻译或镜像）。 author：链接到文档的作者。 bookmark：用于书签的永久网址 help：链接到帮助文档 license：链接到文档的版权信息。 next：选项中的下一个文档 nofollow：是一个HTML标签的属性值。这个标签的意义是告诉搜索引擎”不要追踪此网页上的链接”或”不要追踪此特定链接。 noreferrer：如果用户点击链接指定浏览不要发送 HTTP referer 头部信息。 prefetch：指定的目标文件应该被缓存 prev：选项中的前一个文档 search：文档链接到搜索工具 tag：当前文档的标签(关键词) 元信息head meta 列表表格节程序1234567&lt;img src="planets.gif" width="145" height="126" alt="Planets" usemap="#planetmap"&gt; &lt;map name="planetmap"&gt; &lt;area shape="rect" coords="0,0,82,126" alt="Sun" href="sun.htm"&gt; &lt;area shape="circle" coords="90,58,3" alt="Mercury" href="mercur.htm"&gt; &lt;area shape="circle" coords="124,58,8" alt="Venus" href="venus.htm"&gt;&lt;/map&gt; IE 8- 可能不支持的标签abbrbdimeterrprtrubyoutputcanvasaudiosource]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CompileFirst]]></title>
    <url>%2F2020%2F02%2F16%2FCompileFirst%2F</url>
    <content type="text"><![CDATA[编译原理序章翻译程序编译程序是一种翻译程序，它是高级语言翻译为低级语言的过程，这个低级语言可以在计算机上运行。 编译程序有： 诊断编译程序 优化编译程序 交叉编译程序 可变目标编译程序 解释程序把源语言写的源程序作为输入，但不产生目标程序，而是边编译边执行。 计算思维计算思维就是计算机科学的思维方法： 抽象：提取一般过程； 自动化：将思维物化的过程； 问题分解：做全局性决策，再分解为小问题； 递归：通过解决子问题来解决大问题； 权衡：权衡理论与实际； 保护、冗余、容错、纠错、恢复 启发式推理 不确定情况下的规划、学习、调度 编译的五个过程： 词法分析：输入源程序，识别单词符号，遵循构词规则，利用有限自动机。 语法分析：根据单词符号串分解为语法单位，遵循语法规则，利用上下文无关文法。 中间代码产生：根据语法单位进行初步翻译，依据语义规则，利用属性文法。产生三元式，四元式，树。 优化：对中间代码优化，依据等价变换规则。 目标代码产生：变为目标代码，依据硬件系统结构和机器指令。有三种代码：汇编指令代码，绝对指令代码，可重定位指令代码（需要连接）。 编译程序的框架： 词法分析器 语法分析器 语义分析与中间代码生成器 优化段 目标代码生成器 符号表管理 出错处理：语法错误，语义错误。 相关概念： 遍（pass）：从头到尾扫描一次。一遍可以由若干段组成。 前端与后端：前端是由源语言到中间语言，机器无关；后端是中间语言到目标代码，机器相关。 高级语言编写：由一种高级语言编译另一种高级语言； 移植：把一个机器上的编译程序移植到另一个机器上； 自编译：由自身编译自身。 编译编译工具的工具：LEX，YACC等。 高级语言语法和语义和语用语法：一组规则，用它可以形成和产生合适的程序。 词法规则：单词符号的形成规则。最基本结构。一般包括常数，标识符，基本字，算符，界符等。描述工具是有限自动机。 语法规则：语法单位的形成规则。一般包括表达式，语句，分程序，过程，函数，程序等。描述工具是上下文无关文法。 例如，E为表达式，i为标识符。下面表示一组构成表达式的语法规则：E -&gt; iE -&gt; E + EE -&gt; E * EE -&gt; (E) 语义：一组规则，可以定义一个程序的意义。 描述方法有： 自然语言描述：具有二义性，隐藏错误，不完整性； 形式描述：操作语义，指称语义，代数语义。 程序的层次：程序-&gt;子程序或函数-&gt;语句-&gt;表达式-&gt;运算符 高级语言分类： 强制式语言/过程式语言：一个语句接着一个语句强到对数据的操作。 应用式语言：强调描述函数的构造来实现对数据的处理。 基于规则的语言：检查一定条件，如果满足条件则执行动作。 面向对象语言：通过类，对象，消息与消息响应等处理数据。 程序结构： FORTRAN：由主程序段和辅程序段构成。各段可独立编译。但是无法嵌套和递归。 PASCAL：可以看做是一个过程，允许嵌套和递归。 作用域 最近嵌套原则 JAVA：面向对象。 高级语言一般特性： 数据结构： 属性：区别于其他的对象的属性。 值：允许的取值。 操作：可以进行的操作。 数据类型与操作： 数值： 整形，实数，复数，双精度 加减乘除等 逻辑类型： 布尔型 布尔运算 字符类型： 符号处理 指针类型 标识符：一种语法概念，由字母，数字组成。名字：语义概念，标识程序中的对象。 标识符可以绑定到名字。 名字的意义和属性： 值：单元中的内容。 属性：类型和作用域。 名字的说明方式： 由说明语句来明确规定：如，int score 隐含说明：以某字母开头代表整形，否则为实数型 动态确定 数据结构： 数组：由同一类型的数据组成，分为可变与不可变长度。要给出访问方式，存放方式。 内情向量：登记维数，记录上下限等。 记录：元素构成，可各不相乘。各元素也称为域。要给出访问和存储方式。 字符串：符号处理，公式处理。 表格：记录结构 栈。 线性表。 抽象数据类型：由数据集合和相关操作组成，但操作不给出具体实现。 语句与控制结构： 表达式：操作数和算符组成 形式：前缀，后缀，中缀。 构成规则。 优先次序：左结合，右结合，代数性质（数学）。 语句： 赋值语句： 名字的左值：该名字代表的地址。 名字的右值：该名字代表的值。 控制语句： 无条件转义。 条件语句。 循环语句。 过程调用语句。 返回语句。 分类： 功能 执行性：执行。 说明性：声明。 形式 简单句 复合句 文法基本概念文法：描述语法结构的形式规则。 字母表：是一个有穷字符集，记为Σ。 字符：字母表中的元素。 Σ上的字（字符串）：指由Σ中的字符构成的有穷序列。 空字：字符串中不包含任何字符的序列，记为ε。 Σ*：所有字的全体，包含空字。 Σ*的子集U，V的连接（积）定义为： U V = {αβ | α∈U &amp; β∈V}也就是两个集合的所有字符串进行拼接得到的结果。二者UV和VU运算结果不同，因为顺序不一样。$V^n$：V的n次方。特别的，$V^0$ = { ε }。V：是V的闭包，V = $V^0$ ∪ $V^1$ ∪ $V^2$ ∪ …V+：V的正规闭包，V+ = V V，正规闭包不会引入空字，其他一样。-&gt;：定义，左边是被定义的对象，右边是定义内容。### 上下文无关文法设G是一个四元组：G = (VT, VN, S, P)其中：- VT：终结符集合，非空，是不能分解的单位- VN：非终结符集合，非空，且 VT ∩ VN = ∅，是可以再分解的- 不允许一个符号即是终结符，又是非终结符- S：文法的开始符号，S∈VN- P：产生式的集合，每个产生式形式为： P -&gt; α ，P ∈ VN，α∈(VT∪VN) 例如定义：G = &lt; {i, +, *, (, )}, {E}, E, P&gt;，P由下列产生式组成： E -&gt; i E -&gt; E + E E -&gt; E * E E -&gt; (E) 巴科斯范式(BNF)： 定义符使用::= 表示文法：给出开始符号和产生式 文法化简：G(E): E -&gt; i|E+E|E*E|(E) 推导 * α1 $\Longrightarrow$ αn：经过0步或若干步推出+ α1 $\Longrightarrow$ αn：经过1步或若干步推出 句型：S 星推出 阿尔法 是句型。 句子：仅含有终结符的句型是句子。 语言：文法G产生的句子的全体是语言。 L(G) = { α | S +推出 阿尔法, α∈VT*} 例1：证明(i*i+i)是文法。由E开始推导。例2：给出{a^n b^n | n&gt;=1}的文法。 最左推导：替换最左边的终结符。最右推导：替换最右边的终结符。语法树：推导树。二义性： 推导树不一样：二义文法； 可以由两个文法产生：二义语言。 无二义文法：E -&gt; T | E + TT -&gt; F | T * FF -&gt; (E) | i 形式语言（仅有产生式不一样，终结符，非终结符，文法开始符号都一样）： 0型文法：短语文法，图灵机。产生式：α -&gt; β，α β ∈ (VT ∪ VN)*且至少包含一个非终结符。 1型文法：上下文有关文法，线性界限自动机。产生式：α -&gt; β，α长度&lt;=β长度，仅S-&gt;ε除外。 2型文法：上下文无关文法，非确定下推自动机。产生式：A -&gt; β，A∈VN，β∈(VT ∪ VN)*，利用栈分析。 3型文法：正规文法，有限自动机。产生式：A -&gt; αB或A -&gt; α，α∈VT*，A B∈VN 词法分析词法分析器词法分析器 功能：输入源程序，输出单词符号 单词符号种类： 基本字，关键字 标识符：变量名，函数名等 常数 运算符 界符 输出 二元组（单词种别，单词自身的值） 种别：整数编码 值：标准二进制 词法分析器组成： 预处理：去除空白，跳格，回车、注释；区分符号区，句末符 输入缓冲区：接收文件 扫描器：驱动程序，输出单词符号 扫描缓冲区：接收预处理输出文本 扫描器： 起点指示器 搜索指示器 扫描缓冲区：分为两个半区，半区长度为单词最大长度。 超前搜索：使用限制减轻超前搜索任务 基本字 标识符 字符串 常数 其他 状态转换图状态转换图： 结点：状态 状态之间用箭头表示，上面标记可能出现的输入字符和字符类 一张图只包含有限个状态，一个初态，至少一个终态。 可以用于识别和接收一定的字符串。 终态有两个圈套起来构成，加*表示退掉最后一个字符。 只有终态表示返回。 状态状态实现： 定义： ch：字符变量，存放最近一个读入字符 strToken：字符数组 GetChar：读入下一个字符ch GetBC：跳过空白符 Concat：把ch连入strToken IsLetter，IsDisgital：判断是否为字母，数字 Reserve：检查是否是保留字，并给出编码 Retract：搜索指针退回一个位置 InsertId：将标识符插入符号表，给出符号表指针 InsertConst：将strToken插入常数表，返回常数表指针 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546int code, value;char strToken[MAX_VALUE];GetChar();GetBC();if(IsLetter())&#123; // 分支 1 while(IsLetter() or IsDigit())&#123; Concat(); GetChar(); &#125; Retract(); code = Reserve(); if(code == 0)&#123; value = InsertId(strToken); return ($ID, value); &#125;else&#123; return (code, NULL); &#125;&#125;else if(IsDigit())&#123; // 分支 2 while(IsDigit())&#123; Concat(); GetChar(); &#125; Retract(); value = InsertConst(strToken); return ($INT, value);&#125;else if(ch == '=')&#123; // 分支 3 return ($ASSIGN, NULL);&#125;else if(ch == '+')&#123; return ($PLUS, NULL);&#125;else if(ch == '*')&#123; GetChar(); if(ch == '*')&#123; return ($POWER, NULL); &#125; Retract(); return ($STAR, NULL);&#125;else if(ch == ',')&#123; return ($COMMA, NULL);&#125;else if(ch == '(')&#123; return ($LPAR, NULL);&#125;else if(ch == ')')&#123; return ($RPAR, NULL);&#125;else&#123; ProcError();&#125; 状态图的代码化： curState：现有状态 stateTrans[state][ch]：状态图，state当前状态，ch输入符号，返回下一个状态 12345678910curState = "初态"GetChar();while(stateTrans[curState][ch] is defined)&#123; Concat(); curState = stateTrans[curState][ch]; if (curState is FINAL_STATE)&#123; return strToken; &#125; GetChar();&#125; 自动机正规集，正规式正规集：合法的单词和符号。 正规式：是表示正规集的方法。 正规式 ε和∅都是Σ上的正规式，表示的正规集为{ε}和∅ 对于任意a∈Σ，a是Σ上的正规式，它表示的正规集为{a} 如果e1和e2都是Σ上的正规式，他们的正规集是L(e1)和L(e2)，则 (e1|e2)为正规式，表示的正规集为L(e1)∪L(e2)，并集 (e1·e2)为正规式，表示的正规集为L(e1)L(e2)，连接 (e1)*为正规式，表示的正规集为( L(e1) )*，闭包 等价：如果两个正规式表示的正规集相同，则两个正规式等价。 例：证明：(a*b*)=(a|b)* 对于正规式满足： 或运算交换律 或运算结合律 或运算分配律 连接运算没有交换律 确定有限自动机 DFA确定有限自动机 M = (S, Σ, f, S0, F) S：有穷状态集 Σ：输入字母表（有穷） f：状态转换函数 S x Σ -&gt; S，例如f(s, a)=s’，表示当前状态s，输入字符a，转换为后继状态s’ S0：S0∈S，表示唯一的初态 F：F包含于S，表示终态的集合，可以为空，表示没有终态 设，M = ( {0, 1, 2, 3}, {a, b}, f, 0, {3} ) 其中 f 定义为：f(0, a)=1f(0, b)=2f(1, a)=3f(1, b)=2f(2, a)=1f(2, b)=3f(3, a)=3f(3, b)=3 也可以写成矩阵形式： a b 0 1 2 1 3 2 2 1 3 3 3 3 也可以画为状态转换图。 如果DFA M有m个状态，n个输入字符，则转换图有m个状态节点，每个节点最多有n个箭头射出，每个箭头用Σ上的不同输入字符来标记。 DFA M所识别的字的全体记为L(M) DFA 的程序实现 12345678910curState = "初态"GetChar();while(stateTrans[curState][ch] is defined)&#123; Concat(); curState = stateTrans[curState][ch]; if (curState is FINAL_STATE)&#123; return strToken; &#125; GetChar();&#125; 非确定有限自动机 NFA非确定有限自动机 NFA，M = (S, Σ, f, S0, F) S Σ f：S x Σ* -&gt; 2^S 的部分映射，f(S, α)=S’，α是一个字，S’是一个状态的集合 S0：包含于S，是一个非空的初态集 F 特点： 可以有多个初态 弧上的标记可以是字，甚至是正规式 同一个字可以出现在多个同状态射出的弧上 DFA 是 NFA 的特例 NFA 转换为 DFA如果两个有限自动机M和M’，如果L(M)=L(M’)，则二者等价。判定两个自动机等价的算法是存在的。 假设NFA M = (S, Σ, δ, S0, F)，改造过程如下 引入新增初态X和终态Y，X,Y∉S， 从X到S0中任意一个节点连接一条ε的弧 从F中任意节点连接一条到Y的ε弧。 对于 i —-AB—&gt; j 子图，代换为 i –A–&gt; k –B–&gt; j 子集法 确定化 在状态表中，含有初态的集合视为初态，含有终态的集合视为终态。 DFA 化简假设s和t为M的两个状态，满足如下调剂称为s和t为等价： 从s出发读到某个字α而终止于终态 从t出发也能读到α而终止于终态 把M的状态集划分为不相交的子集，使任何两个不同子集的状态是可区别的，同一子集的任何两个状态是等价的。最后，把每个子集选出一个代表，消去其他状态。 划分步骤： 划分S为终态和非终态 检查每个划分得到的子集是否能进一步划分 是否存在一个字符a，使得Ia不会包含在其他子集中 正规式与有限自动机正规式与有限自动机可以等价。 为 NFA 构造正规式假设NFA M = (S, Σ, δ, S0, F)，改造过程如下 加入X与Y，分别为新的初态和终态。 i –r1–&gt; j –r2–&gt; k 换为 i –r1r2–&gt; k i –r1–&gt; j 和 i –r2–&gt; j 换为 i –r1|r2–&gt; k i –r1–&gt; j –r2–&gt; j –r3–&gt; k 换为 i –r1r2*r3–&gt; k 为正规式构造 NFA]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SecurityFirst]]></title>
    <url>%2F2020%2F02%2F15%2FSecurityFirst%2F</url>
    <content type="text"><![CDATA[计算机取证取证过程所遵循的基本原则： 维护证据完整性； 数字取证可以无限数量拷贝分析； 数字HASH可以验证数据完整性； 维护监管链； 数字证物原始版本写保护，使用拷贝分析； 标准操作步骤； 证物使用按照流程规范，即使事后证明流程有误（免责）； 取证分析全部过程记录文档。 考虑事项： 不要破坏数据现场（实际几乎无法实现，除非是虚拟机）； 寄存器，CPU缓存，IO设备缓存等易失性存储器几乎无法获取； 系统内存是易失存储器中主要的取证对象，不修改无法获取其中数据； 非易失存储器通常使用完整镜像拷贝保存； 正常关机（会被恶意软件察觉）还是直接拔掉电源（会损坏数据）。 证据搜索：数据-&gt;信息&gt;证据。 取证方法： 活取证 抓取文件metadata，创建时间线，历史命令，分析日志，哈希摘要，转存内存信息； 使用未受感染的干净程序取证（包括cd，ls等常用指令，甚至终端程序） U盘/网络存储收集到的证据 死取证 关机后制作硬盘镜像，分析镜像（MBR，GPT，LVM） 内存取证内存中保存着非常重要的信息。一旦内存数据被窃取，该机器上包括系统信息，系统用户，应用软件信息，应用软件缓存（如Web服务中的session等）都会被窃取。 内存取证工具： 内存Dump工具：Dumpit； 内存文件与内存大小接近，RAW格式。 该工具可以一键保存内存转储文件到桌面，也可以存到其他位置。 以Windows为例： 分析工具 volatillity：123456volatillity imageinfo -f xp.raw # 信息文件，关注profilevolatillity hivelist -f xp.raw --profile=WinXPSP3x86 # 数据库文件volatillity -f xp.raw --profile=WinXPSP3x86 hivedump -o 0xe124f8a8 # 按虚内存地址查看注册表内容volatillity -f xp.raw --profile=WinXPSP3x86 printkey -K "SAM\Domains\Account\Users\Names" # 用户账号volatillity -f xp.raw --profile=WinXPSP3x86 printkey -K "SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon" # 最后登录的用户volatillity -f xp.raw --profile=WinXPSP3x86 userassist # 正在运行的程序，运行多少次，最后一次运行时间等 在Kali系统中： 1234567891011121314151617181920212223242526272829303132333435363738# 查看当时的进程volatillity -f xp.raw --profile=Win7SP1x64 pslist# 查看某进程内存，-D 输出到目录，-p 进程PIDvolatillity -f xp.raw --profile=Win7SP1x64 memdump -p 1456 -D mem/# 借助工具查看进程内存hexeditor 1456.dmp # 查看16进制数据strings 1456.dmp # 查看关键字符串，例如调用的恶意程序名strings 1456.dmp | morestrings 1456.dmp | grep password# 查看进程树volatillity -f xp.raw --profile=Win7SP1x64 pstree# 查看注册表蜂巢volatillity -f xp.raw --profile=Win7SP1x64 hivelist# 查看某注册表蜂巢的内容，使用相应的虚内存地址# 例如查看 \SystemRoot\System32\Config\SOFTWARE 蜂巢# 可以看到系统上所有注册安装的软件volatillity -f xp.raw --profile=Win7SP1x64 hivedump -o 0xfffff8a0004a5010 # 查看用户列表volatillity -f xp.raw --profile=Win7SP1x64 printkey -K "SAM\Domains\Account\Users\Names"# 查看最后登录的用户volatillity -f xp.raw --profile=Win7SP1x64 printkey -K "SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon"# 提取用户密码哈希（查询注册表蜂巢）volatillity -f xp.raw --profile=Win7SP1x64 hashdump -y system虚存地址 -s SAM虚存地址# 查看用户行为（似乎可以追溯到几年前）volatillity -f xp.raw --profile=Win7SP1x64 userassist# 查看命令行历史volatillity -f xp.raw --profile=Win7SP1x64 cmdscan# 查看当前网络连接volatillity -f xp.raw --profile=Win7SP1x64 netscanvolatillity -f xp.raw --profile=Win7SP1x64 connscan# IE历史信息volatillity -f xp.raw --profile=Win7SP1x64 iehistory# USN日志记录插件# NTFS特性，用于追踪硬盘内容变化（不记录具体变更内容）# 下载地址 https://raw.githubusercontent.com/tomspencer/volatillity/master/usnparser/usnparser.pyvolatillity -f xp.raw --profile=Win7SP1x64 usnparser --output=csv --output-file=usn.csv# 时间线插件，从多个位置收集大量用户活动，访问的进程，浏览的网页，本地文件等volatillity -f xp.raw --profile=Win7SP1x64 timeliner 内存取证发现恶意软件简易流程：12345678910111213141516# 分析内存镜像volatillity imageinfo -f xp.raw # 查看进程volatillity -f xp.raw --profile=WinXPSP3x86 pstree# 分析网络连接情况volatillity -f xp.raw --profile=WinXPSP3x86 connscan# 分析 利用PID查看SID，可多个volatillity -f xp.raw --profile=WinXPSP3x86 getsids -p 111,222# 分析 DLL 调用情况volatillity -f xp.raw --profile=WinXPSP3x86 dlllist -p 111,222# 查看可能的恶意程序volatillity -f xp.raw --profile=WinXPSP3x86 malfind -D result/# 或volatillity -f xp.raw --profile=WinXPSP3x86 malfind -p 111 -D result/# 对可疑程序利用杀软检查# 或使用网站virustital查看 活取证内存还原文字procdump工具：下载 strings工具：下载 12345# 将当前进程内存情况存入文件procdump -ma notepad.exe notepad.dmp# 将内存文件中的字符串提取出来strings notepad.dmp &gt; notepad.txt# 其他文字处理文件也适用 内存还原图像获取内存： 12# 将当前进程内存情况存入文件procdump -ma mspaint.exe mspaint.dmp 进入Kali： 修改mspaint.dmp文件名为mspaint.data。 安装gimp： 1apt-get install gimp 打开gimp，选择文件类型.raw，打开mspaint.data文件，通过修改偏移与图像类型，一点点调试得到可能有图片的位置，再微调宽度得到图像。 内存还原密码当前的用户密码明文一般存在lsass.exe进程。 1procdump -ma lsass.exe lsass.dmp 打开mimikatz，输入命令：12sekurlsa::minidump lsass.dmpsekurlsa::logonPasswords 即可查看相应内容。 死取证硬盘镜像通过Kali光盘进入取证模式访问计算机，准备生成镜像文件。 打开guymager，使用两种方式查找硬盘。选择硬盘，右键，产生镜像。产生的镜像可以加入Meta信息和哈希值以防止篡改。 查看镜像可以用： DFF工具（digital forensics framework）。 Autopsy（web架构）。 Extundelete：适用ext3，ext4文件系统。 1extundelete [device-file] --restore-file [restore location] iPhone Backup Analyzer：只能用于分析iTunes生成的备份文件。 Foremost：从内测中恢复图片，支持raw，dd，iso，vmem等格式。 1foremost -t jpeg,gif,png,doc -i 7.raw 网络取证可以参考《协议分析》：全流量镜像还原历史。]]></content>
      <categories>
        <category>系统与网络安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cudaFirst]]></title>
    <url>%2F2020%2F02%2F14%2FcudaFirst%2F</url>
    <content type="text"><![CDATA[CUDA参考书： CUDA C Programming Guide CUDA Best Practice Guide 社区：Cuda-zone CUDA 基础CPU 计算现代CPU技术和架构都已经有了性能上的优化：流水线技术，分支预测，超标量，乱序执行，存储器层次，矢量操作，多核处理等。CPU内部包含多个核心，共享三级缓存，访存控制，外设接口等。 并行计算并行计算的编程模型有： 共享存储模型 线程模型 消息传递模型 数据并行模型 GPU 开发环境搭建Windows 安装安装Visual Stuido与CUDA，搞深度学习还可以再安装CUDNN。 Visual Stuido 2019 CUDA cuDNN（需要登录） 安装完成后，打开Visual Studio，新建项目，选择NVIDIA的CUDA项目，选择CUDA Runtime，输入项目名称，确定创建。 CUDA代码以.cu为后缀。创建完成后，软件自动打开kernel.cu文件。这是一个示例文件，可以在此基础上进行开发。按下Ctrl+F5编译运行程序。运行成功表名安装成功。 另外，CUDA会提供CUDA Samples，可以参考使用。 Ubuntu 安装查看系统相关信息：12345678# 查看系统版本cat /etc/issue# 查看显卡lspci | grep -i nvidia# Linux发行版本uname -a# 查看gccgcc -v 下载CUDA。 安装支持库： 1sudo apt-get install freeglut3-dev build-essential libxll-dev libxmu-dev libxi-dev libgll-mesa-glx libglul-mesa-dev 卸载旧的NVIDIA驱动：1sudo nvidia-uninstall 清除相关的库：1sudo apt-get --purge remove nvidia-* 12cd /etc/modprobe.d/vim nvidia-installer-disable-nouveau.conf 文件内容是：12blacklist nouveauoptions nouveau modeset=0 关闭窗口管理器1service lightdm stop 重启电脑。 安装CUDA：1234567sudo sh cuda_*.run # 安装过程配置选项# 是否接受EULA：accept# 是否安装图形加速驱动：yes# 是否安装CUDA：yes# 是否安装CUDA样例代码：yes# CUDA样例代码路径：回车，保持默认 配置环境变量：12vim ~/.bash.rcsource ~/.bash.rc .bash.rc内容为：123export CUDA=/usr/local/cuda-9.2export PATH=$CUDA/bin:$PATHexport LD_LIBRARY_PATH=/usr/lib:$CUDA/lib64:$CUDA/lib:/lib:$LD_LIBRARY_PATH 查看版本信息：1nvcc --version 编译样例代码：12cd NVIDIA*_Samplesmake 运行样例：12cd bin/x86_64/linux/release/./vectorAddDrv GPU 体系架构处理器资源thread：是CUDA中的最小单位，由一个CUDA Core执行。一个CUDA Core包含一个ALU，相应的register和local memory。 warp：以32个thread组成的一个单元。warp中所有线程并行的执行相同的指令。 block：由若干thread组成，以及一块shared memory，硬件上则是由一块SM（Streaming Multiprocessors）执行。需要注意的是，大部分thread只是逻辑上并行，并不是所有的thread可以在物理上同时执行。这就导致，同一个block中的线程可能会有不同步调。 grid：由若干个block构成，除此之外还包含global memory，texture memory等。一个grid由一个设备负责运行。 kernel：是在GPU上执行的一个程序。一个kernel启动一个grid，包含了若干线程块，这个数量可以由用户定义。每一个线程和线程块都有唯一的标识。 存储器资源GPU的存储包括：Register：片内，由thread私有。Shared Memory：片内，属于block拥有。Local Memory：片外，由thread私有。Global Memory：片外，每个grid公用。Constant Memory：片外。Texture Memory：片外，对于主机可写，对于设备只读。Instruction Memory：片外，不可见的。 CPU与GPU有各自的存储空间，二者通过PCI-E总线连接。因此在编程过程中，所有的数据必须预先传输给GPU，产生的结果也得通过总线取回。 编程模型函数在编程中，如果要将变量和函数放入GPU中执行，需要修饰关键字修饰相关的变量和函数。 函数声明： 123456// 执行位置：设备，调用位置：设备__device__ float DeviceFunc()// 执行位置：设备，调用位置：主机__global__ void KernelFunc() // 执行位置：主机，调用位置：主机__host__ float HostFunc() 其中__global__函数必须返回void，__device__与__host__可以同时使用。 由__global__修饰的函数又叫核函数（Kernels），调用核函数需要指定占用的线程数。 123456789101112__global__ void VecAdd(float *A, float *B, float *C)&#123; int i = threadIdx.x; C[i] = A[i] + B[i];&#125;int main()&#123; int A[100], B[100], C[100]; // 1个Block，每个Block含32个Threads VecAdd&lt;&lt;&lt;1, 32&gt;&gt;&gt;(A, B, C);&#125; 在GPU上编写程序与在CPU上编写不同，在GPU上： 不鼓励使用递归，因为其堆栈很小； 不要使用静态变量； 少用malloc，因为众多线程都去malloc，量就会很大； 小心指针，尤其是函数指针。 Block可以使用一维，二维或三维方式访问Thread。 每一个线程都有一个编号：Thread Index。对于一维Block，有：Thread ID == Thread Index；对于二维Block(Dx, Dy)，有：Thread ID of index(x, y) == x + y Dy；对于三维Block(Dx, Dy, Dz)，有：Thread ID of index(x, y, z) == x + y Dy + z Dx Dy 123456789101112131415__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])&#123; // threadIdx -&gt; Thread Index int i = threadIdx.x; int j = threadIdx.y; C[i][j] = A[i][j] + B[i][j];&#125;int main()&#123; int numBlocks = 1; dim3 threadsPerBlock(N, N); // 1个Block，每个Block含 N * N 个Threads MatAdd&lt;&lt;&lt;numBlocks, threadsPerblock&gt;&gt;&gt;(A, B, C);&#125; 注意：最大线程数在不同的显卡中是不一样的，具体要看显卡的相关资料。如图所示，该显卡每个线程块最大含有1024个线程。 Grid可以用一维或多维的方式访问Block。 每一个块都有一个块索引：blockIdx。 123456789101112131415161718__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])&#123; // threadIdx -&gt; Thread Index // blockDim -&gt; Block Dimension // blockIdx -&gt; Block Index int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadIdx.y; if (i &lt; N &amp;&amp; j &lt; N)&#123; C[i][j] = A[i][j] + B[i][j]; &#125;&#125;int main()&#123; dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); MatAdd&lt;&lt;&lt;numBlocks, threadsPerblock&gt;&gt;&gt;(A, B, C);&#125; 例如，设N=32，那么Grid里面有2x2个Block：blockIdx([0, 1], [0, 1])blockDim = 16threadIdx([0, 15], [0, 15])i = [0, 1] * 16 + [0, 15] 访存对于访存，不同的模型可以访问的内存区域也不同，读写属性也不同。 Register：由threads私有且可读可写，速度快，容量小。Shared Memory：由block内的所有threads共享，且可读可写。Local Memory：由threads私有且可读可写。Global Memory：由grid内所有threads共享，可读可写；对于Host而言，也可读可写。Constant Memory：由grid内所有threads共享，只可读；对于Host而言，可读可写。 123456789101112131415161718// 在设备端分配global memorycudaMalloc()// 释放存储空间cudaFree()// 例如：float *Md;int size = Width * Width * sizeof(float);// 这里的Md是设备端的指针，不能在主机端使用cudaMalloc((void**)&amp;Md, size);cudaFree(Md);// 内存传输cudaMemcpy(dest, src, size, direction);// 例如：cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice);cudaMemcpy(P, Pd, size, cudaMemcpyDeviceToHost); 方阵相乘示例 1步骤： 分配内存，拷贝数据； 并行计算； 拷贝结果，释放内存。 12345678910111213141516171819202122232425262728293031323334353637383940414243__global__ void MatrixMulKernel(float *M, float *N, float *P, int Width)&#123; // 获取当前计算的点 P(tx, ty) int tx = threadIdx.x; int ty = threadIdx.y; float Pvalue = 0; // 矩阵相乘 for (int k = 0; k &lt; Width; k++)&#123; // 这里使用一维数组存储二维矩阵 float Mdelement = Md[ty * Md.width + k]; float Ndelement = Nd[k * Nd.width + tx]; Pvalue += Ndelement * Ndelement; &#125; // 写回数据 Pd[ty * Width + tx] = Pvalue;&#125;void MatrixMulOnDevice(float *M, float *N, float *P, int Width)&#123; int size = Width * Width * sizeof(float); // 分配内存，拷贝数据 cudaMalloc(Md, size); cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice); cudaMalloc(Nd, size); cudaMemcpy(Nd, N, size, cudaMemcpyHostToDevice); cudaMalloc(Pd, size); // 并行计算 Width * Width 个线程 dim3 dimBlock(Width, Width); dim3 dimGrid(1, 1); MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, P, Width); // 拷贝结果，释放内存 cudaMemcpy(P, Pd, size, cudaMemcpyDeviceToHost); cudaFree(Md); cudaFree(Nd); cudaFree(Pd);&#125; 但是这样的方式也有局限。首先是访存的频率和计算频率接近 1:1 ，而访存的时间又比较长，因此限制了性能。其次是每个Block限制了最大线程数，我们无法计算大型的矩阵乘法。 数据类型与操作在GPU上支持向量数据类型，主要有： char[1-4] uchar[1-4] short[1-4] ushort[1-4] int[1-4] uint[1-4] long[1-4] ulong[1-4] longlong[1-4] ulonglong[1-4] float[1-4] double1 double2 他们同时适用于host和device，可以通过make_&lt;typename&gt;构造。例如 12int2 i = make_int2(1, 2);float4 f = make_float4(1.0f, 2.0f, 3.0f, 4.0f); 引用可以使用属性.x，.y，.z，.w的方式引用：123int2 i = make_int2(1, 2);int x = i.x;int y = i.y; 此外还有一些常用的数学函数： sqrt rsqrt exp log sin cos tan sincos asin acos atan2 trunc ceil floor 等 如果是在设备端，可以在对应函数前使用双下划线，如：__sin(x)，它的速度更快，但是精度较低。 块内线程同步由于一个块内部的线程并不一定是同步的，有时又需要在特定的地方需要同步操作，因此可以使用同步函数。 1__syncthreads(); 该函数会等待所有线程完成任务再继续执行，但是同步也会造成死锁，编写代码的时候需要注意。 Wrap 线程束与线程调度GPU执行程序时，是按照wrap为单位执行，一个wrap是32个线程。每一个wrap保证同一时刻下面的线程执行相同的指令（SIMD模式）。但是block下并不是只有32个线程，而是更多。因此一个block可以包含多个wrap，且wrap之间的程序不一定是同步的，而且甚至是一个wrap在执行，另外一个wrap在等待调度。 如果一个wrap下不同线程要经过不同的分支，又要保证同一时刻执行相同的指令，就要使用线程屏蔽技术。该技术使这32个线程在遇到分支结构时，例如程序进入分支1，那么就会屏蔽分支2的线程；等分支1执行完毕后，再屏蔽分支1，启动分支2的线程执行。 123456// 如果32个线程中既有满足分支1条件的线程，也有满足分支2条件的线程，那么就会按顺序，先执行分支1，再执行分支2，对于不满足条件的分支给予屏蔽。if (condition)&#123; // 分支 1&#125;else&#123; // 分支 2&#125; 对于一些老式显卡也有特殊情况。尽管调度是按照wrap为单位，但是承接调度的设备是一个SM。如果一个SM只能运行8个线程，那么此次调度的线程就要分4批进入SM，也就是32个线程就不会同步执行。对于现代显卡，一个SM基本上至少可以运行100多个线程。 内存模型延时隐藏技术：在处理器处理程序时，处理的过程是很快的，但是当要进行访存等较慢且需要等待的操作，处理器就会停滞。为了让处理器“忙”起来，我们就会给处理器指派其他可以做的工作，直到前一次访存成功，再回去继续执行。 例如，有N个wrap，每个wrap访存一次需要16个周期，访存后停滞一段时间，每次访存只能有一个wrap。如果我们需要覆盖200个周期，那么需要的wrap数为：200 / 16 = 13个，才能掩藏延时。 另外，决定每个SM能够承载多少线程，是内部资源的分配决定的。 例如，每个SM含有8K个寄存器，当有768个线程需要分配时，每个线程可以分配8K / 768 = 10个寄存器。 再如，如果每个线程如果使用11个寄存器，那么这个SM就承载不了768个线程了。这样就会闲置CPU Core。 Local Memory是每个线程私有，但是存储在GPU的外存中。 Shared Memory是每个Block拥有，存储在GPU片内。它跟寄存器一样，也是决定SM能够承载多少线程的因素。 Global Memory可供全局使用，但是访问延时很长。 Constant Memory也可供全局使用，延时短，带宽高，容量有64KB，但是对于GPU只读。 声明内存可以使用： 声明 存储器 作用域 声明周期 单独的auto变量（非数组） register thread kernel auto变量数组 local thread kernel __shared__ int shared block kernel __device__ int global grid application __constant__ int constant grid application Host可以通过如下的函数访问global和constant变量：1234cudaGetSymbolAddress()cudaGetSymbolSize()cudaMemcpyToSymbol()cudaMemcpyFromSymbol() 另外，constant变量必须在函数外声明。 方阵相乘示例 2上一次的方阵相乘问题： 仅使用一个block，线程数并不多，导致处理问题的规模受限制； 有很多的global memory访存活动，占用较多的时间。 解决方案： 去除问题规模的限制：将结果矩阵拆分成小块，把一个小块布置到一个block中。 减少global memory访存：将需要的数据按小块读入shared memory。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 假设 1 个block最大包含16 * 16 = 256个线程// 且shared memory足够使用#define TILE_WIDTH 16__global__ void MatrixMulKernel(float *M, float *N, float *P, int Width)&#123; // 创建shared memory __shared__ float Mds[TILE_WIDTH][TILE_WIDTH]; __shared__ float Nds[TILE_WIDTH][TILE_WIDTH]; int bx = blockIdx.x; int by = blockIdx.y; int tx = threadIdx.x; int ty = threadIdx.y; // 获取当前计算的点 P(Row, Col) int Row = by * TILE_WIDTH + ty; int Col = bx * TILE_WIDTH + tx; float Pvalue = 0; // 矩阵相乘 for (int k = 0; k &lt; Width/TILE_WIDTH; k++)&#123; // 将数据从global memory读入shared memory Mds[ty][tx] = Md[Row * Width + (k * TILE_WIDTH + tx)] Nds[ty][tx] = Nd[Col + (k * TILE_WIDTH + ty) * Width] __syncthreads(); // 当 Width/TILE_WIDTH 个小块全部读入数据到shared memory后，计算 for (int m = 0; m &lt; TILE_WIDTH; m++)&#123; Pvalue += Mds[ty][m] * Nds[m][tx]; &#125; __syncthreads(); &#125; // 写回数据 Pd[Row * Width + Col] = Pvalue;&#125;void MatrixMulOnDevice(float *M, float *N, float *P, int Width)&#123; int size = Width * Width * sizeof(float); // 分配内存，拷贝数据 cudaMalloc(Md, size); cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice); cudaMalloc(Nd, size); cudaMemcpy(Nd, N, size, cudaMemcpyHostToDevice); cudaMalloc(Pd, size); // 并行计算 Width * Width 个线程 dim3 dimBlock(TILE_WIDTH, TILE_WIDTH); dim3 dimGrid(Width / TILE_WIDTH, Width / TILE_WIDTH); MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, P, TILE_WIDTH); // 拷贝结果，释放内存 cudaMemcpy(P, Pd, size, cudaMemcpyDeviceToHost); cudaFree(Md); cudaFree(Nd); cudaFree(Pd);&#125; 由于我们定义TILE_WIDTH为16，因此global memory的访存次数减少16倍。因为： 假设有两个16 16矩阵M，N相乘，则访存次数为16 16 * 32次，因为计算1个元素需要读取M的一行与N的一列，即32个元素参与计算，访存32次。 当使用shared memory后，我们访问global memory的次数为16 16 2次，也就是将2个16 * 16的矩阵复制到shared memory所需要的次数。 定义TILE_WIDTH大小应当根据： 每个block所能容纳的线程数目； 每个thread可以分配的Local Memory的大小； 每个thread可以分配的Registry的数量； 原子操作原子操作是耗时的，尽量少用原子操作。 12345678910111213// 算术操作atomicAdd()atomicSub()atomicExch()atomicMin()atomicMax()atomicDec()atomicCAS()// 位运算atomicAnd()atomicOr()atomicXor() 调试使用Nsight可以调试： Linux下可以使用命令： 1nsight 打开Eclipse，编写一个CUDA程序。在设备代码中打入断点，Debug时即可在CUDA选项中查看变量的值，左侧可以选择CUDA线程。 提示：如果设备正在用于图像显示，则不能进行调试。 Nsight也可以进行性能分析，可以在Profiler中查看。 如果仅有一块GPU卡，需要先停止桌面环境，仅仅可以使用命令行调试，或从其他系统上通过Nsight远程调试。 程序优化并行规约：例如有8个数据要求和，可以进行两两求和得到4个数据，再经过多次两两求和最终合并为1个数据。 合并的方式有两种，一种是：第一轮：A[0] = A[0] + A[1]，A[2] = A[2] + A[3]，A[4] = A[4] + A[5]，A[6] = A[6] + A[7]；第二轮：A[0] = A[0] + A[2]，A[4] = A[4] + A[6]；第三轮：A[0] = A[0] + A[4]。 12345678910111213141516__global__ void SumOnDevice(float A[])&#123; __shared__ float partialSum[]; // 载入数据到shared memory for (unsigned int k = 0; k &lt; blockDim.x; k++)&#123; partialSum[k] = A[k]; &#125; // 求和 unsigned int t = threadIdx.x; for(unsigned int stride = 1; stride &lt; blockDim.x; stride *= 2)&#123; __syncthreads(); if(t % (2 * stride) == 0)&#123; partialSum[t] += partialSum[t + stride]; &#125; &#125;&#125; 另一种是：第一轮：A[0] = A[0] + A[4]，A[1] = A[1] + A[5]，A[2] = A[2] + A[6]，A[3] = A[3] + A[7]；第二轮：A[0] = A[0] + A[2]，A[1] = A[1] + A[3]；第三轮：A[0] = A[0] + A[1]。 12345678910111213141516__global__ void SumOnDevice(float A[])&#123; __shared__ float partialSum[]; // 载入数据到shared memory for (unsigned int k = 0; k &lt; blockDim.x; k++)&#123; partialSum[k] = A[k]; &#125; // 求和 unsigned int t = threadIdx.x; for(unsigned int stride = blockDim.x / 2; stride &gt; 0; stride /= 2)&#123; __syncthreads(); if(stride &gt; t)&#123; partialSum[t] += partialSum[t + stride]; &#125; &#125;&#125; 这两种方法是有区别的： 前者在进行第二轮运算时，会屏蔽1，3，5，7号线程，第三轮屏蔽1，2，3，5，6，7号线程，而留下1号与4号线程。这样就会使得每个wrap都被占用，但都只利用其中一小部分资源，从而造成资源的浪费。 后者则在第二轮减半后释放后面的4个线程，只留下前面的4个线程，可以减少占用的wrap数，而正在使用的wrap也得到了充分利用。 因此，我们在编写程序时，应当注意利用thread index与wrap的关系，合理的使用wrap。 thread index与wrap的关系，就是wrap 0对应0~31号线程；wrap 1对应32~63号线程……以此类推。 存储优化global memoryCPU与GPU数据传输应当减少传输，组团传输。应注意： 中间数据直接在GPU上分配与释放； GPU上更适合进行重复计算； 如果没有减少数据传输，将CPU的的代码移植到GPU上也可能无法提示性能； 大块传输要优于小块传输； 采用双缓存同时计算与传输。 global memory的延迟很长，可以通过编译指令绕过一级缓存L1，只缓存于二级缓存L2。 1-Xptxas - dlcm=cg 如果wrap的读写请求落到L1 cache line，则只需一次传输。因此应当使用合并原则，即使用连续的32字节块，对应一个wrap去处理，每个线程访问其中的1个字节。 另外，也尽量避免单个线程访问连续的字节块。 shared memoryshared memory的访问速度比global memory速度快上百倍，因此也可以使用shared memory缓存数据，再进行不规则访问。 shared memory被分为了许多banks（多体低位交叉存储），具备如下特性： 连续的32bit（4字节）访存会被分配到连续的banks中； 每个bank每周期可相应一个地址； 多个bank也可以在同一个周期相应多个地址申请； 如果对同一bank进行多次并发访存将导致bank冲突。 在没有bank冲突的情况下，share memory的存取速度几乎和register一样快。对于分析是否含有bank冲突，可以使用profiler分析器查看。 没有冲突的情况： half-wrap内所有线程访问不同banks； half-wrap内所有线程读取同一地址。 产生冲突的情况： half-wrap内多个线程访问同一个bank； 访存串行化。 矩阵转置在矩阵转置中，不论是按行读按列写，还是按列读按行写，总有情况是访存不合并的。但是我们期望读写都是访存合并的。 这个问题可以通过shared memory解决。首先将小块数据由global memory读入shared memory，转置后再以连续化的数据写入global memory。这一过程中需要注意同步线程。 1234567891011121314151617__global__ void transposeCoalesced(float *odata, float *idata, int width, int height)&#123; __shared__ float tile[TILE_DIM][TILE_DIM]; int xIndex = blockIdx.x * TILE_DIM + threadIdx.x; int yIndex = blockIdx.y * TILE_DIM + threadIdx.y; int index_in = xIndex + yIndex * width; xIndex = blockIdx.y * TILE_DIM + threadIdx.x; yIndex = blockIdx.x * TILE_DIM + threadIdx.y; int index_out = xIndex + yIndex * height; // 下面会产生bank冲突 tile[threadIdx.y][threadIdx.x] = idata[index_in]; __syncthreads(); odata[index_out] = tile[threadIdx.x][threadIdx.y];&#125; 由于这种方法会产生bank冲突，因此需要优化：tile[TILE_DIM][TILE_DIM]改为tile[TILE_DIM][TILE_DIM + 1]，也就是多一组用于占位，这样就不会连续多次访问同一个bank。 texure memorytexure memory对于GPU来说是一个只读存储器，其优势在于可以适应无法合并访存的场合，支持数据过滤输出（如：线性，双线性，三线性插值；由专用硬件完成），支持多维寻址，支持整数和小数作为坐标寻址，支持越界寻址。这些特征非常适用于对图像的处理。 SM 资源分割SM上的资源是有限的，主要包含如下几类资源： threads block slots：block 的最大值也受限制 threads slots registers shared memory 资源占用可以使用相应的计算器计算，CUDA GPU Occupancy Calculator。 循环展开有时为了更好的性能，可以将循环展开：12345for(i = 0; i &lt; 16; i++)&#123; Sum += A[i];&#125;// 改为Sum += A[0] + A[2] + A[3] + A[4] + A[5] + A[6] ... 这一过程可以由编译器自动实现：12345#pramga unroll BLOCK_SIZEfor(int i = 0; i &lt; BLOCK_SIZE; i++)&#123; Sum += A[i];&#125;#pramga GPU 架构系列系列命名：Tesla，Fermi，Kepler，Maxwell，Pascal，Volta，Turing，Ampere 系列对比 Fermi 架构Fermi是第一个完整的GPU计算架构，参考配置： 16个SM，每个SM包含32个CUDA Core； 每个CUDA Core包含1个ALU和1个FPU； 6个384位GDDR5 DRAM，支持6GB global memory； 768KB L2 Cache。 Fermi架构的部分显卡：GTX 480；GTX 470，GTX 465，GF 100等。 Kepler 架构显卡：GTX600/600M系列和GTX700/700M系列。 特性： Dynamic Parallelism：允许GPU动态的启动新的Grid。有了这个特性，任何kernel内都可以启动其它的kernel了。 Hyper-Q： 允许多个CPU核同时在单一GPU上启动线程，从而大大提高了GPU的利用率并削减了CPU空闲时间。 GPUDirect：能够使单个计算机内的GPU或位于网络内不同服务器内的GPU直接交换数据，无需进入CPU系统内存。 Grid Management Unit：能够使用先进、灵活的GRID管理和调度控制系统。 Maxwell 架构显卡：GTX800/800M系列与GTX750和GTX750TI。 特性：加入了新的G-SYNC（垂直同步）技术。 Pascal 架构显卡： GeForce系列：GTX1050、1050Ti、1060(3G, 5G, 6G)、1070、1070Ti、1080、1080Ti等； QUADRO系列：GP100、P6000、P5000、P4000、P2000、P1000、P600、P400等； 特斯拉系列：P100、P4、P40； TITAN XP。 CUDA APIAPI：]]></content>
      <categories>
        <category>CUDA 入门</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[STM32]]></title>
    <url>%2F2020%2F02%2F12%2FSTM32%2F</url>
    <content type="text"><![CDATA[Keil 标准库创建STM32F103工程首先创建一个项目目录： STM32F103RBT Project User Device Driver 打开Keil，选择上方的Project-&gt;New uVersion Project，在Project目录下创建工程文件。在打开的面板左侧选择版型，这里选择STM32F1 Series-&gt;STM32F103-&gt;STM32F103C8。 下一步会弹出Manage Run-Time Environment，这里是选择外设的地方。这里选择需要的库： CMSIS CORE Device DMA GPIO Startup StdPeriph Drivers ADC Framework RCC DMA EXIT GPIO DGBMCU TIM SPI USART 创建完成后打开Options for Target，在C/C++选项卡的Define项填写：1STM32F10X_MD,USE_STDPERIPH_DRIVER 前一项表示板子的类型，由与是C8板，因此是MD型；如果是Z系列或V系列，则为HD型。后一项表示使用标准库。 在Include Paths中填写，这里是.h文件的搜索路径1..\Device;..\Driver;..\User;..\Project;..\UCOS;..\UCOS\core;..\UCOS\cpu;..\UCOS\lib 在Debug选项卡右侧的Use中选择J-LINK/J-TRACE Cortex。完成后点击Settings，选择Flash Download选项卡，删除Programming Algorithm中的项目，点击ADD，添加第一项。另外，在Debug选项卡可以选择Port，可以是Jtag或SW，可根据下载器选择。完成后确定返回。 这里开始创建一个main.c和一个main.h文件。 123456789101112131415161718// main.c#include "main.h"int main(void)&#123; GPIO_InitTypeDef gpio; RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOA, ENABLE); gpio.GPIO_Mode = GPIO_Mode_Out_PP; gpio.GPIO_Speed = GPIO_Speed_50MHz; gpio.GPIO_Pin = GPIO_Pin_2; GPIO_Init(GPIOA, &amp;gpio); while(1) &#123; GPIO_ResetBits(GPIOA, GPIO_Pin_2); &#125;&#125; 1234567// main.h#ifndef MAIN_H#define MAIN_H#include "stm32f10x.h"#endif 之后打开Manage Project Items按钮，编辑项目目录。这可以按照项目目录创建Groups，并在对应的Files中添加相应.c文件。 最后编译下载查看效果。 uC/OS-III 参考uC/OS-III 代码架构主要有：配置文件，应用程序，系统代码，库文件，CPU相关代码，BSP板级支持包等。 配置文件：cpu_cfg.h，lib_cfg.h，os_cfg.h，os_cfg_app.h 应用程序：app.c，app.h 库文件：lib_* 系统代码：os_cfg_app.c，os_type.h，os_core.c，os_dgb.c，os_flag.c，os_int.c，os_mem.c，os_msg.c，os_mutex.c，os_pend_multi.c，os_g.c，os_sem.c，os_stat.c，os_tick.c，os_time.c，os_tmr.c，os_var.c，os.h CPU相关代码：os_cpu.h，os_cpu_a.asm，os_cpu_c.c，cpu_def.h，cpu_c.c，cpu_a.asm，cpu_core.c，cpu_core.h BSP板级支持包：bsp.h，bsp.c uC/OS III 代码移植首先去官方代码下载，下载uC/OS III 代码，对于F103可以下载STM32F107的代码，选择Keil版，uC/OS III。 下载完成后，代码目录如下： Software EvalBoards Micrium uC-Eval-STM32F107 BSP uCOS-III uC-CPU ARM-Cortex-M3 GNU IAR RealView uC-LIB Port ARM-Cortex-M3 GNU IAR RealView uCOS-III Source Ports ARM-Cortex-M3 GNU IAR RealView 首先在我们的项目文件夹下建立目录： STM32F103RBT Project User Device Driver Ucos lib core cpu 之后： 将代码目录\uC-CPU以及\uC-CPU\ARM-Cortex-M3\RealView下的文件（不包括文件夹）全部拷贝到我们的项目目录\STM32F103RBT\Ucos\cpu下； 将代码目录\uC-LIB以及\uC-LIB\Ports\ARM-Cortex-M3\RealView下的文件（不包括文件夹）全部拷贝到我们的项目目录\STM32F103RBT\Ucos\lib下； 将代码目录\uCOS-III\Source以及\uCOS-III\Ports\ARM-Cortex-M3\Generic\RealView下的文件（不包括文件夹）全部拷贝到我们的项目目录\STM32F103RBT\Ucos\core下； 将代码目录\EvalBoards\Micrium\uC-Eval-STM32F107\uCOS-III下的文件（不包括文件夹与stm32f10x_conf.h）全部拷贝到我们的项目目录\STM32F103RBT\User下。 将代码目录\EvalBoards\Micrium\uC-Eval-STM32F107\BSP下的bsp.c与bsp.h拷贝到我们的项目目录\STM32F103RBT\User下。 打开Manage Project Items按钮，编辑项目目录。这可以按照项目目录创建Groups，并在对应的Files中添加相应.c文件和汇编（.asm，.a，.s）文件。 修改startup_stm32f10x_md.s： PendSV_Handler改为OS_CPU_PendSVHandler，共3处； SysTick_Handler改为OS_CPU_SysTickHandler，共3处； 修改includes.h： #include &lt;stm32f10x_lib.h&gt;改为#include &quot;stm32f10x.h&quot;； 修改cpu_cfg.h： CPU_CFG_TS_32_EN后面的选项为DEF_ENABLED； CPU_CFG_INT_DIS_MEAS_EN上面的#if 0为#if 1； 修改app_cfg.h： APP_CFG_SERIAL_EN后面的选项为DEF_DISABLED； 修改lib_cfg.h: LIB_MEM_CFG_HEAP_SIZE后面的大小改为2u * 1024u 修改app.c： BSP_IntDisAll();去掉； 修改AppTaskStart函数的内容； 删除下面的部分； 1234567APP_TRACE_INFO(("Creating Application Tasks...\n\r"));AppTaskCreate(); /* Create Application Tasks */APP_TRACE_INFO(("Creating Application Events...\n\r"));AppObjCreate(); /* Create Application Objects */BSP_LED_Off(0); 修改while中的部分；12345678910while (DEF_TRUE) &#123; Led_on(); OSTimeDlyHMSM(0, 0, 0, 100, OS_OPT_TIME_HMSM_STRICT, &amp;err); Led_off(); OSTimeDlyHMSM(0, 0, 0, 100, OS_OPT_TIME_HMSM_STRICT, &amp;err);&#125; 修改bsp.h内容为：1234567891011121314151617181920212223242526272829#ifndef BSP_PRESENT#define BSP_PRESENT#ifdef BSP_MODULE#define BSP_EXT#else#define BSP_EXT extern#endif#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;#include &lt;cpu.h&gt;#include &lt;cpu_core.h&gt;#include &lt;lib_ascii.h&gt;#include &lt;lib_def.h&gt;#include &lt;lib_mem.h&gt;#include &lt;lib_str.h&gt;#include &lt;stm32f10x.h&gt;#include &lt;app_cfg.h&gt;void BSP_Init (void);CPU_INT32U BSP_CPU_ClkFreq (void);void Led_on(void);void Led_off(void);#endif 修改bsp.c文件为：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#define BSP_MODULE#include &lt;bsp.h&gt;CPU_INT32U BSP_CPU_ClkFreq_MHz;#define DWT_CR *(CPU_REG32 *)0xE0001000#define DWT_CYCCNT *(CPU_REG32 *)0xE0001004#define DEM_CR *(CPU_REG32 *)0xE000EDFC#define DBGMCU_CR *(CPU_REG32 *)0xE0042004#define DBGMCU_CR_TRACE_IOEN_MASK 0x10#define DBGMCU_CR_TRACE_MODE_ASYNC 0x00#define DBGMCU_CR_TRACE_MODE_SYNC_01 0x40#define DBGMCU_CR_TRACE_MODE_SYNC_02 0x80#define DBGMCU_CR_TRACE_MODE_SYNC_04 0xC0#define DBGMCU_CR_TRACE_MODE_MASK 0xC0#define DEM_CR_TRCENA (1 &lt;&lt; 24)#define DWT_CR_CYCCNTENA (1 &lt;&lt; 0)void BSP_Init(void)&#123; GPIO_InitTypeDef gpio; RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOA,ENABLE); gpio.GPIO_Mode = GPIO_Mode_Out_PP; gpio.GPIO_Speed = GPIO_Speed_50MHz; gpio.GPIO_Pin = GPIO_Pin_2; GPIO_Init(GPIOA, &amp;gpio);&#125;void Led_on(void)&#123; GPIO_ResetBits(GPIOA, GPIO_Pin_2);&#125;void Led_off(void)&#123; GPIO_SetBits(GPIOA, GPIO_Pin_2);&#125;CPU_INT32U BSP_CPU_ClkFreq(void)&#123; RCC_ClocksTypeDef rcc_clocks; RCC_GetClocksFreq(&amp;rcc_clocks); return ((CPU_INT32U)rcc_clocks.HCLK_Frequency);&#125;#if (CPU_CFG_TS_TMR_EN == DEF_ENABLED)void CPU_TS_TmrInit (void)&#123; CPU_INT32U cpu_clk_freq_hz; DEM_CR |= (CPU_INT32U)DEM_CR_TRCENA; /* Enable Cortex-M3's DWT CYCCNT reg. */ DWT_CYCCNT = (CPU_INT32U)0u; DWT_CR |= (CPU_INT32U)DWT_CR_CYCCNTENA; cpu_clk_freq_hz = BSP_CPU_ClkFreq(); CPU_TS_TmrFreqSet(cpu_clk_freq_hz);&#125;#endif#if (CPU_CFG_TS_TMR_EN == DEF_ENABLED)CPU_TS_TMR CPU_TS_TmrRd (void)&#123; return ((CPU_TS_TMR)DWT_CYCCNT);&#125;#endif 接下来的开发将主要在app.c和bsp.c中了。 系统综述在ucos-iii中，可以创建无数多个任务。另外，在初始化的时候，系统还会窗空闲任务OS_IdleTask()和时基任务OS_TickTask()，以及三个可选任务：软件定时器任务OS_TmrTaks()，中断延迟提交任务OS_IntQTask()和统计任务OS_StatTask()。 任务具有五种状态： 休眠：声明但尚未创建，不受系统管理。 就绪：等待CPU使用权。 运行：正在运行。 等待：等待IO或某事件。 中断服务：进入中断函数。 ucos-iii中对任务定义了9种状态： OS_TASK_STATE_RDY：就绪状态； OS_TASK_STATE_DLY：延时状态； OS_TASK_STATE_DEL：删除状态； OS_TASK_STATE_SUSPENDED：挂起状态； OS_TASK_STATE_PEND：无限期等待，直到某事件发生； OS_TASK_STATE_PEND_TIMEOUT：有限期等待，超时则继续执行； OS_TASK_STATE_DLY_SUSPENDED：在延时中被挂起； OS_TASK_STATE_PEND_SUSPENDED：无限等待中被挂起； OS_TASK_STATE_PEND_TIMEOUT_SUSPENDED：优先等待中被挂起 另外，系统还提供软件定时器，多值信号量，互斥信号量，消息队列，事件标志组，任务信号量，消息队列，内存管理（分区）等功能。 中断管理关闭中断（进入临界区）：123void OS_CRITICAL_ENTER(void);// 或void OS_CRITICAL_ENTER_CPU_EXIT(void); 开启中断（退出临界区）：123void OS_CRITICAL_EXIT(void);// 或void OS_CRITICAL_EXIT_NO_SCHED(void); 在进入中断服务函数后，应当调用函数将中断嵌套计数器加1，并在退出时减1。1234// 中断嵌套计数 + 1void OSIntEnter(void);// 中断嵌套计数 - 1void OSIntExit (void); 时钟节拍时钟节拍就是系统以固定的频率产生中断（时基中断），并在中断中处理与时间相关的事件，推动所有任务向前运行。时钟节拍需要依赖于硬件定时器，在STM32裸机程序中经常使用的SysTick时钟是MCU的内核定时器，通常都使用该定时器产生操作系统的时钟节拍。 用户需要先在os_cfg_app.h中设定时钟节拍的频率OS_CFG_TICK_RATE_HZ，该频率越高，操作系统检测事件就越频繁，可以增强任务的实时性，但太频繁也会增加操作系统内核的负担加重，所以用户需要权衡该频率的设置。一般采用1ms的设置，也就是1000Hz。 定时器的初始化是在AppTaskStart()函数中。在初始化过程中，会开启SysTick中断，同时在SysTick中断中会给OS_TickTask()任务发送信号量。OS_TickTask()任务收到信号量后就会进入就绪状态，准备运行。 在实际运行中，由软件产生的定时器效果精度较硬件定时器低，误差约在1%以内，一般该精度足够用了。 时间管理时间管理的相关函数有： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/*延时执行当前任务，延时结束后再回来执行当前任务。选项：OS_OPT_TIME_DLY Dly 为相对时间，就是从现在起延时多长时间， 到时钟节拍总计数OSTickCtr = OSTickCtr 当前+ dly 时延时结束。OS_OPT_TIME_TIMEOUT 跟OS_OPT_TIME_DLY 情况一样。OS_OPT_TIME_MATCH Dly 为绝对时间，就是从系统开始运行（调用OSStart()）时到节拍总计数OSTickCtr = dly 时延时结束。OS_OPT_TIME_PERIODIC 周期性延时，跟OS_OPT_TIME_DLY差不多。如果是长时间延时，该选项更精准一些。错误：OS_ERR_NONE 没错误。OS_ERR_OPT_INVALID 选项不可用。OS_ERR_SCHED_LOCKED 调度器被锁OS_ERR_TIME_DLY_ISR 在中断中使用该函数。OS_ERR_TIME_ZERO_DLY Dly 为0。*/void OSTimeDly( OS_TICK dly, // 延时的节拍数 OS_OPT opt, OS_ERR *p_err );/*延时执行当前任务，延时结束后再回来执行当前任务。开关：os_cfg.h\OS_CFG_TIME_DLY_HMSM_EN选项：OS_OPT_TIME_DLY Dly 为相对时间，就是从现在起延时多长时间， 到时钟节拍总计数OSTickCtr = OSTickCtr 当前+ dly 时延时结束。OS_OPT_TIME_TIMEOUT 跟OS_OPT_TIME_DLY 情况一样。OS_OPT_TIME_MATCH Dly 为绝对时间，就是从系统开始运行（调用OSStart()）时到节拍总计数OSTickCtr = dly 时延时结束。OS_OPT_TIME_PERIODIC 周期性延时，跟OS_OPT_TIME_DLY差不多。如果是长时间延时，该选项更精准一些。OS_OPT_TIME_HMSM_STRICT 延时时间取值比较严格。 hours (0...99) minutes (0...59) seconds (0...59) milliseconds (0...999)OS_OPT_TIME_HMSM_NON_STRICT 延时时间取值比较宽松。 hours (0...999) minutes (0...9999) seconds (0...65535) milliseconds (0...4294967295)错误：OS_ERR_NONE 没错误。OS_ERR_OPT_INVALID 选项不可用。OS_ERR_SCHED_LOCKED 调度器被锁OS_ERR_TIME_DLY_ISR 在中断中使用该函数。OS_ERR_TIME_INVALID_HOURS 小时数不可用。OS_ERR_TIME_INVALID_MINUTES 分钟数不可用。OS_ERR_TIME_INVALID_SECONDS 秒数不可用。OS_ERR_TIME_INVALID_MILLISECONDS 毫秒数不可用。OS_ERR_TIME_ZERO_DLY 延时时间为0。*/void OSTimeDlyHMSM ( CPU_INT16U hours, // 小时数 CPU_INT16U minutes, // 分钟数 CPU_INT16U seconds, // 秒数 CPU_INT32U milli, // 毫秒数 OS_OPT opt, OS_ERR *p_err);/*结束其他任务的延时。错误：OS_ERR_NONE 没错误。OS_ERR_STATE_INVALID 任务状态非法。OS_ERR_TIME_DLY_RESUME_ISR 在中断中结束延时。OS_ERR_ TASK_NOT_DLY 任务不在延时。OS_ERR_TASK_SUSPENDED 任务被挂起。开关：os_cfg.h\OS_CFG_TIME_DLY_RESUME_EN该函数的p_tcb 参数不可以是当前任务。不可以用该函数结束等待事件。*/void OSTimeDlyResume ( OS_TCB *p_tcb, // 任务的任务控制块指针 OS_ERR *p_err);/*获取当前的时钟节拍计数值。错误：OS_ERR_NONE 没错误。返回：当前的时钟节拍计数值。*/OS_TICK OSTimeGet ( OS_ERR *p_err);/*设置当前的时钟节拍计数值。错误：OS_ERR_NONE 没错误。该函数谨慎使用。*/void OSTimeSet ( OS_TICK ticks, // 时钟节拍数 OS_ERR *p_err); 软件定时器软件定时器启动之后是由软件定时器任务OS_TmrTask()统一管理，在创建软件定时器之前必须先使能软件定时器和配置软件定时器的相关参数。 软件定时器开启位置：os_cfg.h\OS_CFG_TMR_EN软件定时器配置位置：os_cpu_app.h\OS_CFG_TMR_TASK_PRIO 相应的API有：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/*创建一个软件定时器。选项：OS_OPT_TMR_ONE_SHOT 周期性定时。OS_OPT_TMR_PERIODIC 一次性定时。错误：OS_ERR_NONE 没错误OS_ERR_ILLEGAL_CREATE_RUN_TIME 非法创建内核对象OS_ERR_OBJ_CREATED 该定时器已被创建过OS_ERR_OBJ_PTR_NULL 定时器对象为空OS_ERR_OBJ_TYPE 定时器对象无效OS_ERR_OPT_INVALID 选项不可用。OS_ERR_TMR_INVALID_DLY 定时初始实参无效OS_ERR_TMR_INVALID_PERIOD 周期重载实参无效OS_ERR_TMR_ISR 在中断函数中定时一次性定时时dly 不能为0。周期性定时时period 不能为0。*/void OSTmrCreate ( OS_TMR *p_tmr, // 定时器控制块指针。 CPU_CHAR *p_name, // 定时器名称。 OS_TICK dly, // 初始定时节拍数。 OS_TICK period, // 周期定时重载节拍数。 OS_OPT opt, OS_TMR_CALLBACK_PTR p_callback, // 定时到期时的回调函数。 void *p_callback_arg, // 传给回调函数的参数。 OS_ERR *p_err );/*启动一个软件定时器。错误：OS_ERR_NONE 没错误OS_ERR_ILLEGAL_CREATE_RUN_TIME 非法创建内核对象OS_ERR_OBJ_CREATED 该定时器已被创建过OS_ERR_OBJ_PTR_NULL 定时器对象为空OS_ERR_OBJ_TYPE 定时器对象无效OS_ERR_OPT_INVALID 选项不可用。OS_ERR_TMR_INVALID_DLY 定时初始实参无效OS_ERR_TMR_INVALID_PERIOD 周期重载实参无效OS_ERR_TMR_ISR 在中断函数中定时返回：DEF_TRUE，执行成功。DEF_FALSE，执行失败。一次性定时时dly 不能为0。周期性定时时period 不能为0。*/CPU_BOOLEAN OSTmrStart ( OS_TMR *p_tmr, // 定时器控制块指针。 OS_ERR *p_err);/*停止一个软件定时器。选项：OS_OPT_TMR_NONE 只需停止定时器，不需执行指定事件。OS_OPT_TMR_CALLBACK 停止定时器，并执行回调函数。OS_OPT_TMR_CALLBACK_ARG 停止定时器，并执行回调函数，且将p_callback_arg 作为新实参。错误：OS_ERR_NONE 没错误OS_ERR_OBJ_TYPE p_tmr 不是一个定时器指针OS_ERR_OPT_INVALID opt 非法OS_ERR_TMR_INACTIVE 定时器为被创建OS_ERR_TMR_INVALID p_tmr 为空OS_ERR_TMR_INVALID_STATE 定时器状态非法OS_ERR_TMR_ISR 在中断中被调用OS_ERR_TMR_NO_CALLBACK 定时器不存在回调函数OS_ERR_TMR_STOPPED 定时器已被停止返回：DEF_TRUE ， 停止成功（ 包括定时器已被停止， 即错误类型为“OS_ERR_TMR_STOPPED”）。DEF_FALSE，停止失败。*/CPU_BOOLEAN OSTmrStop ( OS_TMR *p_tmr, OS_OPT opt, void *p_callback_arg, OS_ERR *p_err);/*删除一个软件定时器。错误：OS_ERR_NONE 没错误OS_ERR_OBJ_TYPE p_tmr 不是一个定时器类型OS_ERR_TMR_INVALID p_tmr 为空OS_ERR_TMR_ISR 在中断中被调用OS_ERR_TMR_INACTIVE 定时器未被创建过OS_ERR_TMR_INVALID_STATE 定时器处于非法状态返回：DEF_TRUE，删除成功；DEF_FALSE，删除失败，或者有错误。*/CPU_BOOLEAN OSTmrDel ( OS_TMR *p_tmr, OS_ERR *p_err); 软件定时器结构体： 123456789101112131415161718struct os_tmr &#123; OS_OBJ_TYPE Type; CPU_CHAR *NamePtr; OS_TMR_CALLBACK_PTR CallbackPtr; void *CallbackPtrArg; OS_TMR *NextPtr; OS_TMR *PrevPtr; OS_TICK Match; OS_TICK Remain; OS_TICK Dly; OS_TICK Period; OS_OPT Opt; OS_STATE State;#if OS_CFG_DBG_EN &gt; 0u OS_TMR *DbgPrevPtr; OS_TMR *DbgNextPtr;#endif&#125;; 多值信号量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145/*创建一个多值信号量。错误：OS_ERR_NONE 没错误OS_ERR_CREATE_ISR 在中断中调用该函数OS_ERR_ILLEGAL_CREATE_RUN_TIME 在调用OSSafetyCriticalStart()函数后创建内核对象OS_ERR_NAME p_name 为空指针OS_ERR_OBJ_CREATED 信号量已经被创建过OS_ERR_OBJ_PTR_NULL p_sem 是个空指针OS_ERR_OBJ_TYPE p_sem 已被初始化到另一种对象类型*/void OSSemCreate ( OS_SEM *p_sem, // 多值信号量指针。 CPU_CHAR *p_name, // 多值信号量名称。 OS_SEM_CTR cnt, // 资源数目。 OS_ERR *p_err);/*发布多值信号量。选项：OS_OPT_POST_1 发布给等待该信号量中最高优先级的任务。OS_OPT_POST_ALL 发布给等待该信号量的所有任务。OS_OPT_POST_1 |OS_OPT_POST_NO_SCHED发布给等待该信号量中最高优先级的任务，但不进行任务调度。OS_OPT_POST_ALL |OS_OPT_POST_NO_SCHED发布给等待该信号量的所有任务，但不进行任务调度。错误：OS_ERR_NONE 没错误OS_ERR_OBJ_PTR_NULL p_sem 为空OS_ERR_OBJ_TYPE p_sem 不是多值信号量类型对象OS_ERR_SEM_OVF 该发布将导致了信号量的计数值溢出返回：0，有错误。其他值，信号量的计数值。*/OS_SEM_CTR OSSemPost ( OS_SEM *p_sem, OS_OPT opt, OS_ERR *p_err);/*等待一个多值信号量。选项：OS_OPT_PEND_BLOCKING 如果不能立即获得信号量，就堵塞当前任务，继续等待信号量。OS_OPT_PEND_NON_BLOCKING 如果不能立即获得信号量，不堵塞当前任务，不继续等待信号量。错误：OS_ERR_NONE 没错误，获得信号量。OS_ERR_OBJ_DEL p_sem 被删除。OS_ERR_OBJ_PTR_NULL p_sem 为空。OS_ERR_OBJ_TYPE p_sem 不是信号量类型对象。OS_ERR_OPT_INVALID opt 非法。OS_ERR_PEND_ABORT 等待被另一个任务中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_STATUS_INVALID 等待状态非法。OS_ERR_TIMEOUT 等待超时。返回：0，信号量的当前计数值为0，或有错误。其他值，信号量的当前计数值。*/OS_SEM_CTR OSSemPend ( OS_SEM *p_sem, OS_TICK timeout, // 等待超时时间（单位：时钟节拍），0代表无期限等待。opt 为OS_OPT_PEND_BLOCKING 时该参数才起作用。 OS_OPT opt, CPU_TS *p_ts, // 时间戳，用于存储信号量最后一次被发布的时间戳，或者等待被中止的时间戳，或者信号量被删除时的时间戳，具体返回哪个时间戳，要根据返回的p_err 判断。该参数可以为NULL，表示用户不需要获得时间戳。 OS_ERR *p_err);/*中止对一个多值信号量的等待。选项：OS_OPT_PEND_ABORT_1 只中止该信号量等待列表中的最高优先级任务。OS_OPT_PEND_ABORT_ALL 中止该信号量等待列表中的所有优先级任务。OS_OPT_PEND_ABORT_1|OS_OPT_POST_NO_SCHED 只中止该信号量等待列表中的最高优先级任务，但不进行任务调度。OS_OPT_PEND_ABORT_ALL|OS_OPT_POST_NO_SCHED 中止该信号量等待列表中的所有优先级任务，但不进行任务调度。错误：OS_ERR_NONE 没错误。OS_ERR_OBJ_PTR_NULL p_sem 为空。OS_ERR_OBJ_TYPE p_sem 不是多值信号量类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 没有任务在等待该信号量。返回：0，没有任务在等待该信号量，或者有错误产生。&gt;0，被中止的任务数。*/OS_OBJ_QTY OSSemPendAbort ( OS_SEM *p_sem, OS_OPT opt, OS_ERR *p_err);/*删除一个多值信号量。选项：OS_OPT_DEL_NO_PEND 如果没有任务等待p_sem，才删除p_sem。OS_OPT_DEL_ALWAYS 必须删除p_sem。错误：OS_ERR_NONE 没错误。OS_ERR_DEL_ISR 该函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_sem 为空。OS_ERR_OBJ_TYPE p_sem 不是多值信号量类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_TASK_WAITING 还有任务在等待该信号量。返回：0，没有任务在等待该信号量，或者有错误产生。&gt;0，信号量被删除前等待其的任务数。*/OS_OBJ_QTY OSSemDel ( OS_SEM *p_sem, OS_OPT opt, OS_ERR *p_err);/*设置多值信号量的计数值。错误：OS_ERR_NONE 没错误。OS_ERR_SET_ISR 函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_sem 为空。OS_ERR_OBJ_TYPE p_sem 不是多值信号量类型。OS_ERR_TASK_WAITING 还有任务在等待p_sem。*/void OSSemSet ( OS_SEM *p_sem, OS_SEM_CTR cnt, // 要设置的信号量计数值。 OS_ERR *p_err); 123456789101112struct os_sem &#123; OS_OBJ_TYPE Type; CPU_CHAR *NamePtr; OS_PEND_LIST PendList; #if OS_CFG_DBG_EN &gt; 0u OS_SEM *DbgPrevPtr; OS_SEM *DbgNextPtr; CPU_CHAR *DbgNamePtr;#endif OS_SEM_CTR Ctr; CPU_TS TS;&#125;; 互斥信号量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/*创建一个互斥信号量。错误：OS_ERR_NONE 没错误OS_ERR_CREATE_ISR 在中断中调用该函数OS_ERR_ILLEGAL_CREATE_RUN_TIME 在调用OSSafetyCriticalStart() 函数后创建内核对象OS_ERR_NAME p_name 为空指针OS_ERR_OBJ_CREATED 信号量已经被创建过OS_ERR_OBJ_PTR_NULL p_mutex 是个空指针*/void OSMutexCreate ( OS_MUTEX *p_mutex, // 互斥信号量指针。 CPU_CHAR *p_name, // 互斥信号量名称。 OS_ERR *p_err);/*释放互斥信号量。选项：OS_OPT_POST_NONE 释放信号量后，如果信号量可用，而且有任务正在等待，就（默认）进行任务调度。OS_OPT_POST_NO_SCHED 释放信号量后，如果信号量可用，而且有任务正在等待，不进行任务调度，继续运行当前任务。错误：OS_ERR_NONE 无错误。OS_ERR_MUTEX_NESTING p_mutex 被嵌套。OS_ERR_MUTEX_NOT_OWNER 当前任务不持有p_mutex。OS_ERR_OBJ_PTR_NULL p_mutex 为空。OS_ERR_OBJ_TYPE p_mutex 不是多值信号量类型。OS_ERR_POST_ISR 在中断中释放多值信号量。*/void OSMutexPost ( OS_MUTEX *p_mutex, OS_OPT opt, OS_ERR *p_err);/*申请一个互斥信号量。选项：OS_OPT_PEND_BLOCKING 如果不能立即获得信号量，就堵塞当前任务，继续等待信号量。OS_OPT_PEND_NON_BLOCKING 如果不能立即获得信号量，不堵塞当前任务，不继续等待信号量。错误：OS_ERR_NONE 没错误，获得信号量。OS_ERR_OBJ_DEL p_sem 被删除。OS_ERR_OBJ_PTR_NULL p_sem 为空。OS_ERR_OBJ_TYPE p_sem 不是信号量类型对象。OS_ERR_OPT_INVALID opt 非法。OS_ERR_PEND_ABORT 等待被另一个任务中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_STATUS_INVALID 等待状态非法。OS_ERR_TIMEOUT 等待超时。返回：0，有错误。其他值，信号量的计数值。*/void OSMutexPend ( OS_MUTEX *p_mutex, OS_TICK timeout, // 等待超时时间（ 单位： 时钟节拍）， 0 代表无期限等待。opt 为OS_OPT_PEND_BLOCKING 时该参数才起作用。 OS_OPT opt, CPU_TS *p_ts, // 时间戳 OS_ERR *p_err);/*中止对一个互斥信号量的等待。选项：OS_OPT_PEND_ABORT_1 只中止该信号量等待列表中的最高优先级任务。OS_OPT_PEND_ABORT_ALL 中止该信号量等待列表中的所有优先级任务。OS_OPT_PEND_ABORT_1 |OS_OPT_POST_NO_SCHED只中止该信号量等待列表中的最高优先级任务，但不进行任务调度。OS_OPT_PEND_ABORT_ALL |OS_OPT_POST_NO_SCHED中止该信号量等待列表中的所有优先级任务，但不进行任务调度。错误：OS_ERR_NONE 没错误。OS_ERR_OBJ_PTR_NULL p_mutex 为空。OS_ERR_OBJ_TYPE p_mutex 不是多值信号量类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 没有任务在等待该信号量。返回：0，没有任务在等待该信号量，或者有错误产生。&gt;0，被中止的任务数。*/OS_OBJ_QTY OSMutexPendAbort ( OS_MUTEX *p_mutex, OS_OPT opt, OS_ERR *p_err);/*删除一个互斥信号量。选项：OS_OPT_DEL_NO_PEND 如果没有任务等待p_mutex，才删除p_mutex。OS_OPT_DEL_ALWAYS 必须删除p_mutex。错误：OS_ERR_NONE 无错误。OS_ERR_DEL_ISR 该函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_mutex 为空。OS_ERR_OBJ_TYPE p_mutex 不是互斥信号量类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_STATE_INVALID 持有信号量任务状态非法。OS_ERR_TASK_WAITING 还有任务在等待该信号量。返回：0，没有任务在等待该信号量，或者有错误产生。&gt;0，信号量被删除前等待其的任务数。*/OS_OBJ_QTY OSMutexDel ( OS_MUTEX *p_mutex, OS_OPT opt, OS_ERR *p_err); 1234567891011121314struct os_mutex &#123; OS_OBJ_TYPE Type; CPU_CHAR *NamePtr; OS_PEND_LIST PendList;#if OS_CFG_DBG_EN &gt; 0u OS_MUTEX *DbgPrevPtr; OS_MUTEX *DbgNextPtr; CPU_CHAR *DbgNamePtr;#endif OS_TCB *OwnerTCBPtr; OS_PRIO OwnerOriginalPrio; OS_NESTING_CTR OwnerNestingCtr; CPU_TS TS;&#125;; 消息队列123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/*创建一个消息队列。错误：OS_ERR_NONE 无错误OS_ERR_CREATE_ISR 在中断中调用该函数OS_ERR_ILLEGAL_CREATE_RUN_TIME 在调用OSSafetyCriticalStart() 函数后创建内核对象OS_ERR_NAME p_name 为空指针OS_ERR_OBJ_CREATED 该消息队列已经被创建过OS_ERR_OBJ_PTR_NULL p_q 是个空指针OS_ERR_Q_SIZE max_qty 为0.*/void OSQCreate ( OS_Q *p_q, // 消息队列指针。 CPU_CHAR *p_name, // 消息队列名称。 OS_MSG_QTY max_qty, // 最大消息数目。 OS_ERR *p_err);/*向消息队列发布一个消息。选项：OS_OPT_POST_FIFO 把消息发布到队列的入口端，并且只唤醒一个等待任务。OS_OPT_POST_LIFO 把消息发布到队列的出口端，并且只唤醒一个等待任务。OS_OPT_POST_FIFO |OS_OPT_POST_ALL 把消息发布到队列的入口端，并且唤醒全部等待任务。OS_OPT_POST_LIFO |OS_OPT_POST_ALL 把消息发布到队列的出口端，并且唤醒全部等待任务。OS_OPT_POST_FIFO |OS_OPT_POST_NO_SCHED 把消息发布到队列的入口端；只唤醒一个等待任务；不进行任务调度，继续运行当前任务。OS_OPT_POST_LIFO |OS_OPT_POST_NO_SCHED 把消息发布到队列的出口端；只唤醒一个等待任务；不进行任务调度，继续运行当前任错误：OS_ERR_NONE 调用成功，消息被发布了。OS_ERR_MSG_POOL_EMPTY 消息池没可用消息。OS_ERR_OBJ_PTR_NULL p_q 为空。OS_ERR_OBJ_TYPE p_q 不是消息队列类型。OS_ERR_Q_MAX 消息队列已满。*/void OSQPost ( OS_Q *p_q, void *p_void, // 消息指针 OS_MSG_SIZE msg_size, // 消息大小（字节） OS_OPT opt, OS_ERR *p_err);/*等待一个消息队列的消息。选项：OS_OPT_PEND_BLOCKING 如果不能立即获得消息，就堵塞当前任务，继续等待消息。OS_OPT_PEND_NON_BLOCKING 如果不能立即获得消息，不堵塞当前任务，不继续等待消息。错误：OS_ERR_NONE 没错误，任务获得消息。OS_ERR_OBJ_PTR_NULL p_q 为空。OS_ERR_PTR_INVALID p_msg_size 为空。OS_ERR_OBJ_TYPE p_q 不是消息队列类型对象。OS_ERR_PEND_ABORT 等待被中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_STATUS_INVALID 等待状态非法。OS_ERR_TIMEOUT 等待超时。返回：!= (void *)0，接收到的消息的指针（首地址）。== (void *)0，接收到一个空消息，或者没接收到消息，或者所等待的消息队列不存在，或者用户传给p_q 的不是消息队列类型的对象。*/void *OSQPend ( OS_Q *p_q, OS_TICK timeout, // 等待超时时间 OS_OPT opt, OS_MSG_SIZE *p_msg_size, // 消息大小（单位：字节）。 CPU_TS *p_ts, OS_ERR *p_err);/*中止任务对一个消息队列的等待。选项：OS_OPT_PEND_ABORT_1 只中止该消息队列等待列表中的最高优先级任务。OS_OPT_PEND_ABORT_ALL 中止该消息队列等待列表中的所有优先级任务。OS_OPT_PEND_ABORT_1 |OS_OPT_POST_NO_SCHED只中止该消息队列等待列表中的最高优先级任务，但不进行任务调度。OS_OPT_PEND_ABORT_ALL |OS_OPT_POST_NO_SCHED中止该消息队列等待列表中的所有优先级任务，但不进行任务调度。错误：OS_ERR_NONE 无错误。OS_ERR_OPT_INVALID 选项非法。OS_ERR_OBJ_PTR_NULL p_q 为空。OS_ERR_OBJ_TYPE p_q 不是消息队列类型。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 没有任务在等待该消息队列。返回：0，没有任务在等待该信号量，或者有错误产生。&gt;0，被中止的任务数。*/OS_OBJ_QTY OSQPendAbort ( OS_Q *p_q, OS_OPT opt, OS_ERR *p_err);/*删除一个消息队列。选项：OS_OPT_DEL_NO_PEND 如果没有任务等待p_q，才删除p_q。OS_OPT_DEL_ALWAYS 必须删除p_q。错误：OS_ERR_NONE 无错误。OS_ERR_DEL_ISR 该函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_q 为空。OS_ERR_OBJ_TYPE p_q 不是消息队列类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_TASK_WAITING 还有任务在等待该消息队列。返回：0，没有任务在等待该消息队列，或者有错误产生。&gt;0，消息队列被删除前等待其的任务数。*/OS_OBJ_QTY OSQDel ( OS_Q *p_q, OS_OPT opt, OS_ERR *p_err);/*清空一个消息队列（的消息）。错误：OS_ERR_NONE 无错误，执行成功。OS_ERR_FLUSH_ISR 该函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_q 为空。OS_ERR_OBJ_TYPE p_q 不是消息队列类型。返回：清空消息队列前队列里的消息数目。*/OS_MSG_QTY OSQFlush ( OS_Q *p_q, OS_ERR *p_err); 1234567891011struct os_q &#123; OS_OBJ_TYPE Type; CPU_CHAR *NamePtr; OS_PEND_LIST PendList;#if OS_CFG_DBG_EN &gt; 0u OS_Q *DbgPrevPtr; OS_Q *DbgNextPtr; CPU_CHAR *DbgNamePtr;#endif OS_MSG_Q MsgQ; &#125;; 事件标志组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139/*创建一个事件标志组。错误：OS_ERR_NONE 无错误，创建成功。OS_ERR_CREATE_ISR 在中断中调用该函数OS_ERR_ILLEGAL_CREATE_RUN_TIME 在调用OSSafetyCriticalStart() 函数后创建内核对象OS_ERR_NAME p_name 为空指针OS_ERR_OBJ_CREATED 该事件标志组已经被创建过OS_ERR_OBJ_PTR_NULL p_q 是个空指针*/void OSFlagCreate ( OS_FLAG_GRP *p_grp, // 事件标志组指针。 CPU_CHAR *p_name, // 事件标志组名称。 OS_FLAGS flags, // 事件标志初始值。 OS_ERR *p_err);/*发布一个事件标志组。选项：OS_OPT_POST_FLAG_SET 把选定的标志位置1。OS_OPT_POST_FLAG_CLR 把选定的标志位清0。OS_OPT_POST_FLAG_SET |OS_OPT_POST_NO_SCHED 把消息发布到队列的末端，并且唤醒全部等待任务；不进行任务调度，继续运行当前任务。OS_OPT_POST_FLAG_CLR |OS_OPT_POST_NO_SCHED 把消息发布到队列的前端，并且唤醒全部等待任务；不进行任务调度，继续运行当前任务。错误：OS_ERR_NONE 调用成功。OS_ERR_OBJ_PTR_NULL p_grp 为空。OS_ERR_OBJ_TYPE p_grp 不是事件标志组类型。OS_ERR_OPT_INVALID 选项非法。返回：事件标志组的标志值。*/OS_FLAGS OSFlagPost ( OS_FLAG_GRP *p_grp, OS_FLAGS flags, OS_OPT opt,, OS_ERR *p_err);/*等待一个事件标志组的事件组合发生。选项：OS_OPT_PEND_FLAG_CLR_ALL 等待flags 指定位均被清0。OS_OPT_PEND_FLAG_CLR_ANY 等待flags 指定位有一位被清0 即可。OS_OPT_PEND_FLAG_SET_ALL 等待flags 指定位均被置1。OS_OPT_PEND_FLAG_SET_ANY 等待flags 指定位有一位被置1 即可。OS_OPT_PEND_FLAG_CLR_ALL |OS_OPT_PEND_FLAG_CONSUME 等待flags 指定位均被清0；等到后把触发位取反。OS_OPT_PEND_FLAG_CLR_ANY |OS_OPT_PEND_FLAG_CONSUME 等待flags 指定位有一位被清0 即可；等到后把触发位取反。OS_OPT_PEND_FLAG_SET_ALL |OS_OPT_PEND_FLAG_CONSUME等待flags 指定位均被置1；等到后把触发位取反。OS_OPT_PEND_FLAG_SET_ANY |OS_OPT_PEND_FLAG_CONSUME等待flags 指定位有一位被置1 即可；等到后把触发位取反。OS_OPT_PEND_FLAG_CLR_ALL |OS_OPT_PEND_NON_BLOCKING要求flags 指定位均被清0；不符合要求不等待。OS_OPT_PEND_FLAG_CLR_ANY |OS_OPT_PEND_NON_BLOCKING要求flags 指定位有一位被清0；不符合要求不等待。OS_OPT_PEND_FLAG_SET_ALL |OS_OPT_PEND_NON_BLOCKING要求flags 指定位均被置1；不符合要求不等待。OS_OPT_PEND_FLAG_SET_ANY |OS_OPT_PEND_NON_BLOCKING要求flags 指定位有一位被置1；不符合要求不等待。OS_OPT_PEND_FLAG_CLR_ALL |OS_OPT_PEND_FLAG_CONSUME |OS_OPT_PEND_NON_BLOCKING要求flags 指定位均被清0；符合要求就把触发位取反；不符合要求不等待；。OS_OPT_PEND_FLAG_CLR_ANY |OS_OPT_PEND_FLAG_CONSUME |OS_OPT_PEND_NON_BLOCKING要求flags 指定位有一位被清0；符合要求就把触发位取反；不符合要求不等待；。OS_OPT_PEND_FLAG_SET_ALL |OS_OPT_PEND_FLAG_CONSUME |OS_OPT_PEND_NON_BLOCKING要求flags 指定位均被置1；符合要求就把触发位取反；不符合要求不等待；。OS_OPT_PEND_FLAG_SET_ANY |OS_OPT_PEND_FLAG_CONSUME |OS_OPT_PEND_NON_BLOCKING要求flags 指定位有一位被置1；符合要求就把触发位取反；不符合要求不等待；。错误：OS_ERR_NONE 等待成功，指定事件组合发生。OS_ERR_OBJ_PTR_NULL p_grp 为空。OS_ERR_OBJ_TYPE p_grp 不是事件标志组类型对象。OS_ERR_PEND_ABORT 等待被中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_TIMEOUT 等待超时。返回：!= (void *)0，任务脱离等待时的事件标志组的标志成员值。== (void *)0，有错误，或者等待超时。*/OS_FLAGS OSFlagPend ( OS_FLAG_GRP *p_grp, OS_FLAGS flags, // 要等待的事件（位）的组合 OS_TICK timeout, OS_OPT opt, CPU_TS *p_ts, OS_ERR *p_err);/*中止任务对一个事件标志组的等待。选项：OS_OPT_PEND_ABORT_1 只中止该事件标志组等待列表中的最高优先级任务。OS_OPT_PEND_ABORT_ALL 中止该事件标志组等待列表中的所有优先级任务。OS_OPT_PEND_ABORT_1 |OS_OPT_POST_NO_SCHED只中止该事件标志组等待列表中的最高优先级任务，但不进行任务调度。OS_OPT_PEND_ABORT_ALL |OS_OPT_POST_NO_SCHED中止该事件标志组等待列表中的所有优先级任务，但不进行任务调度。错误：OS_ERR_NONE 无错误。OS_ERR_OBJ_PTR_NULL p_grp 为空OS_ERR_OBJ_TYPE p_grp 不是事件标志组类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 没有任务在等待该事件标志组。返回：0，没有任务在等待该事件标志组，或者有错误产生。&gt;0，被中止的任务数。*/OS_OBJ_QTY OSFlagPendAbort ( OS_FLAG_GRP *p_grp, OS_OPT opt, OS_ERR *p_err);/*删除一个事件标志组。选项：OS_OPT_DEL_NO_PEND 如果没有任务等待p_grp，才删除p_grp。OS_OPT_DEL_ALWAYS 必须删除p_grp。错误：OS_ERR_NONE 无错误。OS_ERR_DEL_ISR 该函数在中断中被调用。OS_ERR_OBJ_PTR_NULL p_grp 为空。OS_ERR_OBJ_TYPE p_grp 不是事件标志组类型。OS_ERR_OPT_INVALID 选项非法。OS_ERR_TASK_WAITING 还有任务在等待该事件标志组。返回0，没有任务在等待该事件标志组，或者有错误产生。&gt;0，事件标志组被删除前等待其的任务数。*/OS_OBJ_QTY OSFlagDel ( OS_FLAG_GRP *p_grp, OS_OPT opt, OS_ERR *p_err); 123456789101112struct os_flag_grp &#123; OS_OBJ_TYPE Type; CPU_CHAR *NamePtr; OS_PEND_LIST PendList; #if OS_CFG_DBG_EN &gt; 0u OS_FLAG_GRP *DbgPrevPtr; OS_FLAG_GRP *DbgNextPtr; CPU_CHAR *DbgNamePtr;#endif OS_FLAGS Flags; CPU_TS TS; &#125;; 等待多个内核对象1234567891011121314/*等待多个内核对象（多值信号量或消息队列）。选项：OS_OPT_PEND_BLOCKING 如果目前没有对象已被发布，阻塞任务，等待对象被发布。OS_OPT_PEND_NON_BLOCKING 如果目前没有对象已被发布，不阻塞任务。*/OS_OBJ_QTY OSPendMulti ( OS_PEND_DATA *p_pend_data_tbl, // 要等待的内核对象，等待两个或以上对象时一般为数组。 OS_OBJ_QTY tbl_size, // 等待对象的数目。 OS_TICK timeout, OS_OPT opt, OS_ERR *p_err); 12345678910struct os_pend_data &#123; OS_PEND_DATA *PrevPtr; OS_PEND_DATA *NextPtr; OS_TCB *TCBPtr; OS_PEND_OBJ *PendObjPtr; OS_PEND_OBJ *RdyObjPtr; void *RdyMsgPtr; OS_MSG_SIZE RdyMsgSize; CPU_TS RdyTS;&#125;; 任务信号量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/*给一个任务发布任务信号量。选项：OS_OPT_POST_NONE 没有选项。OS_OPT_POST_NO_SCHED 不进行任务调度。错误：OS_ERR_NONE 没错误OS_ERR_SEM_OVF 该发布将导致了信号量的计数值溢出。OS_ERR_STATE_INVALID 任务状态非法。返回：0，有错误。其他值，任务信号量的当前计数值。*/OS_SEM_CTR OSTaskSemPost ( OS_TCB *p_tcb, // 目标任务控制块。 OS_OPT opt, OS_ERR *p_err);/*等待任务信号量。选项：OS_OPT_PEND_BLOCKING 如果不能立即获得信号量，就堵塞当前任务，继续等待信号量。OS_OPT_PEND_NON_BLOCKING 如果不能立即获得信号量，不堵塞当前任务，不继续等待信号量。错误：OS_ERR_NONE 没错误，成功获得信号量。OS_ERR_PEND_ABORT 等待被另一个任务中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_STATUS_INVALID 等待状态非法。OS_ERR_TIMEOUT 等待超时。返回：0，信号量的当前计数值为0，或有错误。其他值，信号量的当前计数值。*/OS_SEM_CTR OSTaskSemPend ( OS_TICK timeout, OS_OPT opt, CPU_TS *p_ts, CPU_TS *p_ts, OS_ERR *p_err);/*中止一个任务对其任务信号量的等待。选项：OS_OPT_POST_NONE 没有选项。OS_OPT_POST_NO_SCHED 不进行任务调度。错误：OS_ERR_NONE 没错误，成功中止。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 目标任务并未在等待任务信号量。OS_ERR_PEND_ABORT_SELF 目标任务是自身。返回：== DEF_FALSE&gt;0，目标任务没在等待任务信号量，或者有错误。== DEF_TRUE，目标任务确实在等待任务信号量，而且等待成功被中止。目标任务不可以是自身（当前运行任务）。*/CPU_BOOLEAN OSTaskSemPendAbort ( OS_TCB *p_tcb, OS_OPT opt, OS_ERR *p_err); 任务消息队列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/*向任务消息队列发布一个消息。选项：OS_OPT_POST_FIFO 把消息发布到队列的入口端。OS_OPT_POST_LIFO 把消息发布到队列的出口端。OS_OPT_POST_FIFO |OS_OPT_POST_NO_SCHED把消息发布到队列的入口端；不进行任务调度，继续运行当前任务。OS_OPT_POST_LIFO |OS_OPT_POST_NO_SCHED把消息发布到队列的出口端；不进行任务调度，继续运行当前任务。错误：OS_ERR_NONE 无错误，消息成功被发布了。OS_ERR_Q_MAX 任务消息队列已满。OS_ERR_MSG_POOL_EMPTY 消息池没可用消息。*/void OSTaskQPost ( OS_TCB *p_tcb, // 目标任务。如果该参数为NULL，消息将发送给当前运行任务。 void *p_void, // 消息指针。 OS_MSG_SIZE msg_size, // 消息长度。 OS_OPT opt, OS_ERR *p_err);/*等待任务消息队列的消息。选项：OS_OPT_PEND_BLOCKING 如果不能立即获得消息，就堵塞当前任务，继续等待消息。OS_OPT_PEND_NON_BLOCKING 如果不能立即获得消息，不堵塞当前任务，不继续等待消息。错误：OS_ERR_NONE 没错误，任务成功获得消息。OS_ERR_PTR_INVALID p_msg_size 为空。OS_ERR_PEND_ABORT 等待被中止。OS_ERR_PEND_ISR 在中断中被调用。OS_ERR_PEND_WOULD_BLOCK 缺乏堵塞。OS_ERR_Q_EMPTY 任务消息队列里没有消息OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_TIMEOUT 等待超时。返回：!= NULL，接收到的消息的指针（首地址）。== NULL，接收到一个空消息，或者有错误。*/void *OSTaskQPend ( OS_TICK timeout, OS_OPT opt, OS_MSG_SIZE *p_msg_size, // 消息长度。 CPU_TS *p_ts, OS_ERR *p_err);/*中止一个任务对其消息队列的等待。选项：OS_OPT_POST_NONE 没有选项要求。OS_OPT_POST_NO_SCHED 不进行任务调度。错误：OS_ERR_NONE 无错误，中止成功。OS_ERR_OPT_INVALID 选项非法。OS_ERR_PEND_ABORT_ISR 该函数在中断中被调用。OS_ERR_PEND_ABORT_NONE 目标任务没在等待任务消息队列。OS_ERR_PEND_ABORT_SELF 目标任务是自身（当前运行任务）。返回：== DEF_FALSE，目标任务没在等待任务消息队列，或有错误。== DEF_TRUE，目标任务是在等待任务消息队列，而且等待被中止。p_tcb 不能为NULL 或当前运行任务。*/CPU_BOOLEAN OSTaskQPendAbort ( OS_TCB *p_tcb, OS_OPT opt, OS_ERR *p_err); 内存管理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/*创建一个内存管理对象。错误：OS_ERR_NONE 无错误，创建成功。OS_ERR_CREATE_ISR 在中断中调用该函数OS_ERR_ILLEGAL_CREATE_RUN_TIME 在调用OSSafetyCriticalStart() 函数后创建内核对象OS_ERR_MEM_INVALID_BLKS 内存块数目非法。OS_ERR_MEM_INVALID_P_ADDR 内存分区地址非法。OS_ERR_MEM_INVALID_SIZE 内存空间大小非法。*/void OSMemCreate ( OS_MEM *p_mem, // 内存管理对象。 CPU_CHAR *p_name, // 命名内存管理对象。 void *p_addr, // 内存分区首地址。 OS_MEM_QTY n_blks, // 内存块数目，要求不小于2。 OS_MEM_SIZE blk_size, // 内存块空间字节数，不少于一个指针的字节数。（STM32 是的指针的字节数是4）。 OS_ERR *p_err);/*向内存管理对象获取一个空闲内存块。错误：OS_ERR_NONE 无错误，获取成功。OS_ERR_MEM_INVALID_P_MEM p_mem 为空。OS_ERR_MEM_NO_FREE_BLKS 没有空闲的内存块。返回：获取到的内存块。*/void *OSMemGet ( OS_MEM *p_mem, OS_ERR *p_err);/*内存块退还回内存管理对象。错误：OS_ERR_NONE 无错误，退还成功。OS_ERR_MEM_FULL 内存分区的空闲内存块已满。OS_ERR_MEM_INVALID_P_BLK p_blk 为空。OS_ERR_MEM_INVALID_P_MEM p_mem 为空。*/void OSMemPut ( OS_MEM *p_mem, void *p_blk, // 要退还的内存块（的首地址）。 OS_ERR *p_err); 任务管理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184/*创建一个任务。选项：OS_OPT_TASK_NONE 没有选项要求。OS_OPT_TASK_STK_CHK允许任务进行堆栈检测。OS_OPT_TASK_STK_CLR堆栈全部进行清0 初始化。OS_OPT_TASK_SAVE_FP在上下文切换时保存浮点寄存器。STM32 芯片没有浮点寄存器，该项一般不用。OS_OPT_TASK_NO_TLS屏蔽任务的TLS 支持。错误：OS_ERR_NONE 无错误，创建成功。OS_ERR_ILLEGAL_CREATE_RUN_TIME在调用OSSafetyCriticalStart()函数后创建内核对象OS_ERR_NAME p_name 为空。OS_ERR_PRIO_INVALID prio&gt;= S_CFG_PRIO_MAX-1，或者在OS_CFG_ISR_POST_DEFERRED_EN 被置1 时prio=0。OS_ERR_STK_SIZE_INVALID p_stk_base 为空。OS_ERR_STK_LIMIT_INVALID stk_limit 大于stk_size。OS_ERR_TASK_CREATE_ISR 在中断中创建任务。OS_ERR_TASK_INVALID p_task 为空。OS_ERR_TCB_INVALID p_tcb 为空。*/void OSTaskCreate ( OS_TCB *p_tcb, // 任务控制块指针。 CPU_CHAR *p_name, // 命名任务。 OS_TASK_PTR p_task, // 任务函数。 void *p_arg, // 传递给任务函数的参数。 OS_PRIO prio, // 任务优先级。uC/OS-III 允许任务拥有相同的优先级。 CPU_STK *p_stk_base, // 任务堆栈指针。 CPU_STK_SIZE stk_limit, // 任务堆栈的限制空间。 CPU_STK_SIZE stk_size, // 任务堆栈总空间。 OS_MSG_QTY q_size, // 任务消息队列容量。只有使能了任务消息队列，该参数才有效。 OS_TICK time_quanta, // 时间片（单位：时钟节拍）。如果该参数设为0，表示使用系统默认值（ OSCfg_TickRate_Hz / 10）。 void *p_ext, // 任务扩展内容的指针。 OS_OPT opt, OS_ERR *p_err );/*挂起一个任务。错误：OS_ERR_NONE 无错误，挂起任务成功。OS_ERR_SCHED_LOCKED 挂起当前任务时调度器被锁。OS_ERR_TASK_SUSPEND_ISR 在禁用中断延迟发布的情况下，在中断中调用该函数。OS_ERR_TASK_SUSPEND_IDLE 挂起空闲任务。OS_ERR_TASK_SUSPEND_INT_HANDLER 在使能中断延迟发布的情况下，挂起中断延迟提交任务。不能挂起空闲任务。当OS_CFG_ISR_POST_DEFERRED_EN = 0u 时，不能在中断中调用该函数。当OS_CFG_ISR_POST_DEFERRED_EN &gt; 0u 时，不能挂起中断延迟提交任务。*/void OSTaskSuspend ( OS_TCB *p_tcb, // 任务控制块指针，0 表自身。 OS_ERR *p_err);/*解嵌一个被挂起的任务。错误：OS_ERR_NONE 无错误，解嵌成功。OS_ERR_STATE_INVALID 任务状态非法。OS_ERR_TASK_RESUME_ISR 在禁用中断延迟发布的情况下，在中断中调用该函数。OS_ERR_TASK_RESUME_SELF 解嵌自身。OS_ERR_TASK_NOT_SUSPENDED 任务p_tcb 未被挂起。不能解嵌自身，即p_tcb 不能为0 或当前运行任务。当OS_CFG_ISR_POST_DEFERRED_EN = 0u 时，不能在中断中调用该函数。*/void OSTaskResume ( OS_TCB *p_tcb, OS_ERR *p_err);/*改变一个任务的优先级。错误：OS_ERR_NONE 无错误，调用成功。OS_ERR_PRIO_INVALID 当使能了中断延迟发布时，prio_new = 0；或者，prio_new &gt;=(OS_CFG_PRIO_MAX-1)。OS_ERR_STATE_INVALID 目标任务的任务状态非法。OS_ERR_TASK_CHANGE_PRIO_ISR 在中断中调用该函数。当OS_CFG_ISR_POST_DEFERRED_EN &gt; 0u 时，prio_new 不能为0；prio_new 不能&gt;=(OS_CFG_PRIO_MAX-1)。不能在中断中调用该函数。*/void OSTaskChangePrio ( OS_TCB *p_tcb, OS_PRIO prio_new, OS_ERR *p_err);/*删除一个任务。错误：OS_ERR_NONE 无错误，调用成功。OS_ERR_STATE_INVALID 任务状态非法。OS_ERR_TASK_DEL_IDLE p_tcb 为空闲任务。OS_ERR_TASK_DEL_INVALID 当使能了中断延迟发布时，p_tcb 为中断延迟提交任务。OS_ERR_TASK_DEL_ISR 在中断中调用该函数。当OS_CFG_ISR_POST_DEFERRED_EN &gt; 0u 时，不能删除中断延迟提交任务。*/void OSTaskDel ( OS_TCB *p_tcb, OS_ERR *p_err);/*配置时间片轮转调度。当OS_CFG_ISR_POST_DEFERRED_EN = 0u 时，不能在中断中调用该函数。*/void OSSchedRoundRobinCfg ( CPU_BOOLEAN en, // 使能 DEF_ENABLED/禁用 DEF_DISABLED事件片轮转调度 OS_TICK dflt_time_quanta, // 设置默认时间片：&gt;0 把dflt_time_quanta 设为默认时间片值；=0 把系统默认值OSCfg_TickRate_Hz / 10 设为默认时间片值。 OS_ERR *p_err);/*放弃时间片。错误：OS_ERR_NONE 无错误，调用成功。OS_ERR_ROUND_ROBIN_1 当前优先级的就绪列表中只有一个任务（当前任务）。OS_ERR_ROUND_ROBIN_DISABLED 未使能时间片轮转调度。OS_ERR_SCHED_LOCKED 调度器被锁。OS_ERR_YIELD_ISR 在中断中调用该函数。*/void OSSchedRoundRobinYield ( OS_ERR *p_err);/*设置一个任务的时间片。错误：OS_ERR_NONE 无错误，调用成功。OS_ERR_SET_ISR 在中断中调用该函数。*/void OSTaskTimeQuantaSet ( OS_TCB *p_tcb, OS_TICK time_quanta, OS_ERR *p_err);/*设置一个任务的某个任务寄存器的值。错误：OS_ERR_NONE 无错误，调用成功。OS_ERR_REG_ID_INVALID Id 不在[ 0，OS_CFG_TASK_REG_TBL_SIZE – 1 ]内。*/void OSTaskRegSet ( OS_TCB *p_tcb, OS_REG_ID id, // 任务寄存器的id，取值范围为[ 0，OS_CFG_TASK_REG_TBL_SIZE – 1 ]。 OS_REG value, // 设置任务寄存器的内容。 OS_ERR *p_err);/*获取一个任务的某个任务寄存器的值。返回：0，获取的任务寄存器的值为0（p_err == OS_ERR_NONE），或有错误（p_err !=OS_ERR_NONE）。其他，获取的任务寄存器的值。*/OS_REG OSTaskRegGet ( OS_TCB *p_tcb, OS_REG_ID id, OS_ERR *p_err); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697struct os_tcb &#123; CPU_STK *StkPtr; void *ExtPtr; CPU_STK *StkLimitPtr; OS_TCB *NextPtr; OS_TCB *PrevPtr; OS_TCB *TickNextPtr; OS_TCB *TickPrevPtr; OS_TICK_SPOKE *TickSpokePtr; CPU_CHAR *NamePtr; CPU_STK *StkBasePtr; #if defined(OS_CFG_TLS_TBL_SIZE) &amp;&amp; (OS_CFG_TLS_TBL_SIZE &gt; 0u) OS_TLS TLS_Tbl[OS_CFG_TLS_TBL_SIZE];#endif OS_TASK_PTR TaskEntryAddr; void *TaskEntryArg; OS_PEND_DATA *PendDataTblPtr; OS_STATE PendOn; OS_STATUS PendStatus; OS_STATE TaskState; OS_PRIO Prio; CPU_STK_SIZE StkSize; OS_OPT Opt; OS_OBJ_QTY PendDataTblEntries; CPU_TS TS; OS_SEM_CTR SemCtr; OS_TICK TickCtrPrev; OS_TICK TickCtrMatch; OS_TICK TickRemain; OS_TICK TimeQuanta; OS_TICK TimeQuantaCtr;#if OS_MSG_EN &gt; 0u void *MsgPtr; OS_MSG_SIZE MsgSize;#endif#if OS_CFG_TASK_Q_EN &gt; 0u OS_MSG_Q MsgQ; #if OS_CFG_TASK_PROFILE_EN &gt; 0u CPU_TS MsgQPendTime; CPU_TS MsgQPendTimeMax; #endif#endif#if OS_CFG_TASK_REG_TBL_SIZE &gt; 0u OS_REG RegTbl[OS_CFG_TASK_REG_TBL_SIZE]; #endif#if OS_CFG_FLAG_EN &gt; 0u OS_FLAGS FlagsPend; OS_FLAGS FlagsRdy; OS_OPT FlagsOpt;#endif#if OS_CFG_TASK_SUSPEND_EN &gt; 0u OS_NESTING_CTR SuspendCtr; #endif#if OS_CFG_TASK_PROFILE_EN &gt; 0u OS_CPU_USAGE CPUUsage; OS_CPU_USAGE CPUUsageMax; OS_CTX_SW_CTR CtxSwCtr; CPU_TS CyclesDelta; CPU_TS CyclesStart; OS_CYCLES CyclesTotal; OS_CYCLES CyclesTotalPrev; CPU_TS SemPendTime; CPU_TS SemPendTimeMax; #endif#if OS_CFG_STAT_TASK_STK_CHK_EN &gt; 0u CPU_STK_SIZE StkUsed; CPU_STK_SIZE StkFree;#endif#ifdef CPU_CFG_INT_DIS_MEAS_EN CPU_TS IntDisTimeMax;#if OS_CFG_SCHED_LOCK_TIME_MEAS_EN &gt; 0u CPU_TS SchedLockTimeMax;#endif#if OS_CFG_DBG_EN &gt; 0u OS_TCB *DbgPrevPtr; OS_TCB *DbgNextPtr; CPU_CHAR *DbgNamePtr;#endif&#125;; 中断管理1234567891011121314151617181920212223242526272829303132333435/*标记进入中断服务函数。*/void OSIntEnter (void);/*标记退出中断服务函数。*/void OSIntExit (void);/*获取整个程序目前的最大关中断时间。返回：整个程序目前的最大关中断时间（时间戳时间）。*/CPU_TS_TMR CPU_IntDisMeasMaxGet (void);/*开始测量一个程序段的最大关中断时间。返回：上一次测量的程序段最大关中断时间（时间戳时间）。*/CPU_TS_TMR CPU_IntDisMeasMaxCurReset (void);/*结束一个程序段的最大关中断时间的测量。返回：测量的程序段最大关中断时间（时间戳时间）。返回值是一个以CPU 时钟运行的计数值，通过BSP_CPU_ClkFreq() 函数可以获取CPU 时钟频率。*/CPU_TS_TMR CPU_IntDisMeasMaxCurGet (void) 统计信息统计信息的开关在：os_cfg.h\OS_CFG_STAT_TASK_EN。 CPU 使用率和其最大记录分别保存于全局变量OSStatTaskCPUUsage 和OSStatTaskCPUUsageMax，一个任务的CPU 使用率和其最大记录分别保存于其任务控制块的CPUUsage 和CPUUsageMax 成员，一个任务的任务堆栈的空闲大小和已用大小分别保存于其任务控制块的StkFree 和StkUsed 成员。需要注意，OSStatTaskCPUUsage、OSStatTaskCPUUsageMax、CPUUsage 和CPUUsageMax 均被放大了10000 倍，所以这几个值缩小10000 倍后才是真实值。 12345678910111213141516171819202122/*获取CPU 主频。返回：CPU 的主频（单位：HZ），即HCLK 时钟频率。*/CPU_INT32U BSP_CPU_ClkFreq (void);/*获取系统版本号。返回：0，有错误，获取uC/OS 系统版本号失败。其他值，uC/OS 系统版本号。返回的版本号是一个被去掉“.”符号的整数，用户需要自行处理获取真实的版本号。如版本号为“V3.01.02”就返回30102*/CPU_INT16U OSVersion ( OS_ERR *p_err); 除了前面讲述的统计信息外，uC/OS 系统还为我们提供了很多统计信息。前一章讲述的最大关中断时间就是个很重要参数。此外，全局变量OSTaskCtxSwCtr 记录了任务切换总次数，OSTaskQty 记录了被创建任务的数目， OSSchedLockTimeMax （ 需使能OS_CFG_SCHED_LOCK_TIME_MEAS_EN，位于“os_cfg.h”）记录了调度器被锁的最大时间，OSIntQNbrEntriesMax 记录了中断队列成员被使用的最大数目，OSFlagQty 记录了事件标志组对象的数目，OSMemQty 记录了内存管理（分区）对象的数目，OSMutexQty 记录了互斥信号量对象的数目，OSQQty 记录了消息队列对象的数目，OSSemQty 记录了多值信号量对象的数目，等等。 uC/OS-II 与 uC/OS-III 区别 功能 uC/OS-II uC/OS-III 最大任务数 256 无限制 每个优先级的任务数 1 无限制 时间片轮转 否 是 互斥信号量 不可嵌套 可嵌套 消息邮箱 是 否 不通过信号量标记任务 否 是 不通过消息队列发送消息 否 是 任务的停止与恢复 不可嵌套 可嵌套 代码段需求 6k~26k 6k~20k 运行时配置 否 是 嵌入的测量功能 有限制 大量的 时间戳 否 是 汇编可视化 否 是 任务级的时基定时器处理 否 是 uC/OS-II 参考代码代码分为与处理器相关和无关的代码，以及应用相关的代码。 处理器无关的代码有：ucos_ii.h，ucos_ii.c，os_tmr.c，os_time.c，os_task.c，os_sem.c，os_q.c，os_mutex.c，os_mem.c，os_mbox.c，os_flag.c，os_core.c 处理器相关的代码有：os_cpu.h，os_cou_a.asm，os_cpu_c.c 应用相关的代码有：os_cfg.h，includes.h 任务管理任务是由程序，数据和PCB构成，任务之间由链表连接。 任务管理的相关函数：123456789OSTaskCreate() // 创建任务 OS_TASK_CREATE_EN OSTaskCreateExt() // 创建任务 OS_TASK_CREATE_EXT_ENOSTaskStkChk() // 堆栈检验 OS_TASK_CREATE_EXT_EN OSTaskDel() // 删除任务 OS_TASK_DEL_EN OSTaskDelReq() // 请求删除任务 OS_TASK_DEL_EN OSTaskSuuspend() // 挂起任务 OS_TASK_SUSPEND_ENOSTaskResume() // 恢复任务 OS_TASK_SUSPEND_ENOSTaskChangePrio() // 改变优先级 OS_TASK_CHANGE_PRIO_EN OSTaskQuery() // 查询任务信息 OS_TASK_QUERY_EN 创建任务要求： 创建任务不能在中断中创建； 且优先级范围是0~63，每个优先级与每个任务一一对应； 系统在运行期间可以创建任务。 创建任务：12345678910/*void (*task)(void *p_arg)：任务函数指针void *p_arg：堆栈指针OS_STK *ptos：堆栈栈顶指针INT8U prio：任务优先级返回值：返回函数错误信息如果没有错误，返回OS_NO_ERR*/INT8U OSTaskCreate(void (*task)(void *p_arg), void *pdata, OS_STK *ptos, INT8U prio); 其他任务函数123456789101112// INT8U prio：优先级// 删除任务INT8U OSTaskDel(INT8U prio)// 任务挂起INT8U OSTaskSuspend(INT8U prio)// 任务恢复INT8U OSTaskResume(INT8U prio)// 修改优先级INT8U OSTaskChangePrio(INT8U oldprio, INT8U newprio)// 查询信息INT8U OSTaskChangePrio(INT8U prio, OS_TCB *pdata) 结构体OS_TCB主要包含： 栈顶指针 控制块扩展指针 栈底指针 堆栈长度 创建任务的选项 保留 后一个TCB指针 前一个TCB指针 任务等待的时限 任务状态 优先级 用于快速访问就绪表的数据 例如创建函数的使用：12345678910void main(void)&#123; // Code OSInit(); // 系统初始化 // Code OSTaskCreate(Task, args); // 创建任务 OSTaskCreate(Task, args); // 创建任务 // Code OSStart(); // 运行系统&#125; 任务代码结构：1234567891011void Task(void *pdata)&#123; // 初始化部分 while(1)&#123; // 其他部分 OS_ENTER_CRITICAL(); // 关中断 // 不可中断部分 OS_EXIT_CRITICAL(); // 开中断 // 其他部分 &#125;&#125; 另外还有空闲任务和统计任务：123456789101112131415// 空闲任务，优先最低void OSTaskIddle(void *pdata)&#123; pdata = pdata; // 防止报错，没啥用 for(;;)&#123; OS_ENTER_CRITICAL(); // 关中断 OSIdleCtr++； // 计数 OS_EXIT_CRITICAL(); // 开中断 &#125;&#125;// 统计任务，用于统计CPU使用率：OSCPUsage// 开启需要在OS_CFG.H中配置OS_TASK_STAT_EN 为 1// 且需要在初始化 OSStatInit()OSTaskStart() 任务调度调度器负责在任务就绪队列中选取任务，并将切换出的任务放入等待队列。调度时机有： 操作系统运行开始的时候 任务用完一个时间片 产生了一个中断 任务自身转为等待 任务自身被删除 123456// 关闭调度void OSSchedLock(void);// 打开调度void OSSchedUnlock(void);// 切换任务void OSSched(void); 时钟ucos必须需要一个定时器用来做系统时钟。开启时钟必须在OSStart()之后，也就是用户任务中开启。 时钟管理的相关函数：123456OSTickISR() // 时钟中断OSTimeDly() // 节拍延时OSTimeDlyHMSM() // 时钟延时OSTimeDlyResume() // 唤醒延时OSTimeGet() // 获取当前时钟OSTimeSet() // 设置当前时钟 信号量123456OSSemCreate() // 创建信号量OSSemPend() // 获取信号量，会挂起OSSemPost() // 发送信号量，中断可用OSSemDel() // 删除信号量OSSemAccept() // 无等待获取信号量，中断可用OSSemQuery() // 查询信号量，中断可用 消息邮箱1234567OSMboxCreate() // 创建邮箱OSMboxPend() // 等待消息OSMboxPost() // 发送消息OSMboxPostOpt() // 发送消息OSMboxDel() // 删除消息OSMboxAccept() // 无等待获取消息OSMboxQuery() // 查询消息 消息队列12345678OSQCreate() // 创建消息队列OSQPend() // 等待获取消息OSQPostFront() // 发送消息OSQPostOpt() // 发送消息OSQFlush() // 发送消息OSQDel() // 删除消息OSQQuery() // 查询消息OSQAccept() // 无等待获取消息 内存管理采用固定分区法。 123456OSMemCreate() // 创建内存分区OSMemGet() // 申请内存块OSMemPut() // 释放内存块OSMemQuery() // 查看分区状态OSMemNameGet() // 获取分区名称OSMemNameSet() // 设置分区名称]]></content>
      <categories>
        <category>STM32</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[System]]></title>
    <url>%2F2020%2F02%2F11%2FSystem%2F</url>
    <content type="text"><![CDATA[Windows其他操作文件夹映射为磁盘1234# 映射z盘为dir文件夹subst z: e:\dir# 取消映射subst z: /d LinuxShell]]></content>
  </entry>
  <entry>
    <title><![CDATA[PythonFirst]]></title>
    <url>%2F2020%2F02%2F09%2FPythonFirst%2F</url>
    <content type="text"><![CDATA[数据类型数字型数字型包括： int：20 float：3.3 bool：True（True = 1, False = 0） complex：4+2j, complex(4, 2) 运算方式有：加(+)，减(-)，乘(*)，除-浮点(/)，除-整数(//)，取余(%)，乘方(**) 常用方法： range(n)：产生一个从0到n的序列。 range(m, n)：产生一个从m到n的序列。 sum()：对列表的所有元素求和 all()：判断列表中所有元素是否都是True any()：判断列表中是否包含True 运算方法： abs() max()：参数可以为序列。 min()：参数可以为序列。 pow()：乘幂运算。 round()：四舍五入，可以指定小数点后的位数。 math.ceil()：向上取整。 math.floor()：向下取整。 math.exp() math.fabs() math.log() math.log10() math.modf()：返回小数部分和整数部分（元组，先小数，后整数）。 math.sqrt() math.pi：内置常量，PI math.e：内置常量，E 随机函数： random.choice()：从给定的序列中随机选择一个元素。 random.randrange([start,] stop [, step])：在指定范围内按照基数底层的集合中获取一个随机数。基数默认为1。 random.random()：生成一个0到1之间的实数。 random.seed()：改变种子生成器。 random.shuffle()：将给定的序列随机排列。 random.uniform(x, y)：生成一个x到y之间的实数。 字符串可以使用&#39;inline&#39;、&quot;inline&quot;、&#39;&#39;&#39;multi lines&#39;&#39;&#39;方式。可以使用转义字符。索引从前面开始为0；从后面开始为-1。字符串只读，不能修改某一个字符。 运算方式有（设str_a=&quot;123456789&quot;）： 加(str_a + str_b)：字符串拼接。 乘(str_a * 2)：字符串重复。 切片(str_a[0:-1], str_a[3:])：返回字串”12345678”，”456789”，遵循左闭右开。 禁用转义字符(r&#39;\n&#39;)：返回”\n”，R作用一以。 in：查看是否在其中。 not in %：格式字符串 字符 描述 字符 描述 字符 描述 \ 续行 \\ 反斜线 \&#39; 单引号 \&quot; 双引号 \a 响铃 \b 退格 \0 空 \n 换行 \v 纵向制表符 \r 回车 \f 换页 \t 横向制表符 \oYY 八进制 \xYY 十六进制 常用方法 join()：连接字符串 split()：分隔字符串，返回列表 count(s)：返回子串s出现次数 len()：返回字符串长度 strip()：去掉两边空格 find()：查找子串位置，未找到返回 -1 replace(old, new)：替换子串 bytes.decode(encoding=’UTF-8’,errors=’strict’)：解码为字符串 encode(encoding=’UTF-8’,errors=’strict’)：编码为二进制数据 ljust(width, fillchar)：左对齐，返回填充后的字符串 rstrip(width, fillchar)：右对齐，返回填充后的字符串 center(width, fillchar)：居中对齐，返回填充后的字符串 原始格式化字符串原始格式化字符串： %c：字符 %s：字符串 %d：整数 %u：无符号整数 %o：无符号八进制 %x：无符号十六进制 %X：无符号十六进制（大写） %f：浮点，可以指定小数点后位数 %e：科学计数法 %E：科学计数法 %g：作用同%f%e %G：作用同%f%E %p：变量地址 例如：1"%s use python %f" % ('User', 3.7) 辅助指令： *：定义宽度或小数点精度 -：左对齐 +：在正数前面显示加号 &lt;sp&gt;：在正数前面显示空格 #：在八进制数前面显示零(‘0’)，在十六进制前面显示’0x’或者’0X’(取决于用的是’x’还是’X’) 0：显示的数字前面填充’0’而不是默认的空格 %：’%%’输出一个单一的’%’ var：映射变量(字典参数) m.n.：m 是显示的最小总宽度,n 是小数点后的位数 参考 增强型格式化字符串增强型写法：1234567891011121314# 指定输出位置"&#123;1&#125; &#123;0&#125; &#123;1&#125;".format("hello", "world")# 输出'world hello world'# 指定输出"姓名：&#123;name&#125;, 年龄 &#123;age&#125;".format(name="John", age=3)# 输出列表my_list = ['First', 'Second']print("姓：&#123;0[0]&#125;, 名 &#123;0[1]&#125;".format(my_list))# 格式化输出"&#123;:.2f&#125;".format(3.1415926) # 输出 3.14# 转义输出"&#123;&#123;&#125;&#125;".format() # 输出 &#123;&#125; 格式 描述 格式 描述 格式 描述 {:.2f} 保留小数点后两位 {:+.2f} 带符号保留 {:.0f} 不带小数 {:0&gt;2d} 数字补零 (填充左边, 宽度为2) {:x&lt;4d} 数字补x (填充右边, 宽度为4) {:x&lt;4d} 数字补x (填充右边, 宽度为4) {:,} 以逗号分隔 {:.2%} 百分比格式 {:.2e} 指数记法 {:&gt;10d} 右对齐 {:&lt;10d} 左对齐 {:^10d} 中间对齐 参考 f-stringPython 3.6 新增写法：字符串以f开头，字符串中的变量将会自动运算解析为结果。 123f'Hello &#123;name&#125;'f'&#123;1+2&#125;'f'&#123;w["name"]&#125;: &#123;w["age"]&#125;' f-string 使用{content:format}设置字符串格式。其中 content 是替换并填入字符串的内容，可以是变量、表达式或函数等，format 是格式描述符。 格式 描述 格式 描述 格式 描述 &lt; 左对齐 &gt; 右对齐 ^ 居中 + 加正负号 - 负数加负号 空格 正数加空格，负数加负号 # 进制数切换数字显示方式 width 指定数字宽度 0width 指定宽度并高位补0 width.precision 宽度.显示精度 , 千位分隔符 _ 千位分隔符 b/c/d/o/x 进制显示方式 s 字符串 e/E/f/F/g/G/% 浮点数显示方式 %a/%A/%w/%u 星期 %d 日 %b/%B/%m 月 %y/%Y 年 %H/%I 小时 %p 上下午 %M/%S/%f 分钟，秒，微秒 %j 一年的第几天 %z UTC偏移量 例如 12345c = 12345678f'c is &#123;c:015,d&#125;' # 'c is 000,012,345,678'e = datetime.datetime.today()f'the time is &#123;e:%Y-%m-%d (%a) %H:%M:%S&#125;' Unicode 字符串在Python2中，普通字符串是以8位ASCII码进行存储的，而Unicode字符串则存储为16位unicode字符串，这样能够表示更多的字符集。使用的语法是在字符串前面加上前缀 u。 在Python3中，所有的字符串都是Unicode字符串。 列表列表中的元素的类型可以不同。 运算方式有（设list_a=[1, 2, &quot;a&quot;, True]）： 加(list_a + list_b)：列表拼接。 乘(list_a * 2)：列表重复。 切片(list_a[0:-1], list_a[3:])：返回列表[1, 2, &quot;a&quot;]，[True]。 常用方法： count()：统计某元素出现次数 len()：返回元素个数 append()：在末尾添加元素 pop(n)：移除第n个元素，默认最后一个 index()：返回该元素的索引 insert()：插入一个元素 extend()：在末尾追加另一个列表的所有元素 remove()：移除第一个此元素 reverse()：翻转列表 sort()：元素排序 clear()：清空 copy()：复制 del list[x]：删除第x个元素 内置函数： filter：过滤函数 12345def is_odd(n): return n % 2 == 1 newlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])print(newlist) # [1, 3, 5, 7, 9] map：映射函数 12345def square(x): return x ** 2map(square, [1,2,3,4,5]) # [1, 4, 9, 16, 25]map(lambda x: x ** 2, [1, 2, 3, 4, 5]) # 使用 lambda 匿名函数 reduce：累积函数 12345def add(x, y) : # 两数相加 return x + y reduce(add, [1,2,3,4,5]) # 计算列表和：1+2+3+4+5=15reduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数 元组元组的元素不可修改。元组中的元素的类型可以不同。如果元组包含了对象，那么对象是可以修改的。构造空元组写作tup1 = ()，构造单元素元组tup2 = (20,)，注意有逗号。 运算方式有（设tuple_a=(1, 2, &quot;a&quot;, True)）： 加(tuple_a + tuple_b)：元组拼接。 乘(tuple_a * 2)：元组重复。 切片(tuple_a[0:-1], tuple_a[3:])：返回元组(1, 2, &quot;a&quot;)，(True)。 集合集合中的元素类型必须一致。集合中的元素不能重复。创建一个空集合必须使用set()。 运算方式有： 求差集(a - b) 求并集(a | b) 求交集(a &amp; b) 求二者中不同时拥有的元素(a ^ b) 常用操作： add()：添加元素 update()：批量添加元素 remove()：移除元素，如果不存在，会报错 discard()：移除元素，如果不存在，不会报错 pop()：随机删除一个 len()：求元素个数 clear()：情况集合 x in s：判断使用包含元素 字典字典中的元素按照键值对存取。字典中Key必须是不可变的数据类型（字符串，元组，常量）。字典中Key值必须是唯一的。 常用操作： clear()：清空字典 copy()：浅拷贝 get()：返回某键的值，否则返回default值 key in dict：判断是否有该key pop()：删除某个key 类型转换int()：转换为整型，可以接受：字符串，Bytes对象，数字。float()：转换为浮点，可以接受：字符串，数字。str()：转换为字符串，可接受几乎所有对象，转换结果适用于人类阅读。repr()：转换为字符串，可接受几乎所有对象，转换结果适用于机器使用。eval()：将字符串作为Python语句执行，返回执行结果。tuple()：转化为元组，可以接受：列表，字符串等。list()：转化为列表，可以接受：元组，字符串等。set()：转化为集合。dict()：转化为字典，可以接受：(key, value)的序列。chr()：整数转化为字符。ord()：字符转整数。unichr()：整数转换为Unicode字符。hex()：整数转十六进制字符串。oct()：整数转八进制字符串。 chr()：将数字按照ASCII转化为字符ord()：转换ASCII字符为整数bytearray()：返回一个Byte数组，参数是整数n，则初始化数组长度为n；如果是字符串，则将字符串转换为Bytescompile(source, filename, mode)：将字符串编译为字节码，mode可以为exec、eval、single 类型注解在Python中，我们创建变量，传递变量是不需要注明类型的。但是这也造成了不便。因此 Python 3 提供了类型注解的功能，来表明变量类型。 12345# x:int 注明x是一个int型变量，-&gt; 指明了返回值类型为intdef add(x:int, y:int) -&gt; int: # 声明一个int行变量，并赋值 z:int = 10 return x + y 内置函数input()：标准输入print()：标准输出12345678# 输出的结尾：以逗号结尾，默认是以换行结尾print(end=',')# 输出对象间隔号：以逗号间隔，默认是空格print(sep=',')# 输出到文件print(file='')# 是否强制刷新流print(flush=',') exec()：执行Python语句，无返回值eval()：将给定表达式用Python执行，并返回执行结果execfile(filename)：执行一个文件，返回执行结果file()：创建一个FILE对象，同open()memoryview()：查看对象的在内存的存储形式，对使用缓冲区的地方非常友好，尤其是对str与bytearray123456789101112a = 'aaaaaa'ma = memoryview(a)ma.readonly # True，只读的memoryviewmb = ma[:2] # 不会产生新的字符串a = bytearray('aaaaaa')ma = memoryview(a)ma.readonly # False，可写的memoryviewmb = ma[:2] # 不会会产生新的bytearraymb[:2] = 'bb' # 对mb的改动就是对ma的改动mb.tobytes() # 'bb' ma.tobytes() # 'bbaaaa' globals()：返回当前位置的全局变量，字典形式locals()：返回当前位置的局部变量，字典形式 id()：获取对象的内存地址hash()：返回对象的哈希值super()：调用父类vars()：将对象转化为字典 reload()：重新加载模块__import__()：动态加载类或模块help()：查看模块或函数的帮助信息 查看类型123type(x) # 查看变量的类型，子类与父类不一致。isinstance(x, int) # 查看变量是否是某种类型，子类和父类被认为一直。issubclass(father, son) # 判断是否为子类 基本操作for 循环1234567891011121314151617181920212223# 遍历列表for x in x_list: pass# 遍历字符串for c in "abcdefg": pass# 带索引遍历for i, name in enumerate(name_list, start_index): print(f'index is &#123;i&#125;,name is &#123;name&#125;')# 打包成元组遍历 a = [1,2,3], c = [4,5,6,7,8], zip(a,c) --&gt; [(1, 4), (2, 5), (3, 6)]for i in zip(albums, years): print(i)# 单行 for 循环s.split() for s in sentence# 相当于for s in sentence: s.split()# 遍历字典for k, v in knights.items(): print(k, v)# 遍历排序后的集合for f in sorted(set(basket)): print(f) 迭代器1234567list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=" ")it = iter(list) # 创建迭代器对象print (next(it)) # 输出迭代器的下一个元素print (next(it)) # 输出迭代器的下一个元素 StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 __next__() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 123456789101112131415161718class MyNumbers: def __iter__(self): self.a = 1 return self def __next__(self): if self.a &lt;= 20: x = self.a self.a += 1 return x else: raise StopIteration myclass = MyNumbers()myiter = iter(myclass) for x in myiter: print(x) 在 Python 中，使用了 yield 的函数被称为生成器。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 1234567891011121314151617import sys def fibonacci(n): # 生成器函数 - 斐波那契 a, b, counter = 0, 1, 0 while True: if (counter &gt; n): return yield a a, b = b, a + b counter += 1f = fibonacci(10) # f 是一个迭代器，由生成器返回生成 while True: try: print (next(f), end=" ") except StopIteration: sys.exit() 不定长传参转为元组传入 *1def printinfo( arg1, *vartuple ): 转为字典传入 **1def printinfo( arg1, **var_args_dict ): 匿名函数1sum = lambda arg1, arg2: arg1 + arg2 强制位置参数/前面的参数不能使用关键字参数。*后面的参数必须使用关键字参数。 12def f(a, b, /, c, d, *, e, f): print(a, b, c, d, e, f) 数据结构堆栈可以使用列表作为堆栈。 123stack = [1, 2, 3]stack.append(4)x = stack.pop() 可以使用模块。 12345from queue import LifoQueuestack = LifoQueue()stack.put(1)while not stack.empty(): x = stack.get() 队列使用列表作为队列，但是效率不高。 123que = [1, 2, 3]que.append(4)x = stack.popleft() 可以使用模块。 12345from queue import Queueque = Queue()q.put(1)while not q.empty(): x = q.get() 优先队列123456789101112131415from queue import PriorityQueueq = PriorityQueue()q.put(Task(5, 'Mid-level job'))while not q.empty(): next_job = q.get()class Task(object): def __init__(self, priority, description): self.priority = priority self.description = description return # 运算符重载 def __lt__(self, other): return self.priority &lt; other.priority 列表推导式可以方便用于创建列表 1234vec1 = [2, 4, 6]vec2 = [4, 3, -9][3*x for x in vec1] # [6, 12, 18][x*y for x in vec1 for y in vec2] # [8, 6, -18, 16, 12, -36, 24, 18, -54] 模块与包__name__属性来使该程序块仅在该模块自身运行时执行。 dir() 函数可以找到模块内定义的所有名称。以一个字符串列表的形式返回： 包：管理 Python 模块命名空间的形式，如sound包下的effects包下的echo模块，使用方法： 1import sound.effects.echo 对应的目录结构为： sound/ __init__.py effects/ __init__.py echo.py 包的下面必须有__init__.py文件（可以是空文件），否则将不会识别为包。 如果包定义文件 __init__.py 存在一个叫做 __all__ 的列表变量，那么在使用 from package import * 的时候就把这个列表中的所有名字作为包内容导入。 读写文件使用open()可以打开文件，其完整的参数表为： file: 必需，文件路径（相对或者绝对路径）。 mode: 可选，文件打开模式 buffering: 设置缓冲 encoding: 一般使用utf8 errors: 报错级别 newline: 区分换行符 closefd: 传入的file参数类型 opener: mode指定了文件打开模式，默认为只读，常见方式有： 模式 描述 模式 描述 模式 描述 x 写模式，文件已存在则报错 b 二进制 + 读写 r 只读 rb 只读，二进制 r+ 读写 rb+ 读写，二进制 w 只写 wb 只写，二进制 w+ 读写 wb+ 读写，二进制 a 追加写 ab 追加写，二进制 a+ 追加读写 ab+ 追加读写，二进制 123456789101112131415161718192021f = open(filename)# 读取n个字符或字节，默认是全部内容f.read(n)# 读取一行，如果为空，说明已经最后一行了f.readline()# 读取所有行f.readlines()# 写入f.write(data)# 返回当前指针位置f.tell()# 移动指针位置：0 从开头向后移动m个字节，1 从当前位置向后移动m个字节，2 从结尾向后移动m个字节f.seek(m, 0)# 获取文件描述符f.fileno()# 判断是否为终端设备f.isatty()# 刷新缓冲区到文件f.flush()# 关闭文件，释放资源f.close() 如果觉得打开文件再关闭文件操作繁琐，Python还提供了with as功能，可以打开后不管释放： 123# 执行完毕自动释放with open("/tmp/file.txt") as file: data = file.read() with语句不仅可以用来操作文件，线程等资源也可以使用。 pickle模块，可以用来序列化和反序列化对象。利用这个模块，我们可以用来保存数据结构到文件中。 1234import picklepickle.dump(obj, file)x = pickle.load(file) OS 模块目录与权限： 123456789101112131415161718192021222324252627282930313233343536# 检验权限模式，尝试使用UserID，GroupID访问目录，检验是否有权限访问。mode：# os.F_OK 测试path是否存在。# os.R_OK 测试path是否可读。# os.W_OK 测试path是否可写。# os.X_OK 测试path是否可执行。os.access(path, mode)# 更改当前进程的看到的根目录# 例如 os.chroot('/tmp')# 则 对于进程'/'目录就是系统的'/tmp'目录os.chroot(path)# 切换工作目录os.chdir(path)# 获取工作目录os.getcwd()# 更改权限os.chmod(path, mode)# 更改文件所有者os.chown(path, uid, gid)# 获取路劲下的文件和文件夹os.listdir(path)# 创建路径，mode为权限 0o755os.makedirs(path[, mode])# 删除路径为path的文件os.remove(path)# 删除空目录，如果非空则异常os.rmdir(path)# 重命名os.rename(src, dst)# 获取path信息os.stat(path)# 获取文件系统信息os.statvfs(path) 文件：123456789101112131415161718192021222324252627282930# 获取文件描述符fx = f.fileno()fx = os.open(filepath, os.O_RDONLY)# 关闭文件os.close(fx)# 关闭所有文件，左闭右开os.closerange(fx, fy)# 复制文件描述符os.dup(fx)# 通过描述符改变工作目录，fx指向目录os.fchdir(fx)# 修改文件所有权os.fchown(fx, uid, gid)# 强制写入磁盘os.fdatasync(fx)# 打开的文件的系统配置信息，name，'PC_LINK_MAX' 文件最大连接数，'PC_NAME_MAX' 文件名最长长度os.fpathconf(fx, name)# 获取描述符状态，包括设备信息，文件修改时间，用户ID等os.fstat(fx)# 获取描述符状态，包括文件系统块大小，可用块数，文件结点总数os.fstatvfs(fx) # 创建命名管道，mode为权限 默认0o666os.mkfifo(path[, mode])# 打开一个终端os.openpty()# 创建一个管道os.pipe()# 从command打开一个管道，command 使用的命令，mode r默认 w，bufsize 0无缓冲 1有缓冲os.popen(command[, mode[, bufsize]]) os.path 模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 绝对路径os.path.abspath(path)# 文件名os.path.basename(path)# 文件路径os.path.dirname(path)# 路径是否存在os.path.exists(path)# 文件访问时间os.path.getatime(path)# 文件修改时间os.path.getmtime(path)# 路径创建时间os.path.getctime(path)# 文件大小os.path.getsize(path)# 是否为绝对路径os.path.isabs(path)# 是否为文件os.path.isfile(path)# 是否为目录os.path.isdir(path)# 是否为链接os.path.islink(path)# 是否为挂载点os.path.ismount(path)# 合并目录与文件名os.path.join(path1[, path2[, ...]])# 转换path大小写与斜杠os.path.normcase(path)# 规范path形式os.path.normpath(path)# 返回path真实路径os.path.realpath(path)# 判断目录，文件是否相同os.path.samefile(path1, path2)# 判断是否指向同一文件os.path.sameopenfile(fp1, fp2)# 分割路径与文件名 元组os.path.split(path)# 返回驱动器名和路径 windows下 元组os.path.splitdrive(path)# 分割路径，返回路径名 扩展名 元组os.path.splitext(path)# 分割为加载点与文件os.path.splitunc(path)# 遍历path，每个目录都调用visit函数 visit(arg, dirname 目录, names 目录下所有文件名)os.path.walk(path, visit, arg) 异常与断言123456789101112try: pass# except 后可加元组，可以包含多个Exceptionexcept (ZeroDivisionError, KeyboardInterrupt): passelse: passexcept Exception: pass# finally不论发生异常与否都会执行，如果异常未被接住，则会在finally执行完毕后抛出finally: pass Python assert（断言）用于判断一个表达式，在表达式条件为 False 的时候触发异常。 1234# 语法 assert expression[, arguments] # 例如assert 3 + 2 == 5, '结果不为 5'# 输出 AssertionError: 结果不为 5 对象类的属性与方法的访问权限：123456# 默认为公有def fun():# 保护 一个下划线def _fun():# 私有 两个下划线def __fun(): 类的专用方法有：1234567891011121314151617181920212223242526272829303132333435363738394041# 构造函数def __init__():# 析构函数def __del__():# 打印def __repr__():# 按索引赋值def __setitem__():# 按索引取值def __getitem__():# 获取长度def __len__():# 比较def __cmp__():# 调用def __call__():# 运算符重载# 加def __add__():# 减def __sub__():# 乘def __mul__():# 除def __truediv__():# 取余def __mod__():# 乘方def __pow__():# 小于def __lt__():# 等于def __eq__():# 大于def __gt__():# 小于等于def __le__():# 不等于def __ne__():# 大于等于def __ge__(): 在类的继承中，子类不重写 __init__，实例化子类时，会自动调用父类定义的 __init__。子类重写 __init__，就不会调用父类的初始化函数。如果都想执行，可以使用super()调用。 标准库shutilshutil模块提供了针对日常的文件和目录管理任务： 123import shutilshutil.copyfile('a.txt','b.txt')shutil.move('/dir_a/a.txt','/dir_b') blogglob模块提供了一个函数用于从目录通配符搜索中生成文件列表 12import globglob.glob('*.py') # ['primes.py', 'random.py', 'quote.py'] syssys可以读取命令行参数 12import sysprint(sys.argv) # ['demo.py', 'arg1', 'arg2', 'arg3'] 也可以重定向输出，如stdin，stdout，stderr 1sys.stderr.write('Warning, log file not found starting a new one\n') rere模块为高级字符串处理提供了正则表达式工具。 12345import rere.findall(r'\bf[a-z]*', 'which foot or hand fell fastest')# ['foot', 'fell', 'fastest']re.sub(r'(\b[a-z]+) \1', r'\1', 'cat in the the hat')# 'cat in the hat' datetimedatetime模块为日期和时间处理同时提供了简单和复杂的方法。 12345678910111213141516171819from datetime import date, time, datetime# 格式化输出now = date.today()now.strftime("%m-%d-%y. %d %b %Y is a %A on the %d day of %B.")# '12-02-03. 02 Dec 2003 is a Tuesday on the 02 day of December.'# 日期天数差 birthday = date(1964, 7, 31)age = now - birthdayage.days # 14368# 当前时间戳time_stamp = time.time()# 转为日期时间datetime.fromtimestamp(time_stamp)# 转为时间戳int(time.mktime(today.timetuple()))# 补时差 today + datetime.timedelta(hours=8) 数据压缩以下模块直接支持通用的数据打包和压缩格式：zlib，gzip，bz2，zipfile，以及 tarfile。 1234567import zlibs = b'witch which has which witches wrist watch'len(s) # 41t = zlib.compress(s)len(t) # 37zlib.decompress(t) # b'witch which has which witches wrist watch'zlib.crc32(s) # 226805979 计时器123456789101112from timeit import TimerTimer('t=a; a=b; b=t', 'a=1; b=2').timeit()# 测试函数调用时间def test(): L = [] for i in range(100): L.append(i)if __name__ == '__main__': import timeit print(timeit.timeit("test()", setup="from __main__ import test")) 测试doctest模块提供了一个工具，扫描模块并根据程序中内嵌的文档字符串执行测试。12345678910def average(values): """Computes the arithmetic mean of a list of numbers. &gt;&gt;&gt; print(average([20, 30, 70])) 40.0 """ return sum(values) / len(values)import doctestdoctest.testmod() # 根据所给注释，自动验证本文档所有函数 unittest模块可以在一个独立的文件里提供一个更全面的测试集。 1234567891011import unittestclass TestStatisticalFunctions(unittest.TestCase): def test_average(self): self.assertEqual(average([20, 30, 70]), 40.0) self.assertEqual(round(average([1, 5, 7]), 1), 4.3) self.assertRaises(ZeroDivisionError, average, []) self.assertRaises(TypeError, average, 20, 30, 70)unittest.main() # 从命令行调用，执行所有测试 进阶内容正则表达式 模式 描述 模式 描述 模式 描述 ^ 开头 $ 末尾 . 任意字符，除了换行符 [...] 一组字符 [^...] 不在[]中的字符 re* 匹配0个或多个的表达式 re+ 匹配1个或多个的表达式 re? 匹配0个或1个表达式片段 re{n} 匹配n个前面表达式片段 re{n,} 精确匹配n个前面表达式片段 re{n,m} 匹配 n 到 m 次由前面的正则表达式片段 `a b` 匹配a或b (re) 匹配括号内的表达式 (?#...) 注释 \w 数字字母下划线 \W 非数字字母下划线 \s 任意空白字符 \S 任意非空字符 \d 任意数字 \D 任意非数字 \A 字符串开始 \Z 字符串结束或换行前 \z 字符串结束 \G 最后匹配完成的位置 \b 单词边界 \B 非单词边界 \n,\t 换行符，制表符 \1,…,\9 匹配第n个分组的内容 re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。 1234567891011# pattern 正则表达式# string 要匹配的字符串# flag 标志位# 未匹配返回Noneprint(re.match('a', 'a.b.c').span()) # span 返回匹配开始与结束的位置 返回(0, 1)print(re.match('c', 'a.b.c')) # 返回 Noneobj = re.match(pattern, string, flags=0)obj.group() # 原始对象obj.group(1) # 获取匹配的值obj.group(2) # 获取匹配的值 re.search 扫描整个字符串并返回第一个成功的匹配。 1re.search(pattern, string, flags=0).span() # 返回匹配的位置 re.sub用于替换字符串中的匹配项 1234# repl 替换的字符串，也可以是函数# count 最大替换次数# 返回 替换次数re.sub(pattern, repl, string, count=0, flags=0) compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。 1234pt = re.compile(pattern[, flags])# 例如pt = re.compile(r'\d+')m = pt.match("abcd") findall()在字符串中找到正则表达式所匹配的所有子串，并返回一个列表。 1234pt.findall(string[, pos[, endpos]])# 例如pt = re.compile(pattern[, flags])pt.findall("abcd") split 方法按照能够匹配的子串将字符串分割后返回列表 1re.split(pattern, string[, maxsplit=0, flags=0]) 正则表达式练习 网络HTTPHTTP请求头部格式为：HTTP 字段名: 字段内容，主要有以下几种： 头部 描述 头部 描述 Content-type:text/html 请求的MIME信息 Expires: Date 响应过期的日期和时间 Location: URL 重定向接收方到非请求URL的位置 Last-modified: Date 请求资源的最后修改时间 Content-length: N 请求的内容长度 Set-Cookie: String 设置Http Cookie HTTP响应头部还包括了： Allow：服务器支持的协议 Content-Encoding：编码 Location：如果是重定向301，则跳转到该页面 Date：服务器时间 Last-Modified：文档最后修改时间 Server：服务器名字 Set-Cookie：设置cookie 比较复杂的是Content-type，它包含： text/html ： HTML格式 text/plain ：纯文本格式 text/xml ： XML格式 image/gif ：gif图片格式 image/jpeg ：jpg图片格式 image/png：png图片格式 application/xhtml+xml：XHTML格式 application/xml：XML数据格式 application/atom+xml：Atom XML聚合格式 application/json：JSON数据格式 application/pdf：pdf格式 application/msword：Word文档格式 application/octet-stream：二进制流数据（如常见的文件下载） multipart/form-data：需要在表单中进行文件上传时，就需要使用该格式 SocketSocket API 中定义的协议族（family）参数是指调用者期待返回的套接字地址结构的类型，主要包含（AF有时也写作PF）： 12345678910111213141516171819202122232425262728293031323334353637383940414243AF_UNSPEC 0 /* 未指定 */ AF_UNIX 1 /* Unix domain sockets */AF_LOCAL 1 /* POSIX name for AF_UNIX */AF_INET 2 /* IPv4 */AF_AX25 3 /* 业余无线电 AX.25 */AF_IPX 4 /* Novell IPX */AF_APPLETALK 5/* AppleTalk 地址 */AF_NETROM 6 /* 业余无线电 NET/ROM */AF_BRIDGE 7 /* 多协议网桥 */AF_ATMPVC 8 /* ATM PVCs */AF_X25 9 /* 保留 for X.25 project */AF_INET6 10 /* IPv6 */AF_ROSE 11 /* 业余无线电 X.25 PLP */AF_DECnet 12 /* 保留 for DECnet project */AF_NETBEUI 13/* 保留 for 802.2LLC project*/AF_SECURITY 14/* Security callback pseudo AF */AF_KEY 15 /* PF_KEY key management API */AF_NETLINK 16 /* Only for Linux */AF_ROUTE AF_NETLINK /* Alias to emulate 4.4BSD */AF_PACKET 17 /* Packet family */AF_ASH 18 /* Ash */AF_ECONET 19 /* Acorn Econet */AF_ATMSVC 20 /* ATM SVCs */AF_RDS 21 /* RDS sockets */AF_SNA 22 /* Linux SNA Project (nutters!) */AF_IRDA 23 /* IRDA sockets */AF_PPPOX 24 /* PPPoX sockets */AF_WANPIPE 25 /* Wanpipe API Sockets */AF_LLC 26 /* Linux LLC */AF_IB 27 /* Native InfiniBand address */AF_CAN 29 /* Controller Area Network */AF_TIPC 30 /* TIPC sockets */AF_BLUETOOTH 31/* Bluetooth sockets */AF_IUCV 32 /* IUCV sockets */AF_RXRPC 33 /* RxRPC sockets */AF_ISDN 34 /* mISDN sockets */AF_PHONET 35 /* Phonet sockets */AF_IEEE802154 36/* IEEE802154 sockets */AF_CAIF 37 /* CAIF sockets */AF_ALG 38 /* Algorithm sockets */AF_NFC 39 /* NFC sockets */AF_VSOCK 40 /* vSockets */AF_MAX 41 /* 保留 */ 参考 定义的类型（type）包含： 1234567SOCK_STREAM = 1, // TCPSOCK_DGRAM = 2, // UDPSOCK_RAW = 3, // 原始类型，可以自定义SOCK_RDM = 4, // 提供可靠的数据包连接SOCK_SEQPACKET= 5, // 提供连续可靠的数据包连接SOCK_DCCP = 6, // 数据报拥塞控制协议，具有内置拥塞控制的不可靠数据报的传输SOCK_PACKET = 10, // 与网络驱动程序直接通信 定义的协议（protocol）包含： 12345678910111213141516171819202122232425enum&#123; IPPROTO_IP = 0, /* Dummy protocol for TCP */ IPPROTO_ICMP = 1, /* Internet Control Message Protocol */ IPPROTO_IGMP = 2, /* Internet Group Management Protocol */ IPPROTO_IPIP = 4, /* IPIP tunnels (older KA9Q tunnels use 94) */ IPPROTO_TCP = 6, /* Transmission Control Protocol */ IPPROTO_EGP = 8, /* Exterior Gateway Protocol */ IPPROTO_PUP = 12, /* PUP protocol */ IPPROTO_UDP = 17, /* User Datagram Protocol */ IPPROTO_IDP = 22, /* XNS IDP protocol */ IPPROTO_DCCP = 33, /* Datagram Congestion Control Protocol */ IPPROTO_RSVP = 46, /* RSVP protocol */ IPPROTO_GRE = 47, /* Cisco GRE tunnels (rfc 1701,1702) */ IPPROTO_IPV6 = 41, /* IPv6-in-IPv4 tunnelling */ IPPROTO_ESP = 50, /* Encapsulation Security Payload protocol */ IPPROTO_AH = 51, /* Authentication Header protocol */ IPPROTO_BEETPH = 94, /* IP option pseudo header for BEET */ IPPROTO_PIM = 103, /* Protocol Independent Multicast */ IPPROTO_COMP = 108, /* Compression Header protocol */ IPPROTO_SCTP = 132, /* Stream Control Transport Protocol */ IPPROTO_UDPLITE = 136, /* UDP-Lite (RFC 3828) */ IPPROTO_RAW = 255, /* Raw IP packets */ IPPROTO_MAX&#125;; 在Python中，主要的使用方式如下： 1socket.socket([family[, type[, proto]]]) family，套接字协议族，常见有： socket.AF_UNIX：只能够用于单一的Unix系统进程间通信 socket.AF_INET：服务器之间网络通信，IPv4 socket.AF_INET6：服务器之间网络通信，IPv6 type: 套接字类型，包括： socket.SOCK_STREAM：流式socket，用于TCP socket.SOCK_DGRAM：数据报式socket，用于UDP socket.SOCK_SEQPACKET：可靠的连续数据包服务 socket.SOCK_RAW：原始套接字，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以；其次，SOCK_RAW也可以处理特殊的IPv4报文；此外，利用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头。 protocol: 写 0 即可 连接方面： s.bind()：绑定地址到套接字，IPv4下，使用(host, port)绑定。 s.listen()：开启TCP监听。 s.accept()：等待连接（阻塞）。 s.connect()：主动连接服务器，IPv4下，使用(host, port)，如果连接失败，返回socket.error。 s.connect_ex()：主动连接服务器，出错时返回出错码。 s.close()：关闭套接字。 s.getpeername()：返回远程地址。 s.getsockname()：返回自己的地址。 s.settimeout(timeout)：设置超时时间，例如连接等待时间。 s.gettimeout()：获取超时时间。 数据传输： s.recv()：接收TCP数据，可以指定最大接收量。 s.send()：发送TCP数据，返回发送的字节数。 s.sendall()：发送完整TCP数据，如果失败抛出异常。 s.recvfrom()：接收UDP数据，返回(data, address)。 s.sendto()：发送UDP数据，参数为(data, (ip, port))，返回发送的字节数。 s.setsockopt(level,optname,value)：设置套接字。 s.getsockopt(level,optname[.buflen])：获取设置。 s.fileno()：返回套接字的文件描述符。 s.setblocking(flag)：设置为非阻塞模式。 s.makefile()：创建套接字文件。 uWSGIuWSGI 是Python搭建Web服务所用的中间件，是调和Web服务于Web应用直接的协议问题。 首先安装uWSGI：123pip install uwsgi# uwsgitop 用于监控数据pip install uwsgitop 假设当前Nginx配置为：1234location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:3031;&#125; 我们启动一个uWSGI服务：1234567# --processes 添加更多的进程，用于并发# --threads 添加更多的线程，用于并发# --stats 使用 stats 子系统，可以执行监控任务 (uwsgitop)# --http-socket 启动地址，结合Nginx用# --wsgi-file 指定入口文件# --chdir 指定项目目录，如Django项目目录uwsgi --http-socket 127.0.0.1:3031 --chdir /home/foobar/myproject/ --wsgi-file myproject/wsgi.py --master --processes 4 --threads 2 --stats 127.0.0.1:9191 也可以写成配置文件：1234567[uwsgi]socket = 127.0.0.1:3031chdir = /home/foobar/myproject/wsgi-file = myproject/wsgi.pyprocesses = 4threads = 2stats = 127.0.0.1:9191 接着执行：1uwsgi yourfile.ini 如果不用Django框架，而是单独文件server.py，或是Flask框架：1234# uWSGI Python 加载器将会搜索的默认函数 application def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b"Hello World"] 多线程Python代码的执行由Python虚拟机（也叫解释器主循环）来控制。Python在设计之初就考虑到要在主循环中，同时只有一个线程在执行。虽然 Python 解释器中可以“运行”多个线程，但在任意时刻只有一个线程在解释器中运行。对Python虚拟机的访问由全局解释器锁(GIL)来控制，正是这个锁能保证同一时刻只有一个线程在运行。也就是说，尽管有了线程模块，Python几乎依然是单线程处理。 尽管如此，在IO密集型的多线程应用中，Python的多线程threading库表现却依然还行。但在并行计算型应用中，如果想真正实现多线程，就得在Python中可以使用多线程threading，并自行设计锁结构，或使用多进程multiprocessing，并在主进程设置消息队列，共享内存，管道等方式传递数据。 threading 模块创建线程，可以直接使用： 12345678910from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name)if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.start() print('主线程') 也可以通过子类继承后使用： 123456789101112131415from threading import Threadimport timeclass Sayhi(Thread): def __init__(self,name): super().__init__() self.name=name def run(self): time.sleep(2) print('%s say hello' % self.name)if __name__ == '__main__': t = Sayhi('egon') t.start() print('主线程') Thead 对象的常用方法有： isAlive()：是否运行 getName()：获取线程名称 setName()：设置线程名称 x.join()：当前线程等待x线程结束再继续执行。 setDaemon(True)：设置为守护线程 守护线性：如果设置一个线程为守护线程，就表示这个线程是不重要的，在进程退出的时候，不用等待这个线程退出。主线程只会等待所有非守护线程都结束后才退出。 threading 模块的常用方法有： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 使用 同步锁 可以防止数据竞争问题：123456R = threading.Lock()R.acquire()'''临界区'''R.release() 但是使用锁的时候，一定要解决好死锁的问题。解决方法可以参考《操作系统》相关章节。 线程间通信，可以使用消息队列，可以使用共享内存的方式进行通信。下面使用队列方式通信（注意互斥访问队列）： 12345678910111213141516171819# JoinableQueue# 队列长度，多线程下不够准确Queue.qsize()# 队列判空Queue.empty()# 队列判满Queue.full()# 入队，是否阻塞Queue.put(item, block=True, timeout=None)# 入队，不阻塞Queue.put_nowait(item)# 出队，是否阻塞Queue.get(block=True, timeout=None)# 出队，不阻塞Queue.get_nowait()# 提示让出队列，提示join停止阻塞Queue.task_done()# 阻塞直到队列为空Queue.join() multiprocessing 模块多进程的创建： 1234567891011121314from multiprocessing import Processimport osdef work(): print('hello',os.getpid())if __name__ == '__main__': # 会发现每一个进程都有不同的 PID # 且进程的数据各自保留一份，互不相关 # 之间传递数据必须使用工具 p1=Process(target=work) p2=Process(target=work) p1.start() p2.start() print('主线程/主进程pid',os.getpid()) 创建共享内存实现主进程与子进程通信： 123456789101112import multiprocessing def f(a): a[0] = 5# 创建共享内存arr = multiprocessing.Array('i', range(10))# 子进程处理p = multiprocessing.Process(target=f, args=(arr,))p.start()p.join()print(arr[0]) 使用Manger通信，本质也是共享内存：12345678910111213141516import multiprocessingdef f(ls): ls.append('Hello')# Manager 要在主进程创建server = multiprocessing.Manager()# 每调用一次list产生一个共享内存# 除了list外，也可以是其他形式，如队列、锁、字典、数组等ls = server.list()# ls = server.Queue()# 子进程处理proc = multiprocessing.Process(target=f, args=(ls,))proc.start()proc.join()print(ls) ctypesctypes可以让Python直接调用任意的C动态库的导出函数，由于ctypes会在调用C函数前释放GIL，因此也可以实现多线程。 我们可以将写好的Task编译为C的动态库，例如lib_task.so或lib_task.dll，然后在Python中调用该库。打包动态库可以使用Visual Studio建立相关项目，Visual Studio就会自动生成一个DLL模板。或使用GCC创建： lib_task.h123456789101112131415#ifndef LIB_TASK_H#define LIB_TASK_H#ifdef __cplusplusextern " C " &#123;#endif// DLL 关键字 __declspec (dllexport)extern __declspec (dllexport) void Task(int arg);#ifdef __cplusplus&#125;#endif#endif lib_task.c12345678#include "print.h"// 在这里实现多线程void Task(int arg)&#123; while(arg); return;&#125; 编辑DLL：1gcc --share lib_task.c -o lib_task.dll 12345678910from ctypes import *from threading import Thread# lib_task.h 与 lib_task.dll 必须在这个目录下# 给DLL传递参数时，要将参数转化为C的类型lib = cdll.LoadLibrary("lib_task.dll")t = Thread(target=lib.Task, args=(1,))t.start()lib.Task() 线程池线程池可以帮助我们自动调度线程，在需要多线程任务量巨大的情况下是非常好用的工具，省去我们考虑线程同步的问题，也节省了上下文切换的时间。 第三方线程池 threadpool： 1pip install threadpool 12345678910111213from threadpool import ThreadPool, makeRequests# 创建一个容纳4个线程的线程池pool = ThreadPool(4)requests = makeRequests( some_callable, # 多线程的任务 list_of_args, # 参数 callback # 回调函数，可空 )for req in requests: pool.putRequest(req) # 等待线程池完成任务pool.wait() 另外还有ThreadPoolExecutor，ProcessPoolExecutor，线程（进程）池也可以使用。 Executor提供了以下常用的方法： submit(fn, *args,**kwargs)：将fn函提交给池子；*args是传给fn函数的参数；**kwargs表示以关键字的形式为fn的参数。 map(func, *iterables, timeout=None, chunksize=1)：类似于全局函数的map，只是该函数将会启动多个线程，以异步的方式立即对*iterables执行map处理，就是把for循环和submit结合在一起了。 shutdown(wait=True)：关闭池子，wait=True时等待池内所有任务执行完毕回收完资源后才继续；wait=False时立即返回，并不会等待池内的任务执行完毕；但不管wait参数为何值，整个程序都会等到所有任务执行完毕才会清空池子，所以submit和map必须在shutdown之前执行。 ​程序将task函数submit之后，submit会返回一个Future对象，Future类主要用于获取线程或进程任务函数的返回值。Future中提供了一下方法： cancel()：取消Future代表的线程或者进程任务，如果任务正在执行，不可取消，返回False；否则任务取消，返回Ture。 cancelled()：返回Future代表的任务是否被成功取消。 running()：返回Future代表的任务是否增正在执行。 done()：返回Future代表的任务是否已经结束。 result(timmeout=None)：返回Future代表的任务的结果，如果任务没有完成，该方法将会阻塞当前线程，timeout指定阻塞多长时间。 exception()：返回Future代表的任务的异常，如果没有异常，则返回None。 add_done_callback(fn)：给Future代表的任务加一个’回调函数’，当该任务成功之后，执行这个fn函数。 创建线程池 ThreadPoolExecutor： 123456789101112131415161718import time,threadingfrom concurrent.futures import ThreadPoolExecutordef f(n): time.sleep(2) print(f"线程号 &#123;threading.get_ident()&#125;",n) return n*nif __name__ == '__main__': # 创建线程池，线程数 5 t_pool = ThreadPoolExecutor(max_workers=5) t_l = list() for i in range(1,5): t = t_pool.submit(f,i) t_l.append(t) t_pool.shutdown() for i in t_l: print('===',i.result()) 创建进程池 ProcessPoolExecutor： 12345678910111213141516171819202122232425import time,threadingfrom concurrent.futures import ProcessPoolExecutordef callback_fun(x): passdef f(n): time.sleep(2) print(f"进程PID &#123;os.getpid()&#125;",n) return n*nif __name__ == '__main__': # 创建进程池，进程数 5 p_pool = ProcessPoolExecutor(max_workers=5) p_l = list() for i in range(5): t = p_pool.submit(f,i) # 也可以设置回调函数，回调的参数由任务函数提供 # t.add_done_callback(callback_fun) p_l.append(t) # 也可以写成 # s = p_pool.map(f,range(1,5)) p_pool.shutdown(wait = True) for i in p_l: print('===',i.result()) multiprocessing 模块也提供了进程池： 12345678910111213141516171819202122232425import os,timefrom multiprocessing import Process,Pooldef f(n): print(f"进程PID &#123;os.getpid()&#125;") time.sleep(1) return n*n # 返回值交给回调函数def cb_fun(n): passif __name__ == '__main__': # 创建工作进程 p = Pool(3) p_l = list() for i in range(1,10): re = p.apply( f, # 多线程工作函数 args=(i,), # 传递的参数 callback=cb_fun # 回调函数 ) p_l.append(re) print(p_l) p_l.close() p_l.join() XML 与 JSONXMLXML 指可扩展标记语言（eXtensible Markup Language），形式同HTML，是一种用于标记电子文件使其具有结构性的标记语言。XML也可以用于数据以文本格式存储下来。格式如下（DOM）： 123456789101112131415161718192021222324252627282930313233&lt;collection shelf="New Arrivals"&gt;&lt;movie title="Enemy Behind"&gt; &lt;type&gt;War, Thriller&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;2003&lt;/year&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Talk about a US-Japan war&lt;/description&gt;&lt;/movie&gt;&lt;movie title="Transformers"&gt; &lt;type&gt;Anime, Science Fiction&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;1989&lt;/year&gt; &lt;rating&gt;R&lt;/rating&gt; &lt;stars&gt;8&lt;/stars&gt; &lt;description&gt;A schientific fiction&lt;/description&gt;&lt;/movie&gt; &lt;movie title="Trigun"&gt; &lt;type&gt;Anime, Action&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;episodes&gt;4&lt;/episodes&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Vash the Stampede!&lt;/description&gt;&lt;/movie&gt;&lt;movie title="Ishtar"&gt; &lt;type&gt;Comedy&lt;/type&gt; &lt;format&gt;VHS&lt;/format&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;2&lt;/stars&gt; &lt;description&gt;Viewable boredom&lt;/description&gt;&lt;/movie&gt;&lt;/collection&gt; 解析 XML 可以使用 SAX 模块，SAX 模块用事件驱动模型，通过在解析 XML 的过程中触发一个个的事件并调用用户定义的回调函数来处理 XML 文件。SAX 模块非常适用于对大型文件进行处理，且只需要文件部分信息时使用。 通过使用ContentHandler类读取数据。ContentHandler的方法有： startDocument()：文档启动时调用。 endDocument()：到达结尾时调用。 startElement(name, attrs)：遇到开始标签&lt;..&gt;调用。 endElement(name)：遇到结束标签&lt;/..&gt;调用。 characters(content)：分情况看，有 从行开始，遇到标签之前，若存在字符，则content的值为这些字符串。 从一个标签，遇到下一个标签之前，若存在字符，则content的值为这些字符串。 从一个标签，遇到行结束符之前，若存在字符，则content的值为这些字符串。 标签可以是开始标签，也可以是结束标签。 12345678910111213141516171819202122232425import xml.saxclass MovieHandler( xml.sax.ContentHandler ): def __init__(self): # 此处定义对象属性 pass # 元素开始调用 def startElement(self, tag, attributes): pass # 元素结束调用 def endElement(self, tag): pass # 读取字符时调用 def characters(self, content): pass# 创建XML阅读器parser = xml.sax.make_parser()# 关闭命名空间parser.setFeature(xml.sax.handler.feature_namespaces, 0)# 创建对象Handler = MovieHandler()# 设置XML阅读器parser.setContentHandler(Handler)# 开始解析parser.parse("movies.xml") 如果解析的文件不大，且需要文件的全部信息，可以使用DOM解析器。这个解析器可以一次性将整个文档读入内存，且可读可写到文件。 1234567891011from xml.dom.minidom import parseimport xml.dom.minidom# 使用minidom解析器打开 XML 文档DOMTree = xml.dom.minidom.parse("movies.xml")collection = DOMTree.documentElementif collection.hasAttribute("shelf"): print (f"Root element : &#123;collection.getAttribute('shelf')&#125;")# 在集合中获取所有电影movies = collection.getElementsByTagName("movie") JsonJSON (JavaScript Object Notation) 是一种轻量级的数据交换格式，适合于网络间传输数据，如前后端使用Ajax传输，则偏向于传输Json。 123456789101112import jsondata = &#123; 'no' : 1, 'name' : 'Runoob', 'url' : 'http://www.runoob.com'&#125;# Python 字典类型转换为 JSON 对象json_str = json.dumps(data)# 将 JSON 对象转换为 Python 字典data = json.loads(json_str) GUI 编程TkinterPyQtwxPythonPyside数据与科学计算爬虫Robots 协议Robots 协议指定了一个网站可以爬取的信息，例如：http://www.taobao.com/robots.txt 12345678910111213User-agent: BaiduspiderAllow: /articleAllow: /oshtmlAllow: /ershouAllow: /$Disallow: /product/Disallow: /User-Agent: *Disallow: /# 站点信息Sitemap: ... 使用爬虫技术，需要注意应： 要伪装User-Agent，且需要多个，随机选取 对参数进行URL编码 注意是否是通过AJAX传输数据 保存服务器下发的Cookies URL Lib 包urllib.request，负责读写 url。urllib.error，定义错误与异常。urllib.parse，url参数的编码解码。urllib.robotparser，用于分析robots.txt文件。 简单的读写URL： 123456789101112131415161718192021from urllib.request import urlopen, Request# 直接打开一个url，Request对象，返回HTTPResponse对象，用法类似文件res = urlopen(url, data)# 构造Requestreq = Request(url, headers=&#123; 'User-agent': 'user agent'&#125;)# 或 req.add_header('', '')res = urlopen(req)# 查看结果res.closed # 查看是否关闭，Falsewith res: res.status # 状态码 res.reason # 状态 res.getrul() # 真正的URL，例如重定向后的URL res.info() # headers res.read() # 返回读取的内容res.closed # 查看是否关闭，True URL参数的编码解码： 12345678910111213from urllib.request import parsed = &#123; 'id': 1, 'name': 'auther',&#125;# url编码arg = parse.urlencode(d)# url解码d = parse.unquote(arg)# 使用url = f"http://...?&#123;arg&#125;" # GET# 或 urlopen(req, arg.encode()) POST HTTP 实验网站 AJAX 与 HTTPS在Chrome浏览器里，进入开发者选项，选择XHR分类，查看异步请求。利用其中的AJAX接口进行数据请求。 HTTPS是由权威机构颁发的证书，颁发的证书文件需要事先上传至被认证的服务器上。当用户访问网站时，用户浏览器会首先得到该网站的服务器证书，用户拿到证书后进行验证，进而判断通信是否安全。 在爬虫中，我们会遇到拥有HTTPS但是不信任的网站，因此要尽量忽略HTTPS以减少工作量。 使用SSL模块忽略HTTPS： 123456import ssl# 忽略不信任的证书context = ssl._create_unverified_context()with urlopen(req, context = context) as res: pass urllib 3urllib 3库是一个第三方库，提供了例如连接池管理等功能。 1pip install urllib3 使用： 12345678910import urllib3# 打开一个 URL 池管理器with urllib3.PoolManager() as http: # http.urlopen() resp = http.request() # resp.status # resp.reason # resp.headers # resp.data requests 库requests库是基于urllib3库的，而且提供了更加友好的API使用。 1pip install requests 使用： 12345678910111213import requestsresp = requests.request('GET', url, headers=&#123; 'User-Agent': ua &#125;)with resp: # resp.url # resp.status_code # resp.request.headers # resp.text # resp.cookies 使用带Cookie的访问： 12345with request.Session() as session: for url in urls: resp = session.get(url, headers=&#123;'',''&#125;) with resp: pass XPATH 技术XPath是用来在XML中查找信息的语言。 123456789101112&lt;?xml version="1.0" encoding="ISO-8859-1"?&gt;&lt;bookstore&gt;&lt;book&gt; &lt;title lang="en"&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt;&lt;/bookstore&gt; 在XPath中定义了节点： 元素：&lt;title lang=&quot;en&quot;&gt;Harry Potter&lt;/title&gt; 属性：lang=&quot;en&quot; 文本： 命名空间：&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt; 处理指令 注释 文档节点：&lt;bookstore&gt; 也包含节点关系，如：父，子，兄弟，所有祖先，所有后代。 在XPath中，节点之间的父子关系可以用表达式表示： nodename：选取此节点的所有子节点 /：根节点或分隔符 //：后继节点，不考虑路径 .：当前节点 ..：父节点 @：属性 |：选取多个路径 谓语是用于按照索引选择子节点的工具： [1]：第一个元素 [last()]：最后一个元素 [position()&lt;3]：前两个元素 [@lang]：拥有lang属性的元素 [@lang=&#39;eng&#39;]：满足条件的元素 [price&gt;10]：元素值大于10的元素 通配符： *：任何元素节点 @*：任何属性节点 node()：任何类型节点 轴可定义相对于当前节点的节点集： ancestor：选取当前节点的所有祖先（父、祖父等）。 ancestor-or-self：选取当前节点的所有祖先（父、祖父等）以及当前节点本身。 attribute：选取当前节点的所有属性。 child：选取当前节点的所有子元素。 descendant：选取当前节点的所有后代元素（子、孙等）。 descendant-or-self：选取当前节点的所有后代元素（子、孙等）以及当前节点本身。 following：选取文档中当前节点的结束标签之后的所有节点。 namespace：选取当前节点的所有命名空间节点。 parent：选取当前节点的父节点。 preceding：选取文档中当前节点的开始标签之前的所有节点。 preceding-sibling：选取当前节点之前的所有同级节点。 self：选取当前节点。 使用轴可以选取某些节点： child::book：选取所有属于当前节点的子元素的 book 节点。 child::text()：选取当前节点的所有文本子节点。 安装 lxml 模块：1234# linux 需要依赖sudo apt-get install libxml2-dev libxslt-dev # windows 不需要pip install lxml 使用： 123456789101112131415161718192021from lxml import etree# 构建标签root = etree.Element('html')body = etree.Element('body')root.append(body)# 打印HTMLprint(etree.tostring(root))print(etree.tostring( root, pretty_print=True).decode())# 添加子元素sub = etree.SubElement(body, 'child1')sub = etree.SubElement(body, 'child2')# 解析HTMLetree.HTML(text)a_node.xpath('xpath 路径') 在Chrome使用XPath工具：在选定的标签上右键-&gt;Copy-&gt;XPath，并根据给定的内容进行修改。也可以使用插件ChroPath调试。 在分析选定标签的时候，可以优先找id属性，其次class属性。 示例： 1234567891011121314151617from lxml import etreeimport requestsurl = 'https://moive.douban.com'ua = ''with requests.get( url, headers=&#123;'User-Agent': ua&#125;) as response: # HTML 内容 content = response.txt # 解析为 DOM html = etree.HTML(content) # 使用XPath得到内容 titles = html.xpath("//div[@class='villboard-bd']//tr/td/a/text()") for item in titles: print(item) XPath 语言 Spider数据分析与可视化安装环境： 编辑requirements.txt文件，安装依赖。 123456matplotlib==2.2.2 # 画图工具numpy=1.14.2 # 运算工具pandas==0.20.3 # 数据处理工具TA-Lib==0.4.16 # 技术指标库tables==3.4.2 # 读取 hdf5jupyter=1.0.0 # 展示数据平台 1pip install -r requirements.txt Jupyter Notebook原名Ipython Notebook，是一个基于Web的Python IDE，支持Julia，Python，R三种语言，在画图、数据展示方面非常方便。 运行Jupyter：1jupyter notebook 默认在http://localhost:8888打开IDE。 Cell：一对In Out称为Cell。有编辑模式和命令模式，类似与Vim。 编辑快捷键： Shift + Enter：执行，并下移 Ctrl + Enter：执行，不移动 命令快捷键： A：在上方添加Cell B：在下方添加Cell D + D：删除Cell Markdown：在上方改为标记。 MatplotlibMatplotlib是用来开发2D，3D图表的工具。可以参考Echarts。 12345678910import matplotlib.pyplot as plt# 魔法函数：仅仅在IPython中使用，此句表示可以内嵌绘图，并且可以省略掉plt.show()这一步。%matplotlib inlineplt.figure()plt.plot( [1, 0, 8], # 横坐标 [4, 2, 6] # 纵坐标)plt.show() Matplotlib有三层结构： 容器层：提供画板（Canvas），画布（Figure）以及绘图区/坐标系（Axes，SubPlot）。 辅助显示层：显示图例，刻度，网格等内容。 图像层：显示图像的内容。 常用方法有： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 定义数据x = range(10)y = [random.uniform(10, 20) for i in x] # uniform 均匀分布x_labels = [f"11:&#123;i:02&#125;" for i in x] # 设置步长为 5y_labels = range(40)u = range(10)v = [random.uniform(40, 50) for i in x]# 创建画布 容器层plt.figure( figsize=(20, 8), # 图像的尺寸 dpi=300 # 图像的DPI)# 创建折线图 图像层plt.plot(x, y)# 添加坐标轴刻度plt.xticks(x[::5], x_labels[::5])plt.yticks(y[::5])# 添加网格plt.grid( True, # 是否显示 linestyle='--', # 形状 alpha=0.3 # 透明度)# 添加标题plt.xlabel("Time")plt.ylabel("Temp")plt.title("The Plot")# 添加多条曲线 图像层plt.plot(u, v, color="r", linestyle="--", label="CN")# 图例，要求plot必须设置label属性plt.legend(loc="lower left") # 显示位置# 保存图像plt.savefig(path)# 显示图像，并释放资源plt.show() 如果绘制多个图像： 1234567891011121314151617# 设置 1 x 2 的绘图区，用法类似于plotfigure, axes = plt.subplots(nrows=1, ncols=2)axes[0].plot(x, y)axes[1].plot(u, v)axes[0].legend()axes[1].legend()axes[0].grid(True)axes[1].grid(True)axes[0].set_xticks()axes[1].set_xticks()axes[0].set_xlabel()axes[1].set_xlabel() 也可以画其他图像。 散点图（scatter）：观察数据的分布规律1plt.scatter(x, y) 柱状图（bar）：统计对比数据单柱：1234plt.bar(x, y, width=0.5, # 柱状图宽度 align='center', # 对齐方式) 多柱：12345678plt.bar(x, y1, width=0.2, # 柱状图宽度 align='center', # 对齐方式)plt.bar([i+0.1 for i in x], y2, width=0.2, # 柱状图宽度 align='center', # 对齐方式) 直方图（histogram）：反应一组连续数据的分布 组数 = 极差 / 组距 = (max - min) / bins 123456789distance = 3bins = (max(x) - min(x)) // distanceplt.hist(x, bins=bins, density=True # 是否显示频率)plt.xticks(range(min(x), max(x) + 2, distance)) 饼图（pie）：分类数据的占比情况123456plt.pie(x, labels=bins, # 每部分名称 autopct="%1.2f%%" # 占比显示格式)plt.axis('equal') # 变圆plt.legend() 如果无法正常显示中文，可以增加配置： 12plt.rcParams['font.sans-serif']=['SimHei'] #解决中文显示plt.rcParams['axes.unicode_minus'] = False #解决符号无法显示 或是一劳永逸的（Windows）： 删除~/.matplotlib/下的缓存文件；新增~/.matplotlib/matplotlibrc配置文件，修改内容为： 1234backend:TkAggfont.famly: sans-seriffont.sans-serif: SimHeiaxes.unicode_minus: False NumpyNumpy 是一款高效的运算工具，用于快速处理任意维度的数据。 ndarray数组： 123456789101112131415score = np.array([ [1, 2, 3], [4, 5, 6]]) # ndarray 类型，2维score = np.array([ [ [1, 2, 3], [4, 5, 6] ], [ [1, 2, 3], [4, 5, 6] ]], dtype=np.int32) # 3维，,32位int ndarray在底层使用C语言编写，内部解除了GIL，因此效率大大增加。ndarray因此也支持了向量化运算。 ndarray 包含了几种属性： ndarray.shape：数组维度的元组（“m行n列”等描述） ndarray.ndim：数组维度 ndarray.size：元素数量 ndarray.itemsize：每个元素的长度 ndarray.dtype：元素类型，如np.bool，np.int32，np.uint16，np.float64，np.complex64，np.object，np.string，np.unicode等 数组操作数组的生成： 1234567891011# 全0数组，也可以加dtpye，order参数np.zeros(shape)# 全1数组np.ones(shape)# 现有数组生成np.array(list) # 深拷贝数组np.copy(a) # 深拷贝数组np.asarray(a) # 浅拷贝数组# 生成固定范围的数组np.linspace(0, 100, 7) # 0到100，7个数，闭区间np.arange(0, 100, 7) # 0到100，步长7，左闭右开 随机数生成：12345678# 均匀分布，返回0~1的一组均匀分布的数np.random.rand()# 均匀分布，从[low,high)中随机采样，size指定输出样本数目，可以是int或元组np.random.uniform(low, high, size=None)# 标准正态分布，获取一个或多个样本np.random.randn()# 正态分布，loc为均值，scale为标准差np.random.normal(loc, scale, size=None) 数组操作： 12345678910111213141516171819202122# 定义data = np.array([ [1, 2, 3, 4], [10, 20, 30, 40],])# 选择元素：二维数组，选择第一行的前三个data[0, 0:3] # 切片操作为左闭右开# 改变形状：重新分割数据，并返回data.reshape(shape)# 改变形状：直接改变原始数据data.resize(shape)# 数组转置data.T()# 类型修改data.astype("int32")# 序列化data.tostring()# 去重np.unique(data)# 一维化data.flatten() 数组运算：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 逻辑运算：res = data &gt; 2 # 对每一个数字做计算并返回结果data[data &gt; 2] # 返回满足条件的部分数据data[data &gt; 2] = 1.9 # 对满足条件的数据做运算np.all() # 如果全部是True就返回Truenp.any() # 如果有True就返回Truenp.where(condition, a, b) # 满足condition的元素置为a，否则置为bcondition = np.logical_and(con_a, con_b) # 条件与运算condition = np.logical_or(con_a, con_b) # 条件或运算# 统计运算：np.min(data, axis=-1) # axis 表示按行还是按列np.max(data, axis=-1)np.median() # 中位数np.mean() # 均值np.std() # 标准差np.var() # 均方差 std 的平方np.sum()np.argmax(data, axis=1) # 返回最大值索引# 数组间运算，要遵循广播机制data + 1 # 对每一个元素运算data1 * data2 # 对应元素运算# 矩阵运算，此处的矩阵必须是二维数组mt = np.mat(data) # 转化为矩阵# 矩阵乘法np.matmul(mt1, mt2)np.dot(mt1, mt2)mt1 * mt2# 数组合并np.hstack((a, b)) # 水平拼接np.vstack((a, b)) # 垂直拼接np.concatenate((a, b), axis=0) # 任意拼接，需要设置轴# 数组分割np.split(x, 3) # 按个数分割np.split(x, [1, 3, 5]) # 按索引分割``` #### IO操作读取数据：```py# 无法读取字符串data = np.genfromtxt("data.csv", delimiter=',')# 处理缺失值：直接删除缺失值，插值处理缺失# 获取缺失值个数nan_num = np.count_nonzero(data[:, i][t[:, i] != t[:, i]])# 判断缺失np.isnan(i) GPU 加速首先需要CUDA，CUDNN，可以到官网下载。 查看本机CUDA情况可以到控制面板-&gt;NVIDIA控制面板-&gt;帮助-&gt;系统信息-&gt;组件里面查看。 通过使用Visual Studio可以开发CUDA应用，例如查看一个NVIDIA CUDA的例子：使用Visual Stuido打开项目：CUDA安装目录-&gt;Samples，配置1_Utilities-&gt;deviceQuery-&gt;右键设置为启动项目，执行，就可以看到CUDA信息了。 安装 cupy： 1234567891011121314151617181920# For CUDA 8.0pip install cupy-cuda80# For CUDA 9.0pip install cupy-cuda90# For CUDA 9.1pip install cupy-cuda91# For CUDA 9.2pip install cupy-cuda92# For CUDA 10.0pip install cupy-cuda100# For CUDA 10.1pip install cupy-cuda101# Install CuPy from sourcepip install cupy 使用方法同numpy一样： 123456789101112import numpy as npimport cupy as cp# numpy 用法x=np.ones((1024,512,4,4))*1024.y=np.ones((1024,512,4,1))*512.3254for i in range(20): z=x*y# cupy 用法x=cp.ones((1024,512,4,4))*1024.y=cp.ones((1024,512,4,1))*512.3254for i in range(20): z=x*y PandasPandas 也是处理数据的工具。拥有便捷的数据处理能力，读取文件也方便，同时很好的的结合了matplotlib。 DataFrame尽管numpy在数据计算方面较python原始的方法有很大优势，但是同时也缺失了数据含义的展示。因此DataFrame在这方面进行了增强。 1234567891011121314import numpy as npimport pandas as pd# 添加行列索引row_labels = [f"第&#123;i:02&#125;" for i in range(10)]# 或使用日期col_labels = pd.date_range(start="20200101", period=5, freq="B")data = pd.DataFrame(np.random.normal(0, 1, (10, 5)), index=row_labels, # 行索引 colums=col_labels # 列索引) # 正态分布 常用属性有：12345data.shapedata.index # 必须批量修改索引data.columnsdata.values # 去除索引后的数据，ndarraydata.T 常用方法：12345678head() # 返回前几行tail() # 返回后几行reset_index(drop=True) # 重置索引set_index("字段名", drop=True) # 单个索引set_index(["字段1", "字段2"], drop=True) # 多个索引# 对于多级索引还有属性：data.index.names data.index.levels Panel （即将弃用）是DataFrame的容器，是存储三维数据的结构。 1234567891011pdata = pd.Panel( np.arange(24).reshape(4, 3, 2), items=list("ABCD"), major_axis=pd.date_range("20200101", period=3), minor_axis=['1', '2'])# 查看某一组数据pdata['A']pdata.major_axis("")pdata.minor_axis("1") SeriesSeries 是带索引的一维数组。 创建Series123456# 数组sr = pd.Series(np.arange(10), index=[...])# 或字典sr = pd.Series(&#123;'a': 1, 'b': 2, 'c': 3&#125;)# 或已有数据sr = data.iloc[1, :] 常用属性有：12index # 索引values # 数值 数据操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 直接索引，先列后行data["字段"]["记录"]# 按名索引data.loc["记录"]["字段"]data.loc["记录", "字段"]# 按数字索引data.iloc[1][2]# 混合索引 （即将弃用）data.ix[0:4, ["字段1", "字段2"]]# 赋值data["字段"] = 100 # 按列data.loc["记录", "字段"] = 100 # 单个# 排序data.sort_values(by="字段", ascending=False)data.sort_values(by=["字段1", "字段2"], ascending=False)data.sort_index()# 算数运算data["字段"] + 3data["字段"].add(3)# 逻辑运算data[data["字段"] &gt; 2]data[(data["字段"] &gt; 2) &amp; (data["字段"] &lt; 10)]data.query("字段 &gt; 2 &amp; 字段 &lt; 10")data[data["字段"].isin([100, 50])]# 统计运算minmaxmeanmedianvarstddescribe() # 获取每个字段的所有统计指标idxmax() # max的索引idxmin() # 累计统计函数，查看走势cumsum()cumsum().plot() # 顺便画图cummax()cummin()cumprod()# 自定义运算apply(func, axis=0)# 按列删除data.drop(["字段"], axis=1) 绘图绘图函数如：DataFrame.plot()Series.plot() 12# kind 参数，图像类型plot(x="字段1", y="字段2", kind="scatter") IO操作读取数据，且可以识别表头等，支持CVS，JSON，HTML，Execl，HDF5，SQL等。 1234567891011121314151617181920212223242526272829303132333435363738394041# 读取CVSdata = pd.read_csv( path, usecols=['字段1', '字段2'], names=["字段名1", "字段名2"])# 存储CSVdata.to_csv( path, columns=['字段'], header=True, # 是否写入表头 mode="wa", # 写模式 index=True # 是否写入索引)# 读取HDF5data = pd.read_hdf( path, key=['字段'])# 存储HDF5data.to_hdf( path, key=['字段'])# 读取JSONdata = pd.read_json( path, orient="records" # 读入的形式，读入成记录 lines=True # 每一行是否有换行)# 存储JSONdata.to_json( path, orient="records" lines=True) 处理缺失值当缺失的值为NAN时： 123456789101112131415# 判断是否有Nullpd.isnull(data)pd.isnull(data).any() # 列出所有字段是否缺失pd.notnull(data)pd.notnull(data).all()# 将所有缺失值置0data[pd.isnull(data)]# 删除有缺失值的样本 inplace 是否修改原始 DataFramesdropna(inplace=False)# 替换缺失fillna(value, inplace=False)# 均值替换fillna(data['字段'].mean(), inplace=False) 当缺失值为其他形式： 12# 替换replace(to_replace="?", value=np.nan) 数据离散化通过对数据分类，并按分组分别统计处理数据。方式：one-hot编码（哑编码） 12345678910# 分组# 自动分组sr = data.qcout(data, bins)# 自定义分组，给定边界sr = data.cut(data, [10, 20, 30]) # 编码get_dummies(sr, prefix='')# 查看每个分组的情况sr.value_counts() 合并1234# 按位置拼接，如果按列拼接，要字段一致pd.concat([data1, data2], axis=1)# 按索引合并，on 索引，inner 内连接pd.merge(left, right, how='inner', on=['字段1', '字段2']) 交叉表与透视表用于探索两个变量的关系。 交叉表：用于查看两列数据之间的关系 1pd.crosstab(data['字段1'], data['字段2']) 透视表：也是用于查看两列数据之间的关系 1pivot_table(data['字段1'], data['字段2']) 分组与聚合123# 根据字段1分组，根据字段2聚合data.groupby(by="字段1")['字段2'].max()data['字段2'].groupby(col["字段1"]).max() 常用库科学计算数据收集Beautiful Soup是一个HTML和XML解析器，可为被解析的页面创建解析树，从而用于从web页面中提取数据。从网页中提取数据的过程称为网页抓取。 安装方法1pip install beautifulsoup4 操作指南 Scrapy是一个用于大规模网页抓取的框架。 安装方法1pip install scrapy 操作方法 Selenium是一个倍受欢迎的自动化浏览器工具。在业界常用于测试，但对于网页抓取也非常方便。 操作方法 数据清零与操作Pandas是用Python语言编写的，主要用于数据操作和数据分析。 安装方法1pip install pandas 操作方法1 操作方法2 PyOD用于处理异常值。 安装方法1pip install pyod 操作方法 NumPy可进行高速多维数组运算。 安装方法1pip install numpy Spacy是一个非常有用且灵活的自然语言处理( NLP )库和框架，用于清理创建模型的文本文档。与类似用途的其他库相比，SpaCy速度更快。 安装方法12pip install -U spacypython -m spacy download en 操作方法 数据可视化Matplotlib是Python中最流行的数据可视化库。 安装方法1pip install matplotlib 操作方法 Seaborn是另一个基于matplotlib的绘图库。它是一个为绘制有吸引力的图像而提供高级接口的python库。matplotlib能实现功能，Seaborn只是以另一种更吸引人的视觉方式来实现。 安装方法1pip install seaborn Bokeh是一个面向现代网页浏览器的交互式可视化库，为大量数据集提供优美的通用图形结构。 安装方法1pip install bokeh 操作方法 建模Scikit-learn是Python构建模型中的佼佼者。支持在机器学习中执行的不同操作，如分类、回归、聚类和模型选择等。 操作方法 TensorFlow由谷歌开发，是一个流行的深度学习库，可帮助构建、培训不同模型。是一个开放源码的端到端平台。TensorFlow提供简单的模型构建，强大的机器学习生产，以及强大的实验工具和库。 安装方法 操作方法1操作方法2 PyTorch是一个基于Python的科学计算包，是NumPy的替代品，可使用GPU的强大功能。 · 深度学习研究型平台，拥有最大灵活性和最快速度 安装方法 操作方法1操作方法2 模型解释Lime是一种算法（库），可以解释任何分类器或回归量的预测。 安装方法1pip install lime 操作方法 H2O自动化机器学习的市场领导者。提供简单的数据可视化技术，用于表示高度特征交互和非线性模型行为，通过可视化提供机器学习可解释性（MLI），说明建模结果和模型中特征的影响。 操作方法 语音处理Librosa是一个用于音乐和音频分析的Python库。它提供了创建音乐信息检索系统所需的构建块。 安装方法 操作方法 Madmom是一个用于音频数据分析的很棒的Python库。它是一个用Python编写的音频信号处理库，主要用于音乐信息检索（MIR）任务。 安装方法：依赖Numpy，Scipy，Cython，Mido1pip install madmom 测试依赖：PyTest，Fuaudio，PuFftw 操作方法 pyAudioAnalysis是一个用于音频特征提取、分类和分段的Python库，涵盖广泛的音频分析任务，例如： 对未知声音进行分类 检测音频故障并排除长时间录音中的静音时段 进行监督和非监督的分割 提取音频缩略图等等 安装方法：1pip install pyAudioAnalysis 图像处理OpenCV-Python是用于图像处理的Python API，结合了OpenCV C ++ API和Python语言的最佳特性。主要用于解决计算机视觉问题。 安装方法：1pip install opencv-python 操作方法1操作方法2 Scikit-image是另一个用于图像处理的python库，是用于执行多个不同图像处理任务的算法集合。可用于图像分割、几何变换、色彩空间操作、分析、过滤，形态学、特征检测等等。 安装方法：依赖Numpy，Scipy，Joblib1pip install -U scikit-learn Pillow是从PIL（Python Imaging Library）派生出来的，在一些Linux发行版（如Ubuntu）中被用作原始PIL的替代。 安装方法：1pip install Pillow 操作方法 数据库Psycopg是Python编程语言中最流行的PostgreSQL（高级开源代码关系数据库）适配器。 安装方法：1pip install psycopg2 SQLAlchemy是最流行的数据库语言。SQLAlchemy是pythonSQL工具包和对象关系映射器，它为应用程序开发人员提供了SQL的全部功能，且极具灵活性。 安装方法：1pip install SQLAlchemy 模型部署Flask是一个用Python编写的Web框架，广泛用于部署数据科学模型。 操作方法 其他下面的网站包含了字符编码，文件处理，图像处理，游戏与多媒体，大数据与科学计算，人工智能与机器学习，系统与命令行，数据库，Web框架，安全，GUI库等相关内容。 其他库参考]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker 入门]]></title>
    <url>%2F2020%2F02%2F04%2FDockerFirst%2F</url>
    <content type="text"><![CDATA[Docker 准备工作Docker PlaygroundDocker Playground 这是一个不用下载的，在线就可以用的Docker。使用需要使用Docker的账号密码，可以去注册一个。 下载 DockerDocker分为社区版和企业版。这里主要介绍社区版。 进入官方DockerToolbox下载页面，按照安装教程安装Docker Toolbox。 国内阿里云[DockerToolBox下载页面](http://mirrors.aliyun.com/docker-toolbox/windows/docker-toolbox/DockerToolbox-18.03.0-ce.exe)，如果官方的速度太慢，可以切换到这里。这里的Docker不是最新版的。 其他下载页面，包含Ubuntu下的一键安装脚本。 安装过程会自动安装VirtualBox，Dokcer，Docker-compose以及Kitematic。 Docker 容器查询Docker 官方文档W3C Docker 参考文档 配置 Docker使用Docker，Docker会默认为我们创建一个虚拟机，下载的Image也都会存储在虚拟机中。默认情况下，虚拟机会存储在用户文档下的.docker目录下。若想改变虚拟机默认存储，可以配置环境变量MACHINE_STORAGE_PATH即可。 （如果遇到Waiting for an IP无限等待，可能是OpenSSH的问题，这个是Win10上内置的功能） 运行桌面上的Docker Quickstart Terminal，首次启动Docker会为我们创建一台虚拟机，并在这个虚拟机目录下创建配置文件。打开配置文件（如果修改过就去改后的目录找）：1C:\Users\用户名\.docker\machine\machines\default\config.json 在HostOptions-&gt;EngineOptions-&gt;RegistryMirror中配置为： 123&#123; "RegistryMirror": ["https://sfpj1t4c.mirror.aliyuncs.com"],&#125; 此处的镜像地址最好是到阿里云找一个。登录阿里云，点击产品与服务，选择容器镜像服务-&gt;镜像中心-&gt;镜像加速器。 配置完成后，重新运行桌面上的Docker Quickstart Terminal。 首次使用 Docker首先进入Docker Quickstart Terminal后，在项目目录执行如下内容，用来测试docker是否正常。 1docker run ubuntu:16.04 /bin/echo "Hello world" 提示Hello World说明配置成功。 Docker 安装了什么安装完成后，我们来简单梳理一下都做了什么。 Docker在我们的电脑上安装了： VirtualBox：虚拟机工具。 Docker Machine：虚拟机管理工具。 Docker Compose：Docker脚本执行工具。 Docker Client 完成安装后，首次运行Docker Quickstart Terminal，Docker就会创建一个虚拟机，作为我们的Docker Server，而我们的本地系统则成为了Docker Client。 之后我们使用的容器将全部运行在这个虚拟机中。查看虚拟机的IP可以使用命令： 1docker-machine env Ubuntu 下的 Docker如果图个方便，那么直接安装：1sudo apt-get install -y docker.io containerd runc docker-compose 如果想去官方下载最新版，那么可以按照官方的程序来一遍。 Docker for Linux安装方法 按照官网给出的安装方法安装Docker。此外，官网还给出了下载Docker包安装和卸载Docker的方法。 12345678910111213141516171819202122232425262728293031323334353637383940# 首先删除旧版本sudo apt-get remove docker docker-engine docker.io containerd runc# 更新下载源sudo apt-get update# 配置aptsudo apt-get install -y \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common# 添加Docker源秘钥curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 添加秘钥sudo apt-key fingerprint 0EBFCD88# 添加Docker源sudo add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable"sudo apt-get update# 安装 Docker Communitysudo apt-get install -y docker-ce docker-ce-cli containerd.io# 如果想要安装其他版本，可以尝试下面的操作# 列出可以按照的Docker Community版本apt-cache madison docker-ce# 选择一个版本安装Docker Community，注意替换下面&lt;...&gt;内容sudo apt-get install -y docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io# 安装完成，测试安装结果sudo docker run hello-world 修改Docker配置文件： 在/etc/docker/daemon.json中增加如下内容：123&#123; "registry-mirrors": ["https://sfpj1t4c.mirror.aliyuncs.com"]&#125; 此处的镜像地址最好是到阿里云找一个。登录阿里云，点击产品与服务，选择容器镜像服务-&gt;镜像中心-&gt;镜像加速器。 Docker 原理与架构Docker 是一个平台，它通过Docker Engine把底层的设备与上层应用隔离开。Docker Engine是一个后台进程，即是一个REST API Server，它还有一个CLI接口（docker）。 Docker 包含 Client 与 Server 。Docker Client 通过命令方式控制 Docker Server，在Server上操作Container，Image等。Docker Server通过代码仓库或Docker Hub获取Docker镜像。 Docker ImageImage 本身是只读的。Docker搭建的应用的过程就是将几个Image一层一层叠加上去的过程。例如在Ubuntu Image层上叠加Apache Image层，在上面再叠加一个PHP Image层，就可以实现一个网站。Image之间可以共享同一层，例如Apache与MySQL可以在同一层上。 使用 Image1234567891011# 查看 imagedocker image ls# 删除 imagedocker image rm image_id# 获取 imagedocker pull ubuntu:14.04# 通过 Dockerfile 创建 image -t 表示 Tag . 表示当前目录docker build -t author/name:version . 如果要查询Image，可以去Docker Hub上查找。 创建 Image如果想要自己创建一个Base Image，可以这样做。 例如我们编写一个 c 程序。1vim main.c 编辑程序代码：123456#include &lt;stido.h&gt;int main(int argc, char* argv[])&#123; printf("hello\n");&#125; 编译程序：1gcc -static main.c -o main 执行程序查看效果：1./main 编写Dockerfile文件：1vim Dockerfile 1234# scratch 表示没有BaseFROM scratchADD main /CMD ["/main"] 构建运行Image：123456# 构建docker build -t author/image_tag .# 查看Image层数docker history image_id# 运行docker run author/image_tag 删除 Image删除Image：12docker image rm image_iddocker rmi image_id Docker ContainerContainer 是一种可读可写的层。我们在运行一个Image时，Docker会在这个Image上添加Container层，用于读写程序运行时产生的数据。 我们也可以把Container与Image类比成对象和类。Image只读，负责存储app，可以当做是一个类；Container则是负责运行app，可以当做是一个对象。 使用 Container运行一个Image，就创建了一个Container。Container在运行完成后就会退出。 1docker run ubuntu 运行完成后：123456# 查看所有容器，-a 表示包括已经结束运行的docker container ls -a# 或docker ps -a# 只显示container iddocker container ls -aq 使用如下命令可以进入容器内做交互，注意，这里的所有数据会在Container结束运行时消失：12# -i 表示交互 -t 表示标准输入输出docker run -it ubuntu 删除Container：1234567docker container rm container_id# 或docker rm container_id# 批量删除所有containerdocker rm $(docker container ls -aq)# 批量删除所有退出的containerdocker rm $(docker container ls -f "status=exited" -q) 当我们在container中产了数据，做了某些操作，我们就可以通过commit方式将修改后的contianer变为image。 从Container创建Image12345docker container commit # 同docker commit# 例如docker commit contaienr_name image_name 我们也可以从Dockerfile创建container。首先创建一个空的目录，这个目录下的除配置文件外的所有文件将会被打包进入image。我们创建一个配置文件Dockerfile： 12FROM ubuntuRUN sudo apt-get install -y vim 执行命令打包：1234docker container build # 同 docker build# 例如docker build -t image_name . 进入运行中的container：1234# 进入命令行docker exec -it container_id /bin/bash# 显示ipdocker exec -it container_id ip a 停止container：1docker stop container_id 运行时给container命名：1docker run -d --name=demo image_name 这样就可以不用再操作container_id了，而是可以直接操作name。 查看container信息：1docker inspect container_id 查看container输出信息：1docker logs container_id 上传自制 Image首先注册登录Docker，并进入Docker Hub。 在本地命令行：12345# 登录账号docker login# 推送 imagedocker push author/image:latest# 被推送的image必须是 author/image:latest 格式，否则没有权限推送 进入Docker Hub就可以看见自己推送的Image了。 也可以让Docker与Github关联。在Docker页面，Create，Create Automated Build里面，选择Link Accounts关联Github。在Github里创建Repository，将Dockerfile上传到代码仓库。Docker的服务器会帮我们Build镜像。 如果要搭建自己的Image仓库，可以在Docker hub里面搜索registry，按照里面的教程操作即可。 打包一个Python程序到Image创建一个Python脚本首先创建Docker打包目录，在目录下创建文件app.py： 1234567from flask import Flaskapp = Flask(__name__)@app.route('/')def hello(): return "hello docker"if __name__ == '__main__': app.run() 创建一个 Dockerfile再创建Dockerfile： 1234567FROM python:2.7LABEL maintainer="Author"RUN pip install flaskWORKDIR /appCOPY app.py /app/EXPOSE 5000CMD ["python", "app.py"] 创建 Image123docker build -t author/image_name .# -d 参数后台执行docker run -d author/image_name 如果创建失败，遇到bug想要调试，可以查看build日志，找到最后一个创建成功的Step，复制其id，并通过命令进入bash环境： 1docker run -it id /bin/bash Docker 压力测试进入docker容器中：1docker run -it ubuntu 安装stress工具：1sudo apt-get update &amp;&amp; sudo apt-get install -y stress 使用stress：123456# vm Worker数 # verbose 打印日志# 功能：反复分配释放内存，默认256MBstress --vm 1 --verbose# vm-bytes 申请释放内存大小 或使用Dockerfile1234FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y stressENTRYPOINT ["/usr/bin/stress"]CMD [""] # 从命令行接受参数 12docker build -t image_tag .docker run -it image_tag --vm 1 --verbose 创建一个常开的Container使用busybox这个Image，可以创建一个常开的Container：1docker run -d --name test busybox /bin/sh -c "while true; do sleep 3600; done" 限制Container资源在开启Container时，可以通过添加参数限制Container的资源，包括cpu个数，内存大小等：1234# --memory 内存 --cpu-shares cpu相对占用docker run --memory=200M --cpu-shares=10 image_tag --vm 1 --cpu 1 --verbosedocker run --memory=200M --cpu-shares=5 image_tag --vm 1 --cpu 1 --verbose# 想当与2:1占用一个cpu Docker Network单机Network有三种模式： Bridge Network Host Network None Netw 多机Network有 Overlay Network。 手工配置 Linux Network 命名空间Network命名空间（Namespace）是一种虚拟化技术，它可以将一个物理机虚拟化成多个虚拟机。一个命名空间相当于一个虚拟主机。我们可以通过配置命名空间下的虚拟端口，可以完成虚拟机，也就是命名空间中的网络连接。这也是docker容器的底层技术。 Linux的Network命名空间有关命令： 123456789# 查看所有命名空间sudo ip netns list# 添加命名空间sudo ip netns add net_test1# 删除命名空间sudo ip netns delete net_test1# 查看命名空间下的IPsudo ip netns exec net_test1 ip a# 会看到该命名空间下的IP没有任何启动的虚拟网卡 配置虚拟网络的过程如下：123456789101112131415# veth即为端口，首先创建一对连起来的端口sudo ip link add veth_test1 type veth peer name veth_test2# 将端口添加到命名空间中。sudo ip link set veth_test1 netns net_test1sudo ip link wet veth_test2 netns net_test2# 为端口分配IP地址sudo ip nets exec net_test1 ip addr add 192.168.1.1/24 dev veth_test1sudo ip nets exec net_test2 ip addr add 192.168.1.2/24 dev veth_test2# 启动命名空间网络sudo ip netns exec net_test1 ip link set dev veth_test1 upsudo ip netns exec net_test2 ip link set dev veth_test2 up# 查看结果sudo ip netns exec net_test1 ip linksudo ip netns exec net_test2 ip link# 会看到网络已经启用了，两个Network命名空间也连起来了 Bridge NetworkBridge Network 原理探索 查看Linux本机IP：1ifconfig 可以看到docker0网桥，veth453e607端口以及其他的网络设备。其中： docker0：是一个网桥，是Docker服务端上用于连接其他设备的端口。 veth…：是Docker Container上的端口。它是成对出现的，而它的另一端连接到docker0上。 可以使用下面的工具查看这个拓扑结构。12sudo apt-get install -y bridge-utilsbrctl show Bridge Network 使用查看所有的Docker网络：1docker network ls 我们这里创建两个容器，并让第二个通过桥接方式连接到第一个容器上。 1234docker run -d --name test1 busybox /bin/sh -c "while true; do sleep 3600; done"# 使用 --link 连接到另一个容器docker run -d --name test2 --link test1 busybox /bin/sh -c "while true; do sleep 3600; done"# link 命令并不常用 这样test2就可以直接通过hostname访问test1，但是test1无法通过hostname访问test1。但是二者可以通过IP访问。 另外，我们也可以通过network方式连接两个容器。创建好的容器默认连接到bridge上。我们新建一个bridge，并让两个容器联入新的bridge。12345678910# 创建网桥docker network create -d bridge test_bridge# 查看网桥docker network ls# 新建容器并联入网桥docker run -d --name test3 --network test_bridge busybox /bin/sh -c "while true; do sleep 3600; done"# 对已经有的容器联入网桥docker network connect test_bridge test2# 查看连接状态docker network inspect netword_id 之后，我们还要将端口映射出来。 新建一个Nginx服务器用于测试。12# 将本地8030端口映射到容器的80端口docker run --name web -d -p 8030:80 nginx 访问本地8030端口即可查看。 Host NetworkHost网络是与主机共享一个Network命名空间。启动一个连接Host网络的容器：1docker run -d --name test4 --network host busybox /bin/sh -c "while true; do sleep 3600; done" 这样的容器将直接使用主机上的端口工作。 None NetworkNone网络是一个孤立网络。启动一个连接None网络的容器：1docker run -d --name test6 --network none busybox /bin/sh -c "while true; do sleep 3600; done" 这个容器将不接入任何网络。 Overlay Network通过Overlay Network可以实现不同物理机上的Docker容器通信，Docker通过VXLAN技术实现了Docker容器在不同物理机上的通信。这里可以使用etcd实现分布式存储，用于辅助Overlay网络。 使用方法：1docker network create -d overlay network_name 这样不论在哪个物理机上操作Docker，都操作的是同一个服务，也就是两台物理机上使用的同一个Docker。 Docker 数据持久化Data VolumeVolume有两种，一种是作为本地文件存储的Volume，另一种是通过第三方插件，如NAS，AWS等。 创建的Volume有两种，一种是作为Docker对象呈现，可以用命令查看：1docker volume ls 另一种是直接挂在到本地目录。 对于前者，首先使用Dockerfile定义Volume： 1VOLUME ["/var/lib/mysql"] 创建的时候再指定参数：1docker run -d --name mysql_test -v mysql:/var/lib/mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql Bind Mouting这种模式不必创建Volume，而是可以直接使用，也就是将目录挂载到本地，实现目录的同步： 123docker run -v /home/aaa:/root/aaa# 例如docker run -d 80:80 -v $(pwd):/usr/share/nginx/html --name web nginx Docker ComposeDocker Compose可以通过脚本快速搭建容器集群，适用于开发环境。 一个例子12345678docker run -d --name mysql-test -v mysql-data:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=root \-e MYSQL_DATABASE=wordpress \mysqldocker run -d --name wordpress-test \-e WORDPRESS_DB_HOST=mysql-test:3306 \--link mysql -p 8080:80 wordpress 简介Docker Compose相当于一个批处理工具，可以定义，管理多个docker应用。 Docker Compse有三大概念： Services：代表一个容器，可以指定Network和Volume。 Network： Volumes： 使用方法12345678910111213141516171819202122232425262728293031323334353637383940version: "3"services: db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - back-tier worker: build: ./worker ports: - 8080:80 environment: ENV_A: value_a links: - db - redis # 不用links，可以用networks networks: - back-tier worker_2: build: context: . dockerfile: Dockerfile ports: - 8000:5000 environment: ENV_B: value_bvolumes: db-data:networks: back-tier: driver: bridge front-tier: driver: bridge 12345678910111213141516# 启动一个脚本docker-compose -f docker-compose.yml up# 如果脚本文件名就是docker-compose.yml，可以简写：docker-compose up# 后台执行docker-compose up -d# 查看服务docker-compose ps # 停止服务docker-compose stop# 启动服务docker-compose start# 停止并删除服务docker-compose down# 进入服务docker-compose exec name bash 弹性伸缩当我们需要做负载均衡时，可以使用伸缩的功能创建多个Web服务器，并用redis来存储客户的sessions。我们可以设计如下的架构： 负载均衡器 $\begin{Bmatrix}Web服务 1 \Web服务 2 \Web服务 3 \\end{Bmatrix}$Redis数据库 命令行方式创建多个服务： 1docker-compose up --scale service_name=3 -d 使用脚本方式创建负载均衡器，多个Web服务，以及Redis数据库： 123456789101112131415161718192021version: "3"services: redis: image: redis web: build: context: . dockerfile: Dockerfile environment: REDIS_HOST: redis lb: image: dockercloud/haproxy links: - web port: - 8080:80 volumes: - /var/run/docker.sock:/var/run/docker.sock 启用脚本： 1docker-compose up 将web服务增加到3个： 1docker-compose up --scale web=3 -d Docker SwarmDocker Swarm可以快速搭建容器集群，适用于生产环境。在生产环境中，为了保障服务的正常使用，我们决不能停止当前的服务。不仅如此，我们还需要实时监控服务的状态，甚至在宕机时能够自动恢复。另外，服务还要有足够的安全性，防止数据泄露，扛得住网络攻击。 Swarm 架构 在Swarm中有两种角色。一种是Worker，一种是Manager。Manager是管理Worker的节点，可以有多个，且他们之间数据可以同步，同步使用Raft，。Worker是处理数据的节点，也可以有多个，他们之间通过Gossip network通信。 在Swarm中还定义了Service与Replicas。Service代表了一种服务，而Replicas则是服务下属的节点，一个服务可以有多个下属的节点。每一个Replica是一个容器。 创建集群首先创建三台虚拟机，命名为Manager，Worker1，Worker2。 12345678# 创建虚拟机docker-machine create swarm-managerdocker-machine create swarm-worker1docker-machine create swarm-worker2# 查看虚拟机IP，例如得到ManagerIP为192.168.205.10docker-machine ls# 登录Managerdocker-machine ssh swarm-manager 在Manager节点上执行： 1docker swarm init --advertise-addr=192.168.205.10 之后会返回一条指令，这条指令是给要加入Manager的Worker节点使用的： 1docker swarm join --token SWMTKN-1-3cv6sadfwe...asfwef 192.168.205.10:2377 进入Worker1节点，执行刚刚得到的指令，即可加入集群。 在Manager节点可以查看Worker情况： 1docker node ls 横向扩展横向扩展是指通过创建多个服务来做负载均衡，以保证服务的可靠性。依然是上面的三个虚拟机的集群，在Manager上搭建服务： 1docker service create --name demo busyBox sh -c "while true; do sleep 3600; done" 查看刚刚搭建的服务： 1docker service ps demo 可以看到一个REPLICAS属性，这个属性就是扩展的节点数。下面我们扩展这个服务： 1docker service scale demo=5 再次查看操作结果： 1docker service ps demo 会发现5个服务被平均分配到3台虚拟机上了。如果某个服务宕机了，Swarm会自动新建一个节点，修复集群。 停止服务： 1docker service rm demo 在线更新为了保证更新过程，服务不宕机，Swarm提供了动态更新的功能。 首先创建一个overlay网络： 1docker network create -d overlay demo 在这个网络上创建一个服务，这个服务是一个旧版的Nginx，一会我们通过动态更新换为最新版Nginx。更新之前，首先保证服务节点数大于一个： 12docker service create --name web --publish 8080:5000 --network demo nginx:1.16.1docker service scale web=4 更新Image： 1docker service update --image nginx:latest web 更新端口： 1docker service update --publish-rm 8080:5000 --publish-add 8088:5000 web 在更新过程中，会有旧版和新版同时服务的状况。 搭建WordPress使用WordPress，需要有WordPress和MySQL两个服务。 首先在Manager节点，创建Overlay网络： 1docker network create -d overlay demo 创建服务： 123456789101112docker service create --name mysql \--env MYSQL_ROOT_PASSWORD=root \--env MYSQL_DATABASE=wordpress \--network demo \--mount type=volume,source=mysql-data,destination=/var/lib/mysql \mysqldocker service create --name wordpress -p 80:80 \--env WORDPRESS_DB_PASSWORD=root \--env WORDPRESS_DB_HOST=mysql \--network demo \wordpress 之后三个节点的IP地址都可以访问WordPress服务了。 DNS 服务在Docker内部拥有一个DNS服务，这个服务维护了每一个服务以及其服务IP。如果这个服务有3个节点，那么这个服务就会另外有3个IP，对应3个容器的IP。也就是说，这个服务一共有4个IP：1个虚拟的IP用于对外提供服务，这个IP会保持不变；另外还有3个用于对应容器，可以随时扩展收缩。 我们可以通过访问虚拟机集群，不论访问哪个虚拟机的IP，都能访问容器中的服务。在这个过程中，Docker DNS会自动为我们寻找需要的服务和它的虚拟IP。但是我们请求这个服务，最终会看到容器所在的虚拟机的主机名。 对比Docker Overlay网络，Overlay实现了多个虚拟机之间的容器通信，使用的技术是VXLAN Tunnel；而服务之间则是通过虚拟IP，基于Docker DNS通信，使用LVS（Linux Virtual Server）技术。 使用 Stack 通过 Docker Compose 部署服务使用Stack通过Docker Compose更新服务，首先要确保image不能是在本脚本build，而是必须使用已经build好的image。 deploy属性指定了更新的策略，包括部署数量，部署方式等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950version: "3"services: redis: image: redis:alpine ports: - "6379" networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: web networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager]networks: frontend: backend:volumes: db-data: 使用docker compose脚本搭建的集群，需要脚本中包含deploy属性，并使用docker stack使用与更新服务： 12345678# 部署服务docker stack deploy example --compose-file=docker-compose.yml# 查看服务docker stack ls# 查看服务情况docker stack services example 最后删除服务： 1docker stack rm example 另外推荐一个服务visualizer，可以可视化查看集群中每个虚拟机上的容器状况。 如果更新服务，可以直接修改docker compose文件，然后重新部署：1docker stack deploy example --compose-file=docker-compose.yml Secret 管理在生产环境中，用于管理系统的密码一般不会明文写到docker compose中，而是使用一些手段隐藏起来。 因此用到Secret管理。这里的Secret管理主要包括： 用户名/密码 SSH Key TLS 认证 机密数据 在Manager节点中，有一个内置的分布式存储。在这个存储中我们就可以存储我们的Secret。当Worker上有容器想要使用时，就可以请求分布式存储获取Secret。 首先创建一个文件password.txt，将我们的密码写到这个文件中。创建一个Secret： 1docker secret create demo-password password.txt 之后删掉password.txt。 查看创建的Secret：1docker secret ls 不创建文件而直接创建Secret也可以，通过管道的方式即可： 1echo "admin123456" | docker secret create demo-password2 删除Secret可以： 1docker secret rm demo-password2 使用Secret：1docker service create --name client --secret demo-secret busybox sh -c &quot;while true;do sleep 3600;done&quot; 在容器的/run/secrets/下可以看到刚刚的secret，是可以看到密码原文的。在MySQL中，可以使用MYSQL_ROOT_PASSWORD_FILE指定密码文件。 在compose中也可以使用Secret。 123456789101112131415161718version: "3"services: image: mysql secrets: - demo-password environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/demo-password volumes: - mysql-data:/var/lib/mysqlvolumes: mysql-data:# 不推荐下面的创建方法，而是推荐命令行管道方式创建Secretssecrets: demo-password: file: ./password KubernetesKubernetes，简称k8s，也是容器编排工具，功能上与Swarm相同。在前期时，Docker一直以Swarm为主，后面将逐步过渡至k8s上。 Kubernetes由谷歌制作，因此国内可能会无法访问。 Kubernetes的重要人物，通过该页面可以查看一些关于Kubernetes的介绍。 Kubernetes Playground，通过该页面可以不安装Kubernetes就可以使用。 架构 Kubernetes也分为两种角色：Master节点与Node节点。 Master主要包含： API Server：是外界访问集群的接口； Scheduler：是均衡调度容器的模块； Controller：控制容器的伸缩； etcd：分布式存储。 Node主要包含： Pod：是调度的最基本单位，是具有相同（network） namespace的容器的组合。 Docker：也可以使用其他容器技术，这里使用Docker。 kubelet：是Master控制节点的接口，负责管理Pod。 kube-proxy：负责负载均衡，端口转发等功能。 Fluentd：查询与采集日志。 Optional Add-ons: DNS, UI, etc. 另外还有Image Registry负责保存Image。 创建单节点Kubernetes集群Minikube：安装教程使用教程示例 其他参考：Ubuntu 安装 KVM安装kubectl工具 以下过程为基于Ubuntu的，其他系统自行参考。 首先安装kubectl工具： 1234567891011# 下载kubectl工具（注意有Google，你懂）curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl# 修改为可执行文件chmod +x ./kubectl# 将文件放置到环境变量bin中sudo mv ./kubectl /usr/local/bin/kubectl# 查看版本信息kubectl version --client 可以使用Minikube创建单节点Kubernetes集群。首先安装Minikube（Ubuntu）： 123456789101112131415# 下载安装Minikubecurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \ &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikube# 查看是否支持虚拟化egrep -q 'vmx|svm' /proc/cpuinfo &amp;&amp; echo yes || echo no# 使用VirtualBox作为驱动启动集群minikube start --vm-driver=virtualbox# 配置VirtualBox为默认驱动minikube config set vm-driver virtualbox# 也可以使用KVM作为驱动启动集群minikube start --vm-driver=kvm2 下面开始创建单节点集群：123456789101112# 创建集群minikube start# 查看集群配置kubectl config view# 查看context，每一个context表示一种配置kubectl config get-contexts# 配置minikubekubectl config use-context minikube# 查看集群情况kubectl cluster-info# 登录虚拟机minikube ssh PodPod是调度的最基本单位，一个Pod拥有一个IP，并且可以包含Volume，Container等，它们之间可以通过localhost相互访问，就像是一台机器上的两个进程相互访问。 这里创建一个pod_nginx.yml脚本： 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: app: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 80 下面是一些常用命令： 12345678910111213# 创建这个Pod：kubectl create -f pod_nginx.yml# 删除Pod：kubectl delete -f pod_nginx.yml# 查看部署的Pod：# -o wide 可以显示详细信息kubectl get pods -o wide# 进入第一个Pod，-c表示第几个，不加表示默认的第一个kubectl exec -it nginx -c 1 sh# 查看Pod的详细信息kubectl describe pods nginx# 映射集群端口到本地，格式 本地端口:集群端口kubectl port-forward nginx 8080:80 Replicate首先创建一个文件rs_nginx.yml： 1234567891011121314151617181920appVersion: v1# 如果是高版本，可以用ReplicaSetkind: ReplicationControllermetadata: name: nginxspec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 创建Replicate并可以做如下实验： 123456789# 创建Replicatekubectl create -f rs_nginx.yml# 查看Replicatekubectl get rc# 查看内部的Podkubectl get pods# 删除单个Pod，pod_name可以用get pods查看kubectl delete pods pod_name# 删除后会发现会有新的Pod被创建 如果要扩展Pod数量（或收缩Pod数量）：1kubectl scale rc nginx --replicas=4 最后删除Replicate：1kubectl delete -f rc_nginx.yml 关于ReplicaSet，可以参考如下文档：12345678910111213141516171819202122apiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx labels: tier: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: metadata: name: nginx labels: tier: frontend spec: containers: - name: nginx image: nginx ports: - containerPort: 80 扩展的时候使用1kubectl scale rs nginx --replicas=4 DeploymentDeployment指明了我们期望创建的集群，以及相应容器的版本，而其他内容则全部交给Kubernetes来实现。使用Deployment可以实现版本升级。 首先创建deployment_nginx： 123456789101112131415161718192021appVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: container: - name: nginx image: nginx:1.12.2 ports: - containerPort: 80 12345678# 创建kubectl create -f deployment_nginx.yml# 查看deployment，-o wide表示更多信息kubectl get deployment -o wide# 查看ReplicaSetkubectl get rs# 查看Podskubectl get pods 更新升级Deployment： 12345kubectl set image deployment nginx-deployment nginx=nginx:1.13# 再次查看deployment，可以发现nginx已经更新kubectl get deployment -o wide# 查看更新日志kubectl rollout history deployment nginx-deployment 撤销更新1kubectl rollout undo deployment nginx-deployment 创建多节点Kubernetes集群创建多节点Kubernetes集群，可以使用kubeadm，kops或是Tectonic（10 Nodes以内免费）。这里使用Tectonic（基于Vagrant）。 Tectonic官网Tectonic Sandbox Github页 非官方 安装好Tectonic后，配置Tectonic与minikube并存可以到kubernetes官网查看Configure Access to Multiple Clusters。 查看Node：1kubectl get node 可以看到刚刚创建的两个Node，即两个虚拟机。 集群使用的网络插件可以在此页查看。 ServiceService主要有三种类型： ClusterIP：只有集群内部可以访问的IP。 NodePort：可以对外提供访问。 LoadBalancer：由服务商（阿里云，腾讯云）提供，可以让我们将服务交给服务商管理。 ClusterIP12345# 对外暴露Pod端口，默认是ClusterIPkybectl expose pods nginx-pod# 查看服务kybectl get svc# 这样可以在集群内部访问Pod提供的服务 创建文件deployment_python_http.yml： 1234567891011121314151617181920212223apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: service-testspec: replicas: 2 selector: matchLables: app: service_test_pod template: metadata: labels: app: service_test_pod spec: containers: - name: simple-http image: python:2.7 imagePullPolicy: IfNotPresent command: ["/bin/bash"] args: ["-c", "echo \" &lt;p&gt;Hello from $(hostname)&lt;/p&gt;\" &gt; index.html; python -m SimpleHTTPServer 8080"] ports: - name: http containerPort: 8080 创建Department： 123456# 创建Deploymentkybectl create -f deployment_python_http.yml# 创建服务kubectl expose deployment service-test# 查看服务kubectl get svc 下面编辑yml文件，准备更新：1kubectl edit deployment service-test 更改echo内容，保存退出，Pod就被更新了。 12# 删除服务kubectl delete services nginx-deployment NodePort创建文件pod_nginx.yml：12345678910111213apiVersion: v1kind: Podmetadata: name: nginx-pod labels: app: nginxspec: containers: - name: nginx-container image: nginx ports: - name: nginx-port containerPort: 80 创建Pod： 1kubectl create -f pod_nginx.yml 为Pod指定服务： 123kubectl expose pods nginx-pod --type=NodePort# 查看服务kubectl get svc 这样就可以通过Node访问到服务了。但是一但Pod被关闭，服务就无法使用了。因此可以使用下面的方法： 创建service_nginx.yml： 12345678910111213apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: ports: - port: 32333 # 此两处必须介于30000到32768 nodePort: 32333 targetPort: nginx-port protocol: TCP selector: app: nginx type: NodePort 开启服务： 1kubectl create -f service_nginx.yml 之后就可以访问了。 kopskops是Kubernetes自己开发的用于生产环境的工具。 kops Github页面 安装方法：123curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64chmod +x kops-linux-amd64sudo mv kops-linux-amd64 /usr/local/bin/kops 建立集群：1kops create cluster --node-count=2 --name=k8s 删除集群：1kops delete cluster --name=k8s --yes 运维与监控Docker 命令行查看查看容器内状况： 1docker top container_id 查看节点所有容器情况： 1docker stats WeaveScopeWeaveScope Github页面 安装过程：123sudo curl -L git.io/scope -o /usr/local/bin/scopesudo chmod a+x /usr/local/bin/scopescope launch 打开4040端口的页面，即可看到WeaveScope。通过这个页面，我们可以可视化管理容器。 添加其他节点到监控中，要在两个节点都执行：1scope launch node_1_ip node_2_ip DevOps 推荐工具： 代码管理 Github Gitlab 码云 bitbucket 代码持续集成 TravisCI GitlabCI Jenkins 代码测试与检查 Codecov SonarQube GitLabGitLab 官网 GitLab CE 下载页 Ubuntu Ubuntu 安装 Gitlab首先开一台虚拟机，用于安装Gitlab（配置要求：推荐4GB内存）： 123456# 安装必要扩展程序sudo apt-get updatesudo apt-get install -y curl openssh-server ca-certificates# 安装邮件提醒工具sudo apt-get install -y postfix# 在安装过程中会出现配置页面，选择Internet Site，其他默认 下载Gitlab： 安装官方版本：12curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashsudo apt-get install gitlab-ee 安装国内镜像版本（仅限Ubuntu 16.04）：在文件/etc/apt/sources.list.d/gitlab-ce.list中写入：1deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial main 再安装Gitlab：1234# 配置GPG公钥curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/nullsudo apt-get updatesudo apt-get install gitlab-ce 安装完成后配置GitLab： 12# 配置GitLabsudo gitlab-ctl reconfigure 安装完毕后，首次登陆需要设置密码。 配置GitLab，可以到/etc/gitlab/gitlab.rb文件中： 12# URLexternal_url '' 修改完成后，让配置生效：1sudo gitlab-ctl reconfigure GitLab CI/CDCI是代码持续化工具，可以在代码提交后自动化执行代码风格检查，单元测试，项目编译等。当然也可以用Jenkins代替。 安装 Runner另开一台虚拟机，首先安装Docker： 1curl -sSL https://get.docker.com/ | sh 安装Gitlab CI Runner：123curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | sudo bashsudo apt-get install -y gitlab-ci-multi-runner 检查是否安装成功：1sudo gitlab-ci-multi-runner status 设置Docker权限：123sudo gpasswd -a gitlab-runner dockersudo service docker restartsudo gitlab-ci-multi-runner restart 注册Runner：12345678910sudo gitlab-ci-multi-runner register# 1. 输入 gitlab_ci 的URL# 2. 输入gitlab-ci的token# 2.1 进入gitlab中随便打开一个Repository-&gt;Setting-&gt;CI/CD# 2.2 进入Runners settings-&gt;Setup a specific Runner manually，复制Token# 3. 输入描述，保存默认即可# 4. 输入Runner Tags，例如demo,test等# 5. 是否Run Untagged builds，false# 6. 是否Lock Runner to current project，false# 7. 选择执行器，shell 查看Runner：1sudo gitlab-ci-multi-runner list 回到Gitlab页面，可以看到runner settings里面多了一个runner。 使用 Runner一个项目要使用Runner，首先需要在项目下建立文件.gitlab-ci.yml。进入一个项目，选择CI/CD-&gt;Pipeline。这时可以看到一个Pipeline。每次提交代码，Pipeline就会自动执行一次，且每一个Stage顺次执行。 使用CI/CD可以自动化执行测试、编译、部署等步骤。 1234567891011121314151617181920212223242526272829# .gitlab-ci.yml# 定义阶段stages: - build - test - deploy# 定义任务 1job1: stage: test # 指定runner tags: - demo script: - echo "First" - echo "Second"# 定义任务 2job2: stage: build tags: - demo script: - echo "Build First" - echo "Build Second"job3: stage: deploy tags: - demo script: - echo "Deploy" 检查代码风格首先注册一个Docker类型的Runner：1234567891011sudo gitlab-ci-multi-runner register# 1. 输入 gitlab_ci 的URL# 2. 输入gitlab-ci的token# 2.1 进入gitlab中随便打开一个Repository-&gt;Setting-&gt;CI/CD# 2.2 进入Runners settings-&gt;Setup a specific Runner manually，复制Token# 3. 输入描述，保存默认即可# 4. 输入Runner Tags，这里是python3.7# 5. 是否Run Untagged builds，false# 6. 是否Lock Runner to current project，false# 7. 选择执行器，docker# 8. 选择Docker Image，python:3.7 提前把Image拉取到本地：1docker pull python:3.7 在项目中加入：12345678910# .gitlab-ci.ymlstages: - stypejob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8 自动化部署CD是持续化部署，即在原来的基础上再进行项目部署。例如有一个项目，经过代码检查后做部署： 12345678910111213141516171819202122# .gitlab-ci.ymlstages: - stype - deployjob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8deploy-job: stage: deploy script: - docker build -t program . - if [$(docker ps -ap --filter name=web)]; then docker rm -f web;fi - docker run -d --name web -p 8030:5000 program tags: - demo # 这个demo是那个runner # 只有master分支变化才执行该job only: - master 如果风格检查不能通过的话，部署是无法进行的。 另外，为了不让用户每一次push代码都触发一次CI/CD，我们可以把master分支锁定住，防止任何人提交。任何人必须在分支中改动。 在Gitlab中配置：Repository-&gt;Protected Branches-&gt;master分支-&gt;Allowed to push 改为No one。 General-&gt;Merge request settings-&gt;Only allow merge requests to be merged if the pipeline succeeds. 用户在提交代码后，进入Gitlab平台，填写Merge Request，等待Pipeline通过。 管理员用户在收到Merge Requst后，则可以执行Merge操作，部署将自动执行。 版本发布首先搭建一个Docker Registry，类似于Docker Hub。 这里创建第三个服务器，作为Docker Host。首先安装Docker，然后执行： 1docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry:2 回到Gitlab-CI服务器上，编辑/etc/docker/daemon.json文件： 123&#123; "insecure-registries": ["Docker_Registry_IP:5000"]&#125; 重启Gitlab-CI服务器上的Docker服务：12sudo systemctl daemon-reloadsudo systemctl restart docker 再从Docker Hub拉取一个镜像： 1234# 拉取busyboxdocker pull busybox# 为其打上标签docker tag busybox Docker_Registry_IP:5000/busybox 再Push到我们的私有仓库：1docker push Docker_Registry_IP:5000/busybox 如果这些步骤成功，则说明配置成功了。 下面修改文件.gitlab-ci.yml，增加一个Release操作： 12345678910111213141516171819202122232425262728293031323334353637# .gitlab-ci.ymlstages: - stype - deploy - releasejob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8 # 当代码库新增一个Tag，该任务不执行 except: - tagsdeploy-job: stage: deploy script: - docker build -t program . - if [$(docker ps -ap --filter name=web)]; then docker rm -f web;fi - docker run -d --name web -p 8030:5000 program tags: - demo only: - master# 增加Release操作release-job: stage: release script: - docker build -t Docker_Registry_IP:5000/demo:$CI_COMMIT_TAG - docker push Docker_Registry_IP:5000/demo:$CI_COMMIT_TAG tags: - demo # 只有代码库新增一个Tag，就会触发一次Release only: - tags $CI_COMMIT_TAG是Gitlab定义的环境变量，是版本的标签，可以通过Git工具提交代码时添加新的Tag。 其他Docker尝试Docker GPU(Docker GPU)[https://blog.opskumu.com/docker-gpu.html] Docker Gitlab(Docker Gitlab)[https://www.jianshu.com/p/080a962c35b6] 安装Gitlab： 1234# 拉取镜像docker pull gitlab/gitlab-ce# 运行容器docker run -d -p 8443:443 -p 8030:80 -p 32222:22 --name gitlab --restart always -v ~/gitlab/config:/etc/gitlab -v ~/gitlab/logs:/var/log/gitlab -v ~/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce 配置Gitlab文件./gitlab/config/gitlab.rb： 123456# 配置http协议所使用的访问地址external_url 'http://192.168.199.231:8030'# 配置ssh协议所使用的访问地址和端口gitlab_rails['gitlab_ssh_host'] = '192.168.199.231'gitlab_rails['gitlab_shell_ssh_port'] = 32222 # 此端口是run时22端口映射的32222端口 配置完成后，重启Gitlab：1docker restart gitlab Docker DNS拉取镜像 1docker pull dns-server 其他机器启动时可以使用参数--dns指定DNS容器。 1docker run --dns=xx.xx.xx.xx images Docker Machine在安装Docker Toolbox时，也自动安装了docker machine。利用docker machine可以创建虚拟机（借助VirtualBox），这个虚拟机小巧且精简，附带Docker，但是功能有限。用户如果想要更全功能的Linux虚拟机，可以使用后面的Vagrant。 创建虚拟机创建虚拟机：1docker-machine create name 常用命令1234docker-machine ls # 列出所有虚拟机docker-machine ssh name # 登录虚拟机docker-machine stop name # 停止虚拟机docker-machine env name # 查看环境变量 切换Docker服务端默认情况下，我们在开机后初次运行Docker Quickstart Terminal时，它就会为我们启动一个虚拟机，这个虚拟机包含了一个Docker Server，所以 这里不必切换Docker服务端 。 利用Docker Machine可以实现切换Docker Server。如果不想把自己本地的计算机搞乱，我们可以直接安装Docker Client，而服务端通过其他方式创建，也可以正常使用。 切换本地Docker服务端首先利用上面的docker-machine命令创建带docker server的虚拟机，然后执行下面的操作。 12345678910111213# 使用命令查看虚拟机的环境变量docker-machine env name# 之后会得到虚拟机的环境变量以及一条命令# eval $(docker-machine env name)# 执行这条语句，我们就切换了Docker服务端eval $(docker-machine env name)# 执行这条语句取消切换docker-machine env --unset# 之后会得到一条命令，我们执行它# eval $(docker-machine env --unset)eval $(docker-machine env --unset) 切换阿里云Docker服务端使用阿里云的ECS，首先得保证账号内有钱。其他云平台道理相同。 官方参考页面 进入官方参考页面，点击第三方驱动插件（3rd-party driver plugins），就可以找到Aliyun ECS（点击进入）。 首先是下载驱动，解压文件，修改得到的文件的后缀为.exe，并将驱动的所在目录添加到环境变量。 打开阿里云平台，管理控制台，访问控制，用户管理，创建AccessKey和Secret。 注意 ：Secret只显示一次，一定要保存好。 回到本地命令行，执行： 123docker-machine create -d aliyunecs --aliyunecs-io-optimized=optimized --aliyunecs-instance-type=ecs.c5.large --aliyunecs-access-key-id=用户ID --aliyunecs-access-key-secret=用户Secret --aliyunecs-region=cn-qingdao 虚拟机name# 这些参数的值可以在阿里云平台上的创建页面查看。 创建好以后，就可以按照上一节的内容切换服务端了。 Vagrant（可选）Vagrant是一个虚拟机管理工具。可以用脚本的方式快速创建虚拟机（需要安装VirtualBox）以及虚拟机集群。如果不想直接在自己的电脑上安装Docker，可以尝试Vagrant。 Vagrant官网Vagrant下载页VirtualBox官网 Vagrant 镜像官方镜像首先进入Vagrant官网，点击Find Boxes，输入要查找的虚拟机。例如输入Unbutu 16.04，搜索后进入，选择New，会出现如下页面： 1234# 创建Vagrantfilevagrant init ubuntu/xenial64# 执行Vagrantfilevagrant up 执行页面中提示的操作，Vagrant会在当前目录创建该虚拟机。 非官方镜像如果上面的过程太漫长，可以自定义添加Box。打开vagrantbox.es，按照上面的提升操作添加虚拟机镜像。 例如： 123vagrant box add ubuntu_new https://atlas.hashicorp.com/envimation/boxes/ubuntu-xenial-dockervagrant init ubuntu_newvagrant up 如果命令行下载速度较慢，可以使用迅雷等工具下载到本地，再使用： 123vagrant box add ubuntu_new /path/to/boxvagrant init ubuntu_newvagrant up Vagrant SSH在虚拟机目录下执行： 1vagrant ssh 即可进入虚拟机。 Vagrant 常用命令12345678910111213141516vagrant box add # 添加一个boxvagrant box list # 列出所有的boxvagrant box remove # 删除boxvagrant init ubuntu/trustry64 # 初始化一个新的虚拟机vagrant up # 启动虚拟机vagrant ssh # 登录虚拟机vagrant halt # 关闭虚拟机vagrant reload # 重启虚拟机vagrant suspend # 挂起虚拟机vagrant resume # 恢复挂起vagrant destory [name|id] # 销毁虚拟机vagrant package # 打包当前虚拟机到boxvagrant global-status # 查看当前所有虚拟机状态vagrant ssh-config # 查看ssh连接信息 Vagrant 配置文件通过编辑脚本也可以利用vagrant同时创建多台虚拟机。 我们在使用之前的方法创建虚拟机时，目录下会自动生成Vagrantfile文件，这就是Vagrant虚拟机的配置文件，里面包含虚拟机的配置，SSH的配置以及Vagrant的基础配置，这些配置是基于Ruby语法的。 单机模式配置： 1234567891011121314151617181920212223# boxconfig.vm.box = "CentOs7"# hostnameconfig.vm.hostname = "for_work"# 虚拟机网络设置# 虚拟机网络有两种连接方式：# 主机模式（host-only），虚拟机只能和主机通信，其他人无法访问到虚拟机。# 桥接模式（bridge），虚拟机成为同主机在同一局域网下的独立主机。config.vm.network "private_network", ip: "192.168.33.10"#config.vm.network "public_network"# 同步目录设置config.vm.synced_folder "/Users/path/www", "/vagrant"# 端口转发设置config.vm.network :forwarded_port, guest: 80, host: 80# 配置多行脚本config.vm.provision "shell", inline: &lt;&lt;-SHELL sudo apt-get updateSHELL 参考脚本配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 例 1：Vagrant.configure("2") do |config| config.vm.define :web do |web| web.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "web", "--memory", "512"] end web.vm.box = "base_box" web.vm.hostname = "web" web.vm.network :private_network, ip: "192.168.33.10" end config.vm.define :redis do |redis| redis.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "redis", "--memory", "512"] end redis.vm.box = "base_box" redis.vm.hostname = "redis" redis.vm.network :public_network, ip: "192.168.33.11" endend# 例 2：Vagrant.require_version "&gt;=1.6.0"boxes = [ &#123; :name =&gt; "node1", :eth1 =&gt; "192.168.205.10", :mem =&gt; "1024", :cpu =&gt; "1", :port =&gt; "8888" &#125;, &#123; :name =&gt; "node2", :eth1 =&gt; "192.168.205.11", :mem =&gt; "1024", :cpu =&gt; "1", :port =&gt; "9999" &#125;]Vagrant.configure(2) do |config| config.vm.box = "base_box" boxes.each do |opts| config.vm.define opts[:name] do |config| config.vm.hostname = opts[:name] config.vm.provider "vmware_fusion" do |v| v.vmx["memsize"] = opts[:mem] v.vmx["numvcpus"] = opts[:cpu] end config.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--memory", opts[:mem]] v.customize ["modifyvm", :id, "--cpus", opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] # config.vm.network :public_network config.vm.network "forwarded_port", guest: 80, host: 8050 end end config.vm.synced_folder "./labs", "/home/vagrant/labs" # 本地需要手动创建同步目录 config.vm.provision "shell", privileged: true, path: "./setup.sh" # 初始化脚本，包括更换源，安装Docker，参考下面的编写end 参考文档 配置一个带Docker的Vagrant虚拟机创建一个目录，并配置如下文件： VirtualBox labs sources.list setup.sh 编辑setup.sh如下：12345678910111213141516171819202122232425262728293031sudo cp /etc/apt/sources.list /etc/apt/sources.list.backsudo rm /etc/apt/sources.listsudo touch /etc/apt/sources.listsudo cp /home/vagrant/labs/sources.list /etc/apt/sources.list sudo apt-get remove docker docker-engine docker.io containerd runcsudo apt-get updatesudo apt-get install -y \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable"sudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.iosudo mkdir -p /etc/dockersudo gpasswd -a ubuntu dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://sfpj1t4c.mirror.aliyuncs.com"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart dockersudo service docker restartsudo reboot 编辑sources.list内容如下（适用于ubuntu 16.04，其他版本可以自行搜索）：123456789101112131415deb http://mirrors.aliyun.com/ubuntu/ xenial maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial maindeb http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 在VirtualBox下执行1vagrant init 会生成Vagrantfile文件。打卡文件，编辑：12345678910# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;box_base&quot; config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8030 config.vm.network &quot;public_network&quot; config.vm.synced_folder &quot;./labs&quot;, &quot;/home/vagrant/labs&quot; config.vm.provision &quot;shell&quot;, privileged: true, path: &quot;./setup.sh&quot;end 保存后：1vagrant up 即可创建虚拟机。输入如下命令登录虚拟机： 1vagrant ssh 安装扩展123456# 查看插件列表vagrant plugin list# 安装插件vagrant plugin install vagrant-scp# 使用 scp 复制文件到虚拟机vagrant scp ../node3/labs/ docker-node1:/home/vagrant/labs/ 参考文档Dockerfile 语法命令 FROM定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 123FROM scratch # 制作base imageFROM ubuntu # 使用base imageFROM ubuntu:14.04 # 使用特定版本的image LABEL相当于注释： 123LABEL maintainer="author@web.com"LABEL version="1.0"LABEL description="The Description" RUN用于执行后面跟着的命令行命令。 123456789101112FROM nginxRUN echo '这是一个本地构建的nginx镜像' &gt; /usr/share/nginx/html/index.html# RUN 有以下俩种格式：# 1. shell 格式：RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。# 2. exec 格式：RUN ["可执行文件", "参数1", "参数2"]# 例如：# RUN ["./test.php", "dev", "offline"] 等价于 RUN ./test.php dev offline 另外，Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 12345678910FROM centosRUN yum install wgetRUN wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz"RUN tar -xvf redis.tar.gz# 以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum install wget \ &amp;&amp; wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz" \ &amp;&amp; tar -xvf redis.tar.gz# 以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 编辑保存之后就可以构建Docker镜像了。1docker build -t nginx:test . CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build用的。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效；如果在docker run中指明了命令，CMD就会被忽略。 12345# Shell 格式CMD &lt;shell 命令&gt; # Exec 格式CMD ["&lt;可执行文件或命令&gt;","&lt;param1&gt;","&lt;param2&gt;",...] CMD ["&lt;param1&gt;","&lt;param2&gt;",...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 ENTRYPOINTENTRYPOINT会让容器以应用程序或服务的方式运行。它类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，此选项的参数可当作要运行的程序覆盖 ENTRYPOINT 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 1ENTRYPOINT ["&lt;executeable&gt;","&lt;param1&gt;","&lt;param2&gt;",...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT ["nginx", "-c"] # 定参CMD ["/etc/nginx/nginx.conf"] # 变参 123456789# 1、不传参运行docker run nginx:test# 容器内会默认运行以下命令，启动主进程。# nginx -c /etc/nginx/nginx.conf# 2、传参运行docker run nginx:test -c /etc/nginx/new.conf# 容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件)# nginx -c /etc/nginx/new.conf WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 12WORKDIR &lt;工作目录路径&gt;WORKDIR /test # 会自动创建 COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 12345678910COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] ["&lt;源路径1&gt;",... "&lt;目标路径&gt;"]# [--chown=&lt;user&gt;:&lt;group&gt;]：可选参数，用户改变复制到容器内文件的拥有者和属组。# &lt;源路径&gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：COPY hom* /mydir/COPY hom?.txt /mydir/# &lt;目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格式一致（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点：在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 12345WORKDIR /rootADD main test/ # /root/test/mainWORKDIR /ROOTCOPY main test/ 如果想要添加远程文件，还是要用命令的方式（curl、wget）较好： ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 1234567891011ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...# 例如ENV NODE_VERSION 7.2.0RUN curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz" \ &amp;&amp; curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc"# 不加/bin/bash，会导致无法识别ENV变量RUN ["/bin/bash", "-c", "echo $ENV_KEY"] ARG构建参数，与 ENV 作用一至。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷，可以通过 -v 参数修改挂载点。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。 12VOLUME ["&lt;路径1&gt;", "&lt;路径2&gt;"...]VOLUME &lt;路径&gt; EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 1EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 1USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这是执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 1ONBUILD &lt;其它指令&gt; 总结 应使用LABEL注明文件作用以及内容； 应使用ENV注明主要变量，方便维护； 应当使用WORKDIR注明工作路径，且推荐使用绝对路径； 应使用COPY为主，需要解压时可以使用ADD； 应当在使用RUN时，尽量合并命令，防止产生多个层； 应当在使用Exec格式时使用”/bin/bash -c”来识别ENV变量，且被执行的指令应放到一起； 参考 菜鸟教程 YAML 语法YAML脚本的后缀为yml或yaml，基本语法如下： 大小写敏感； 使用缩进表示层级关系； 缩进不允许使用tab，只允许空格； 缩进的空格数不重要，只要相同层级的元素左对齐即可； ‘#’表示注释。 YMAL 支持三种数据类型： 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值 YAML 对象对象键值对使用冒号结构表示 key: value，冒号后面要加一个空格。 也可以使用 key:{key1: value1, key2: value2, …}。 还可以使用缩进表示层级关系； 123key: child-key: value child-key2: value2 较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value，意思即对象的属性是一个数组[complexkey1,complexkey2]，对应的值也是一个数组[complexvalue1,complexvalue2]： 123456? - complexkey1 - complexkey2: - complexvalue1 - complexvalue2 YAML 数组以 - 开头的行表示构成一个数组： 123456789101112131415161718192021222324# 多行表示- A- B- C# 行内表示：key: [value1, value2, ...]# 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。- - A - B - C# 一个相对复杂的例子：companies: - id: 1 name: company1 price: 200W - id: 2 name: company2 price: 500W# 也可以表示为companies: [&#123;id: 1,name: company1,price: 200W&#125;,&#123;id: 2,name: company2,price: 500W&#125;] 复合结构数组和对象可以构成复合结构，例： 123456789languages: - Ruby - Perl - Python websites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 纯量 字符串 布尔值 整数 浮点数 Null 时间 日期 表示方法如下 123456789101112131415161718192021boolean: - TRUE #true,True都可以 - FALSE #false，False都可以float: - 3.14 - 6.8523015e+5 #可以使用科学计数法int: - 123 - 0b1010_0111_0100_1010_1110 #二进制表示null: nodeName: 'node' parent: ~ #使用~表示nullstring: - 哈哈 - 'Hello world' #可以使用双引号或者单引号包裹特殊字符 - newline newline2 #字符串可以拆成多行，每一行会被转化成一个空格date: - 2018-02-17 #日期必须使用ISO 8601格式，即yyyy-MM-dddatetime: - 2018-02-17T15:02:31+08:00 #时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 引用&amp; 用来建立锚点，&lt;&lt; 表示合并到当前数据，* 用来引用锚点: 123456789101112131415161718192021222324252627defaults: &amp;defaults adapter: postgres host: localhostdevelopment: database: myapp_development &lt;&lt;: *defaultstest: database: myapp_test &lt;&lt;: *defaults# 相当于defaults: adapter: postgres host: localhostdevelopment: database: myapp_development adapter: postgres host: localhosttest: database: myapp_test adapter: postgres host: localhost 参考 菜鸟教程]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云物联网平台使用]]></title>
    <url>%2F2020%2F02%2F04%2FALI-IOT%2F</url>
    <content type="text"><![CDATA[数据的流程数据从节点设备产生，到用户自己的服务器这一过程，我们把它分为两部分。前半部分是节点设备产生数据，经过网络传递到阿里云物联网平台，这一过程使用MQTT协议。后半部分则有阿里云物联网平台将数据转交给阿里云的其他产品，如用户自己的云平台。 节点接入的两种方式。资源受限的节点设备。使用Paho MQTT Client协议栈接入没有TLS透传模式MQTT通信协议与服务器约定： 消息负载的二进制表达 消息主题 资源丰富的节点设备。使用Linkkit SDK接入FreeRTOS，Json，TLS物模型MQTT通信协议安装物模型规定（解耦设备端与应用端开发） Web 后端基于阿里云物联网平台HTTP/2 SDK订阅设备数据使用SpringBoot + Mybatis轻量级框架可开发服务端逻辑MySQL存储设备数据 Web 前端ReactUmi.js Antd 框架组件dva.js数据管理Bizcharts数据可视化定时向后端请求数据 软件STM32CubeMXIAR Embedded WorkbenchPahoo MQTT Client StackLinkkit C-SDKMbedTLSFreeRTOS JDK 8Intellij IDEANode.jsMySQLNavicat for MySQLVSCodeGit MQTTMQTT 介绍MQTT（消息队列遥测传输）是一种基于TCP开发的协议，工作在应用层，使用异步通信模式，解耦通信双方。 MQTT协议具有许多优点，如可靠性，双向传输性，低开销，有序性，低带宽等，采用发布订阅模式。 MQTT协议中包含了四类关键字。 客户端（client）服务器端/代理（server/broker） 会话（session） 消息（message）主题（Topic） 订阅（subscribe）发布（publish） 角色：代理，负责收发数据；发布者，发布消息到代理；订阅者，订阅消息，接收代理推送的消息。 发布者和订阅者通过不同的Topic进行消息的双向传输。二者可以从Topic中发布和订阅消息。 每个产品会定义Topic类，下属的所有设备都会生成相应的Topic。例如某设备的气压，温度，湿度等Topic。 MQTT 协议格式主题：主题具有层级结构，支持通配符。通配符有单级通配符+与多级通配符#。 连接与会话：连接由客户端发起，服务器根据连接参数（客户端ID，用户名，密码，心跳间隔，消息-主题-遗嘱，会话保持等）对客户端鉴权和授权，连接参数也将决定此次会话是否是持久会话。 MQTT报文格式：固定报头：2~5 Bytes，是所有报文必须包含的（MSB在前，LSB在后）。 4 bits 1 bit 2 bits 1 bit 1 ~ 4 Bytes Message Type UDP QoS Level RETAIN Remaining Length 可变报头：长度由Remaining Length决定； 有效载荷：长度由Remaining Length决定。 Message Type：共14种。UDP，QoS Level，RETAIN：只有PUBLISH报文使用。QoS：0 – 最多收到一次，接收方不产生应答；1 – 最少收到一次，接收方返回PUBACK报文；2 – 保证仅收到一次，且消耗资源较大。RETAIN：当客户端发送的消息中Retain置位，则服务器保留该条消息以及QoS级别，当有新的订阅发生，并与该消息主题一致，服务器就会马上把该Retain置位的消息转发给订阅者（相当于给订阅者写了留言，订阅者一上线就收到了这条消息）。服务器仅保留最近一个Retain置位的消息。删除Retain置位的消息是通过客户端发送一条Payload为空的Retain为空的消息。Remaining Length：决定可变报头与有效载荷的总长度。 CONNECT – 连接报文（0x01）： 可变报头 2 Bytes 4 Bytes 1 Byte 1 bit 1 bit 1 bit 2 bits 1 bit 1 bit 1 bit 2 Bytes 可变报头长度 MQTT 版本（0x03） 用户名Flag 密码Flag Will Retail Will QoS Will Flag Clean Session 保留 Keep Alive Timer 标志位 为 1 时表示负载中包含该部分信息。 负载 1 Byte 1 Byte 1 Byte 1 Byte 1 Byte Client Indentifier Will Topic Will Message 用户名 密码 遗嘱（Will）：是连接服务器时告诉服务器的消息，服务器会保存这些消息。当连接意外断开时，服务器会将遗嘱消息转发给所有订阅该设备上Topic的设备。 SUBSCRIBE – 订阅报文（0x08）： 可变报头 2 Bytes Message ID 负载 2 Bytes N Bytes 6 bits 2 bits Topic name String Length Topic Name 保留 QoS Level QoS Level：作用于服务器到客户端的下行链路。 PUBLISH – 发布报文（0x03）： 可变报头 2 Bytes N Bytes 2 Bytes Topic name String Length Topic Name Message ID 负载 N Bytes Publish Message（可选） QoS Level：作用于客户端到服务器的上行链路。 UNSUBSCRIBE – 取消订阅（0xA）：有可变头部和负载 PINGREQ – 发送心跳（0xC）：无可变头部和负载 DISCONNECT – 断开连接（0xE）：无可变头部和负载 阿里云物联网平台物联网体系应用层应用层主要包括了关于物联网的Web应用，例如智慧交通，智能家居等服务端应用，也包括物联网应用接口。 在阿里云物联网体系中还加入了阿里云物联网平台作为物联网应用的总接口。 网络层终端与应用层的各个应用通信，需要借助网络。例如：2/3/4G，NB-IoT，WiFi，蓝牙，LoRaWAN等。 感知层包括物联网终端设备，例如传感器，芯片，控制器，通信模组等。 平台功能设备接入：支持多种通信协议，提供多种通信协议SDK，即可满足长连接，也满足短连接，提供多种入网接入访问。设备通信：可以实现双向通信。设备管理：支持完整的设备声明周期管理，包括设备注册，功能定义，脚本解析，在线调试，远程配置，固件升级，远程维护，实时监控，分组管理，设备删除等。提供上下线通知，数据存储，OTA升级，设备影子缓存（用于解决不可靠网络通信问题）。安全能力：一机一密的设备认证，安全级别高；一型一密的安全机制，安全级别普通。支持TLS（HTTP，MQTT），DTLS（CoAP），安全级别高；支持TCP（MQTT），UDP（CoAP），安全级别普通。数据转发：可配置规则实现设备与设备的通信；支持消息转发至消息队列，表格存储，流计算，TSDB，函数计算等应用中。 另外还有：服务端订阅设备消息：平台数据可以通过HTTP/2通道至服务器，并提供HTTP/2 SDK，实现数据订阅功能。服务器也可以使用SDK传输数据至平台。 产品产品是设备的集合，指通常具有相同功能的一组设备。每一个产品都有一个ProductKey。 设备归属于某个产品之下，指具体的某一个终端。每一个设备都有一个DeviceName。 设备直连设备直接连接物联网平台。 网关连接网关：网关是可以直接连接物联网平台的设备，可以拥有子设备。网关是代理子设备连接云端的设备。 子设备：只能通过网关连接平台。 三元组平台会为每一台设备分配一个三元组。三元组内容如下：ProductKey：产品标识，在全网具有唯一性。DeviceName：设备标识，仅在产品维度内具有唯一性。DeviceSecret：设备秘钥，与DeviceName成对出现。 认证方案一共有三种认证方案：一机一密：该方案要求设备事先烧录自己的三元组，在建立连接时，设备携带自己的三元组在平台上进行认证，认证通过后才可以传输数据。一型一密：所有设备可以烧录相同的固件（ProductKey和DeviceName），设备在认证通过后接收自己的DeviceSecret。子设备认证：网关联入平台后，子设备的认证方案。 通信模式发布/订阅模式：平台维护所有的Topic的发布/订阅用户列表，当有发布者发布某Topic消息的时候，平台会在用户列表中查询所有订阅者，并将消息下发给订阅某Topic的订阅者。适用于非实时场景。 RRPC模式：基于MQTT协议封装的同步通信模式，服务端下发消息，设备可以同步得到响应。适用于实时场景。 设备声明周期管理创建设备：在平台上创建设备。激活设备：由设备申请激活。启用设备：由平台控制设备的启用。禁用设备：由平台控制设备的禁用。删除设备：在平台上删除设备。 设备状态：可以查看设备是否激活，是否在线等。设备标签：可以查看设备厂商、型号等。 物模型属性：设备运行状态，支持GET与SET服务，应用可以发起对属性的读取和设置请求。服务：设备可以被外部调用的方法，可以设置输入参数与输出参数。事件：设备运行时的事件在感知外部和处理通知消息后等激发，可以包含多个输出参数，如设备故障、完成某任务的消息等。事件可以被订阅和推送。 消息流程终端设备 MQTT协议 阿里云平台 HTTP/2协议 个人服务器 HTTPS/HTTP 浏览器，用户终端 设备管理查看数据：支持一次数据快照与历史数据查看。固件升级：支持OTA升级。 数据传输Alink协议接入：用于设备与云端的双向通信，格式为Json。透传接入：设备直接上传二进制数据，云端对数据进行解析，并转化为Alink协议的格式。 服务端订阅配置HTTP/2服务端订阅后，物联网平台会将消息推送到服务端，服务端通过接入HTTP/2 SDK后就可以接收物联网平台的消息。HTTP/2 SDK提供身份认证，Topic订阅，消息发送和接收的能力，并支持设备接入和云端接入。HTTP/2 SDK即适用于服务端与平台传输大量信息，也支持设备与物联网平台之间的消息传输。 规则引擎当设备基于Topic与平台进行消息通信时，用户可以通过规则引擎实现对设备数据的处理和转发，实现将数据转发至阿里云其他产品中。 转发支持转发到RDS，Table Store，HiTSDB等数据库，DataHub进行流计算、离线计算，函数计算，另一个Topic，消息队列五种形式。 设备端开发设备端开发SDK包含： C SDK Android SDK NodeJS SDK Java SDK Python SDK iOS SDK 云端开发云端开发SDK支持 Java Python PHP .NET。 API 包含： 产品管理 设备管理 分组管理 规则引擎 Topic管理 消息通信 设备影子 温湿度传感器案例功能描述配置一个温湿度检测物联网终端设备，可以监测当前温湿度，可以配置温度阈值，当高于温度阈值时，发出报警。 设备方面： 设备每5秒上报温湿度，闪烁绿灯； 温度超过阈值，亮红灯，并每10秒向用户报警一次； 收到用户解除警报信息后红灯闪烁； 温度正常后，灭掉红灯。 平台方面： 温湿度值转发到用户服务器，同时在Web端显示温湿度曲线； 报警消息转发到用户服务器，在Web端显示； Web页面可以解除警报。 Web页面可以设置阈值。 物模型属性： 当前温度 当前湿度 温度阈值 事件： 属性达到上限 温度超过阈值 服务： 设置阈值 获取属性值 解除警报 项目流程节点方面： 初始化 系统初始化 平台初始化 MQTT连接参数计算 连接阿里物联网平台 订阅相关主题 主循环 MQTT连接是否正常 读取温湿度 判断是否报警 发布设备属性 MQTT订阅回调函数 收到设置阈值Topic消息 更新温度阈值 收到解除警报Topic消息 解除警报 阿里云IoT平台配置打开阿里物联网云平台页面，登录并进入产品管理页面。点击创建产品，选择基础版，输入产品名称，选择设备，认证选择否。 进入设备页面，点击添加设备，输入设备名称，就可以生产三元组了。 回到产品页面，在Topic类列表定义Topic类实现自定义Topic。 在服务端订阅中设置：设备上报消息与设备状态变化通知，点击保存。 服务端应用开发开发流程为： 需求分析：功能、交互 系统设计：UI设计、API设计、数据库设计 编码开发：前端编码、后端编码 联调测试：功能测试、交互测试 系统运维：发布上线、持续运维 后端开发流程 数据库设计 API 约定 后端编写 前后端联调 部署上线运维 框架 MySQL Mybatis：在Java中操作MySQL SpringBoot：整合了MyBatis + SpringMVC等 Maven：跨平台项目管理工具 使用 IoT Studio 快速开发在IoT Studio中，用户可以快速构建Web应用，手机APP，以及后端服务。 进入IoT Studio，选择开发服务，新建项目，在项目产品和项目设备中关联自己的设备。 之后选择Web可视化开发或移动应用开发，编辑相关内容，生成应用程序。例如生成Android App，经过几分钟编译打包后，在移动应用开发界面的设置，构建管理中下载安装APP。]]></content>
      <categories>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>物联网</tag>
        <tag>STM32</tag>
        <tag>阿里云</tag>
        <tag>NodeMCU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 入门]]></title>
    <url>%2F2020%2F02%2F03%2FRedisFirst%2F</url>
    <content type="text"><![CDATA[NoSQLNoSQL是一类新出现的数据库，不支持SQL语法，也不是关系型数据库，而是基于KEY-VALUE方式存储数据。他们没有通用的语言，而是各自有各自的语法和用法。他们往往适用于关系简单，而对事务强的业务有很好的支持。 NoSQL数据库常见的有： Mongodb Redis Hadoop Redis 简介官方网站参考文档 支持数据的持有化 不仅支持key-value，还支持list，set，zset，hash等结构。 支持数据备份 性能极高 拥有丰富的数据类型 操作都是原子性的 Redis常常用来做缓存，其读写效率很高，适用于社交平台等大型系统等。 Redis 安装与配置安装配置打开配置文件redis.conf bind：绑定的IPport：绑定的端口daemonizs：是否为守护进程（改为yes）dbfilename：数据存储文件名dir：存储路径logfile：日志文件database：数据库数量slaveof：设置主从（一般不用） 启动1234567891011121314# 直接运行sudo redis-server /etc/redis/redis.confps -ef | grep redis # 得到PID号sudo kill -9 PID号# 以服务方式运行sudo service redis startsudo service redis stop# 进入redis，默认进入0号数据库redis-cli# redis-cli 命令ping # ping数据库select 5 # 切换数据库 Redis数据类型 string：字符串，可以接受任意二进制数据，最大可容纳512MB。 hash：哈希，用于存储对象，包含属性、值，值的类型为string。 list：列表，每个元素都是string，按照插入顺序排序。 set：集和（无序），元素具有唯一性，且不可修改。 zset：有序集和，元素具有唯一性，且每个元素具有一个权重，并按照权重从小到大排序，也是没有修改操作。 数据操作基本操作123456789# 键命令keys pattern # 支持正则表达式keys * # 查看所有键keys 'a*' # 查看所有a开头的键exists key # 查看是否存在键type key # 查看类型del key # 删除键expire key seconds # 设置过期时间ttl key # 查看键的剩余时间 字符串操作123456789# 保存set key valuesetex key seconds value # 设置过期时间mset key1 value1 key2 value2 # 设置多个键值append key value # 追加值# 获取get key # 如果不存在返回(nil)mget key1 key2 key3 哈希操作12345678910# 设置hset key field value # 设置单个属性hmset key field1 value1 field2 value2 # 设置多个值# 获取hkeys key # 获取属性hget key field # 获取值hmget key field1 field2 # 获取多个值hvals key # 获取所有值# 删除hdel key field1 field2 # 删除属性 执行hset可能会抛出无法保存快照的错误，可以执行如下命令：1config set stop-writes-on-bgsave-error no 列表操作123456789# 插入lpush key value1 value2 # 左侧插入rpush key value1 value2 # 右侧插入linsert key before/after old_key new_key # 在old_key前/后插入数据new_key# 显示lrange key start stop # 从几到几，-1表示最后一个# 修改lset key index value lrem key count value # 删除几个某元素，0表生所有；&gt;0表示从左向右；&lt;0表示从右向左 集和操作123456# 增加sadd key value1 value2 # 获取smmbers key # 获取所有元素# 删除srem key value1 value2 # 删除某些元素 有序集和123456789# 增加zadd key score1 member1 score2 member2# 获取zrange key start stop zrangebyscore key min max # 查看权重在区间的元素zscore key member # 查看权值# 删除zrem key member1 member2zremrangebyscore key min max # 删除权重在区间的元素 与 Pyhton 交互安装Redis包1pip install redis 使用123456789from redis import *# 连接数据库，参数：主机名；端口；数据库编号sr = StrictRedis(host='localhost', port=6379, db=0)res = sr.set('key', 'value') # 返回布尔值，表示是否成功。res = sr.get('key') # 如果有，返回该值；没有，返回Noneres = sr.delete('key') # 返回删除成功的数量res = sr.keys(pattern='*') # 返回列表 配置Django中保存session到Redis1pip install django-redis-sessions 在setting.py中配置Redis1234567SESSION_ENGINE = 'redis_sessions.session'SESSION_REDIS_HOST = 'localhost'SESSION_REDIS_PORT = 6379SESSION_REDIS_DB = 2SESSION_REDIS_PASSWORD = '' # 键前缀SESSION_REDIS_PREFIX = 'session' 使用方法依然不变12request.session['key'] = 1num = request.session['key'] Redis 主从在Redis中，主从的数据是共享的，也就是实现了数据的冗余保存，这样可以防止一台机器挂掉后数据丢失的问题。一个Redis主机可以有多个从机，一个从机也可以有多个从机。写数据要在主机中，从机可以读取数据。这样也可以实现数据的读写分离。一般情况下，一个网站的数据读写比例为 10:1 ，因此可以配置多个从机用于读取数据。 主机配置可以保存不变，只是IP地址应该使用局域网或公网IP。配置完成运行服务。从机配置，并启动。123bind 本机IPslaveof 主机IP 主机PORTport 从机PORT，不能与主机冲突 查看某机角色以及状态。1redis-cli -h 某机IP -p 某机PORT info Replication Redis 集群当用户量达到一定量级时，就需要将Redis服务规模升级为集群。 配置过程首先配置3个配置文件， 12345678port 7000bind 本机IPdaemonize yespidfile 7000.pidcluster-enabled yescluster-config-file 7000_node.confcluster-node-timeout 15000appendonly yes 12345678port 7001bind 本机IPdaemonize yespidfile 7001.pidcluster-enabled yescluster-config-file 7001_node.confcluster-node-timeout 15000appendonly yes 12345678port 7002bind 本机IPdaemonize yespidfile 7002.pidcluster-enabled yescluster-config-file 7002_node.confcluster-node-timeout 15000appendonly yes 之后依据这3个配置文件启动3个Redis服务。 使用命令运行集群12345678# 复制程序sudo cp /usr/share/doc/redis-tools/examples/redis-trib.rb /usr/local/bin# 安装依赖sudo gem install redis# 安装Ruby，保证是最新版sudo apt-get install ruby# 创建集群redis-trib.rb create --replicas 1 IP_1:PORT_1 IP_2:PORT_2 IP_3:PORT_3 创建完成后，会输出几个Redis主机和从机，几个主机分别存储一部分数据，按数据槽存储，槽编号范围是0 ~ 16383。 与Python交互1pip install redis-cluster 123456789101112from rediscluster import *startup_nodes = [ &#123;'host': '', 'port': PORT_1&#125; # Redis主机]src = StrictRedisCluster( startup_nodes=startup_nodes, decode_responses=True)result = src.set('key','val')]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>NoSQL</tag>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 入门]]></title>
    <url>%2F2020%2F01%2F30%2FDjangoFirst%2F</url>
    <content type="text"><![CDATA[绪论Django 3 官方参考文档点击进入 Django 2.2 官方参考文档点击进入 Django 2.2 其他参考文档点击进入 Django 1.11 官方参考文档点击进入（英文） Django 1.11 中文参考文档点击进入 Django 2 及后续版本不再支持 Python 2； Django 3 及后续版本不再支持 Python 3.5 及以下版本。 Django 1 与 2 的区别主要区别如下： url 用法：Django 1 主要使用 url 来配置，参数部分使用()做匹配；Django 2 使用 path 来配置，参数部使用&lt;&gt;做匹配，不支持传统的正则表达式。这里Django 2 兼容 Django 1 ，可以用re_path来做Django 1中url的操作。 路由分发 include。 ORM 外键：Django 2 的外键必须加on_delete属性 参考文章一参考文章二 Django 3.0 新特性（2019年12月 推出） 仅支持 Python 3.6以上版本。 支持使用 MariaDB 10.1 或更高版本的数据库。 开始将新增对 ASGI 的支持。这意味着 Django 3 可以支持异步操作，消除阻塞操作对程序的影响。 新增枚举类型 TextChoices 和 IntegerChoices 类。 枚举示例：12345678910111213141516171819class Student(models.Model): FRESHMAN = 'FR' SOPHOMORE = 'SO' JUNIOR = 'JR' SENIOR = 'SR' GRADUATE = 'GR' YEAR_IN_SCHOOL_CHOICES = [ (FRESHMAN, 'Freshman'), (SOPHOMORE, 'Sophomore'), (JUNIOR, 'Junior'), (SENIOR, 'Senior'), (GRADUATE, 'Graduate'), ] year_in_school = models.CharField( max_length=2, choices=YEAR_IN_SCHOOL_CHOICES, default=FRESHMAN, ) Django 基本操作django-admin 基本命令12345678910django-admin startproject # 创建Django项目django-admin startapp # 创建Django应用django-admin check # 检查项目完整性django-admin test # 执行单元测试django-admin runserver # 启动服务器django-admin shell # 进入Django Shelldjango-admin makemigrations # 创建数据库迁移文件django-admin migrate # 执行迁移文件django-admin dumpdata # 导出数据库数据django-admin loaddata # 导入数据库数据 目录结构项目结构 A （本次使用） Project # 项目目录 manage.py # 项目管理文件 project_name # 项目配置目录 asgi.py # Django 3.0 新增文件 settings.py # 项目配置 urls.py # 项目路由 wsgi.py # Web 与 Django 交互入口 my_app # 创建的Django应用目录 migrations # 数据库迁移文件目录 static # 静态文件目录 templates # 模板目录 index.html templatetags # 自定义标签过滤器目录 __init__.py urls.py # 应用路由 apps.py # 应用声明 models.py # 应用模型 test.py # 单元测试 admin.py # Admin模块 views.py # 应用视图 创建过程如下：1234567django-admin startproject project_namecd project_namedjango-admin startapp my_appcd my_appmkdir templatesmkdir templatetagsmkdir static 项目结构 B部分Django项目也会用到这种结构，即将模板，过滤器，静态文件等目录放在应用的外部。 Project manage.py project_name settings.py urls.py wsgi.py （ Web 与 Django 交互入口） templates my_app_templates index.html templatetags # 自定义标签过滤器 __init__.py my_app migrations urls.py apps.py models.py test.py admin.py views.py 配置过程123456789101112131415161718192021222324252627282930313233343536373839404142# 每创建一个应用，都要在项目setting.py中声明该应用INSTALLED_APPS=[ ... 'my_app', # 或写成 'my_app.apps.MyAppConfig' # 具体可以到应用的apps.py文件中查看命名]# 配置项目的数据库，可以保持默认SQLiteDATABASES=[ 'default': &#123; 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), &#125;]# 如果要改为MySQL，配置如下。注意：首次运行可能需要安装所提示的Python扩展包。DATABASES=[ 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': '数据库名称', # 必须手动创建 'USER': 'root', 'PASSWORD': '123456', 'HOST': 'localhost', 'PORT': 3306, &#125;]# 如果使用项目结构 B，则做下面的配置，配置要渲染的模板的目录TEMPLATES = [ ... 'DIR' = [os.path.join(BASE_DIR, 'templates')] ...]# 修改默认语言和时区LANGUAGE_CODE = 'zh-hans'TIME_ZONE = 'Asia/Shanghai'# 如果项目完成后，在交付阶段，要将DEBUG关闭，并配置允许访问的主机DEBUG = FalseALLOWED_HOSTS = ['*'] 配置完成后，在应用my_app下的views.py中添加一个简易的视图：123456from django.shortcuts import renderfrom django.http import HttpResponsedef hello(request): return HttpResponse("Hello World") 同时应该配置路由文件，在my_app中创建并配置urls.py。 1234567# Django 2.0 以上推荐此写法，后续写法均为 2.0 写法。from django.urls import path, re_path, includeimport my_app.viewsurlpatterns = [ path('hello/', my_app.views.hello),] 12345678910# Django 1.11 以及之前的写法。from django.conf.urls import url, includeimport my_app.viewsurlpatterns = [ # 写法 1：这里的'hello'是按照字符串进行匹配，如果用户写作helloabcd，也会命中该记录，如果想修正这种错误，可以写作'hello/'。 url('hello', my_app.views.hello), # 写法 2：使用正则表达式，r表示该串为正则表达式，^与$分别标记了正则表达式匹配的开始和结尾，这样，用户写helloabcd就不会命中了。使用正则表达式的好处，例如匹配GET参数等，都会使操作变得很方便。 url(r'^hello/$', my_app.views.hello),] 之后再配置项目路由器：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('my_app/', include('my_app.urls'))] 配置到这里就可以运行项目看效果了。1python manage.py runserver 8080 进入如下地址，出现Hello World就算配置成功了。http://127.0.0.1:8080/my_app/hello/ Django 模型模型（Models）是用于对接数据库的接口，在所有的MVC应用中都是如此。Django的模型的定义如下： 数据类型 整型：IntegerField 定长文本：CharField 不定长文本：TextField 日期：DataField 时间：TimeField 日期时间：DateTimeField 自增ID：AutoField （可以不定义，自动生成） 布尔：BooleanField Null型布尔：NullBooleanField 十进制浮点数：DecimalField （精度更高，例如钱数） 浮点型：FloatField 文件：FileField 图片：ImageField 主要属性 主键：primary_key 长度：max_length 默认值：default 唯一性：unique（不允许重复出现） 索引：db_index 自定义字段名称：db_column 是否允许为空：null 是否允许空白：blank 十进制浮点数： 数字数：max_digits 小数点数：decimal_places 日期（二者只能用一个） 更新时间：auto_now 创建时间：auto_now_add 外键：’其他表’ （赋值时直接写该对象，2.0以上版本还要求on_delete属性） 创建模型1234567891011121314151617181920212223from django.db import modelsclass MyBookModel(models.Model): # 注意：属性名不能出现两个连续的下划线， # title title = models.CharField(max_length=20) # publish_date publish_date = models.DateTimeField(auto_now=True) # author author = models.ForeignKey('AuthorModel', on_delete=models.CASCADE) # Django 1 版本中不要求on_delete def __str__(self): return self.titleclass AuthorModel(models.Model): # name name = models.CharField(max_length=20) # age age = models.IntegerField(default=0) def __str__(self): return self.name 完成后，迁移数据库到sqlite：12python manage.py makemigrationspython manage.py migrate 使用模型简单查询操作 get：返回模型对象；查到多条或是未查到都会抛出异常。 all：返回查询集；返回所有数据 filter：返回查询集；返回满足条件的数据 exclude：返回查询集；返回不满足条件的数据 order_by：返回查询集；对查询结果排序 对于 get，filter，exclude 这三个查询操作，可以填写查询条件，例如：123456789101112131415161718192021222324252627# 精确查询MyBookModel.objects.get(id=1)MyBookModel.objects.get(title__exact="First Book") # 同 title="First Book"# 模糊查询MyBookModel.objects.filter(title__contains="First")MyBookModel.objects.filter(title__startswith="First")MyBookModel.objects.filter(title__endswith="Book")# 空查询MyBookModel.objects.filter(title__isnull=False)# 范围查询MyBookModel.objects.filter(id__in=[1, 3, 5])# 比较查询MyBookModel.objects.filter(id__gt=2)MyBookModel.objects.filter(id__lt=2)MyBookModel.objects.filter(id__gte=2)MyBookModel.objects.filter(id__lte=2)# 日期查询MyBookModel.objects.filter(publish_date__year=1990)MyBookModel.objects.filter(publish_date__month=2)MyBookModel.objects.filter(publish_date__day=2)MyBookModel.objects.filter(publish_date__gt=date(1980,3,2))# 排序MyBookModel.objects.all().order_by('id', 'title') # 升序MyBookModel.objects.all().order_by('-id') # 降序，前面加一个 减号# 查看是否有数据m = MyBookModel.objects.filter(id=1)m.exists() 也就是说，其参数格式为模型属性名__条件名=值。（注意是双下划线） 高级查询操作1234567891011121314151617181920from django.db.models import F, Q# 直接书写，默认为“且”的关系MyBookModel.objects.filter(id__gt=2, title__contains="First")# Q 对象，实现“与或非”的关系MyBookModel.objects.filter(Q(id__gt=2) &amp; Q(title__contains="First")) # 且的关系MyBookModel.objects.filter(Q(id__gt=2) | Q(title__contains="First")) # 或的关系MyBookModel.objects.filter(~Q(id=2)) # id 不为 2# F 对象，实现“属性（字段）”之间的比较MyBookModel.objects.filter(publish_date=F('publish_date')) # 查询出版日期与出版日期相等的对象MyBookModel.objects.filter(publish_date=F('publish_date') / 3) # 查询出版日期与出版日期除以三相等的对象# 聚合函数 sum count avg max minfrom django.db.models import Sum, Count, Avg, Max, MinMyBookModel.objects.all().aggregate(Count('id')) # 返回字典 &#123;'id_count': 2&#125;MyBookModel.objects.aggregate(Count('id')) # 返回字典 &#123;'id_count': 2&#125;，与前者功能一致MyBookModel.objects.filter(id__gt=2).count() # id 大于 2 的记录数目 查询集： 惰性查询：只有需要具体数据的时候才发生查询。 缓存：第一次查询到的查询集数据会缓存下来，第二次再访问这个查询集的时候就会使用缓存的内容。 切片：对一个查询集切片会产生新的查询集，且切片参数不可为负数。 模型关系模型（数据表）关系分为： 一对一 一对多 多对多 关系属性： 多对多：ManyToManyField(‘表名’)，可以任意定义到其中一个模型中。 一对一：OneToOneField(‘表名’)，可以任意定义到其中一个模型中。 多对一：ForeignKey(‘表名’)，定义在多的模型中。 关联查询（一对多）1234567891011# 查询一表一表.objects.filter(多表__属性__条件='...') # 这里的多表要小写AuthorModel.objects.filter(mybookmodel__title__contains='First')# 查询多表多表.objects.filter(外键__属性__条件='...') MyBookModel.objects.filter(author__name__contains='W')# 查询多表查询集x = 一表.objects.get(id=1)查询集y = 查询集.多表_set.all() # 多表也要小写x = AuthorModel.objects.get(id=1)y = x.mybookmodel_set.all() 插入，更新与删除使用举例：1234567891011121314151617181920212223242526from my_app.models import AuthorModel, MyBookModelfrom datetime import date# 创建一条作者记录a = AuthorModel()a.name = "Wang"a.age = 80a.save()# 创建一条作者记录a = AuthorModel.objects.create(name='Li', age=10)# 创建一条书籍记录m = MyBookModel()m.title = "First Book"m.date = date(1999,1,1)m.author = am.save()# 修改m = MyBookModel.objects.get(id=1)m.title = "Second Book"m.save()# 删除m = MyBookModel.objects.get(id=1)m.delete() 自关联自关联是一种特殊的一对多关系，例如“省-&gt;市-&gt;县”的关系。设计这种关系，一种方法是设计三张表，利用外键关联三个表；另外一种方法是将他们设计到一张表中，利用一个字段指向其父级ID，这样就形成了自关联的关系。 123456class AreaModel(models.Model): title = models.CharField(max_length=100) parent = models.ForeignKey('self', null=True, blank=True, on_delete=False) def __str__(self): return self.title on_delete有CASCADE、PROTECT、SET_NULL、SET_DEFAULT、SET()五个可选择的值。 CASCADE：此值设置，是级联删除。PROTECT：此值设置，是会报完整性错误。SET_NULL：此值设置，会把外键设置为null，前提是允许为null。SET_DEFAULT：此值设置，会把设置为外键的默认值。SET()：此值设置，会调用外面的值，可以是一个函数。 管理器 objects就是MyBookModel.objects的objects。自制管理器的优势有： 改变查询结果 添加个性化方法 自制管理器的方式如下：1234567891011121314151617181920212223242526class AuthorModelManager(models.Manager): def all(self): a = super().all() return a.filter(age__gt=10) # 此方法与下面的create任选一个： def create_author(self, name, age): a = self.model() # a = AuthorModel() a.name = name a.age = age a.save() return aclass AuthorModel(models.Model): ... # 管理器 objects = AuthorModelManager() ... @classmethod def create(cls, name, age): a = cls() a.name = name a.age = age a.save() return a 一旦自制了管理器，原来的管理器就自动失效了（就算名字不是objects，原objects也会失效）。 元选项在数据库中，数据表的命名是项目名_模型名，但是一旦项目名发生变化，所有的表的命名都会受到影响。如果消除这种影响，可以在模型类里面定义一个元类： 12345class AuthorModel(models.Model): ... class Meta: # 指定表名 db_table = 'author_table' 在某些版本的SQLite中不支持数据表改名，所以这一步操作要注意。 导入导出数据12python manage.py dumpdata &gt; data.jsonpython manage.py loaddata data.json Django 视图静态视图在my_app下创建templates文件夹，在该文件夹下创建index.html，编辑index.html。12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 编辑视图函数：123456789101112from django.http import HttpResponsefrom django.shortcuts import render# 第一种方式，直接返回纯文本def hello(request): return HttpResponse('Hello')# 第二种方式，返回模板def index(request): return render(request, 'index.html') 修改后记着修改对应的urls：12345678from django.urls import path, includeimport my_app.viewsurlpatterns = [ path('hello', my_app.views.hello), path('index', my_app.views.index)] 动态视图模板系统基本语法：123变量标签：&#123;&#123; 变量 &#125;&#125;for循环标签：&#123;% for x in list %&#125;, &#123;% endfor %&#125;if-else标签：&#123;% if %&#125;, &#123;% else %&#125;, &#123;% endif %&#125; 首先编辑好前端页面，label_list是要输出的标签。这里我们创建books.html文件，编辑如下：123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#123;% for x in label_list %&#125;&lt;h1&gt;&#123;&#123; x.title &#125;&#125;&lt;/h1&gt;&#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 模板渲染：后台给要输出的标签赋值：12345def get_them(request): get_all = MyBookModel.objects.all() return render(request, 'books.html', &#123; 'label_list': get_all &#125;) 修改后，别忘了修改urls.py文件。1234urlpatterns = [ path('index/', my_app.views.index), path('get_books/', my_app.views.get_books),] 如果想自己做一个渲染器，可以这样做：1234567from django.template import loader, RequestContextdef my_render(request, template, args): temp = loader.get_template(template) context = RequestContext(request, args) res_html = temp.render(context) return HttpResponse(res_html) http://127.0.0.1:8080/my_app/index/http://127.0.0.1:8080/my_app/get_books/ 依据ID进行路由跳转首先建立模板one_book.html：123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;&#123;&#123; item.title &#125;&#125;&lt;/h1&gt;&lt;h2&gt;&#123;&#123; item.author &#125;&#125;&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; 在my_app的urls里面修改：1path('get_the_book/&lt;int:bid&gt;', my_app.views.get_the_book) 相应修改views.py：123456def get_the_book(request, bid): bid = int(bid) get_one = MyBookModel.objects.get(id=bid) return render(request, 'one_book.html', &#123; 'item': get_one &#125;) 页面重定向跳转方法：123456789def create(request): a = AuthorModel.objects.get(id=1) m = MyBookModel() m.title = "Second Book" m.author = a m.save() return HttpResponseRedirect('/my_app/index') 自定义 404 等错误页面在项目urls.py中配置：1234import django.conf.urlsdjango.conf.urls.handler404 = 'my_app.views.error404'django.conf.urls.handler500 = 'my_app.views.error500' 同时设计相应的错误页面。要查看效果，就要关闭DEBUG模式才可以。123456def error404(request): return HttpResponse('Error handler content', status=404) # return render(request, 'error404.html', status=404)def error500(request): return HttpResponse('Error handler content', status=500) 管理静态文件通常一些静态文件，如网站logo等资源需要单独存放到一个固定的位置，一般是存放到静态文件目录下。配置静态文件目录过程为： 确保 INSTALLED_APPS 包含了 django.contrib.staticfiles。 在配置文件中，定义 STATIC_URL，例子:STATIC_URL = &#39;/static/&#39; 在模板中，用 static 模板标签基于配置 STATICFILES_STORAGE 位给定的相对路径构建 URL。 12&#123;% load static %&#125;&lt;img src="&#123;% static 'image/example.jpg' %&#125;" alt="My image"&gt; 将你的静态文件保存至程序中名为 static 的目录中。例如 my_app/static/image/example.jpg。 表单表单的提交常见有两种方式：GET与POST。在Request中包含了浏览器的请求信息，Request的属性包括： POST：POST请求参数，查询字典（QueryDict）类型 GET：GET请求参数，查询字典（QueryDict）类型 FILES：上传的文件，类似于字典的对象 COOKIES：客户端的cookies，一个Python字典 path：表示请求路径，不包括域名与参数 method：表示请求方式 encoding：提交数据的编码，默认utf8 session：服务端session 用法如下123456789def set_author(request): args = request.POST # 写法 1：如果没有该参数则返回None name = args.get('name') name = args.get('name', "Anonymous") # 第二个参数表示默认值，即没有参数的时候返回该默认值 name = args.getlist('name') # 返回name参数的多个值，因为允许一个参数含有多个值 # 写法 2：如果没有该参数则抛出异常KeyError name = args['name'] return HttpResponseRedirect('/my_app/index') Ajax 请求123456789from django.http import JsonResponsedef get_author(request): a = AuthorModel.objects.get(id=1) j = &#123; 'name': 'Wang' 'age': 20 &#125; return JsonResponse(j) Cookie 与 SessionCookie：保存在客户端，由服务器生成，客户端访问服务器时会附带Cookies。另外Cookies是会过期的，如果不指定，则有效期为关闭浏览器时。Session：保存在服务端，也是由服务器生成，依赖于Cookie，因为客户标识码SessionID存储在Cookie里面。Session存储位置在数据库中。 Cookie12345678910# 设置 Cookiesresponse = HttpResponse('')response.set_cookie('num', 1, max_age=7*24*3600) # 从现在开始计算过期时间，单位：秒response.set_cookie('num', 1, expires=timedelta(days=7)+datetime.now()) # 从指定时间计算，单位：秒return response# 读取 Cookiesif 'num' in request.COOKIES['num']: num = request.COOKIES['num']else: num = 0 Session123456789101112131415161718# 设置 Sessionrequest.session['num'] = 1return HttpResponse('...')# 读取 Sessionif 'num' in request.session['num']: num = request.session['num']else: num = 0# 或num = request.session.get('num', '0') # 也可以设置默认值# 清除 Session 的值request.session.clear()# 删除 Session 记录request.session.flush()# 删除 某一个键del request.session['key']# 设置会话超时时间，单位：秒。默认两周；为0，则关闭浏览器过期request.session.set_expiry(24*3600) 设计分页我们也可以使用index?page=1的方式传递GET参数，分页也一般采用这种方式查看当前访问的是第几页。通过GET参数获取请求的分页，为了获取GET参数，可以使用如下：12345page = request.GET.get('page') # 字符串，可能没有这个参数if page: page = int(page)else: page = 1 Django自带了分页组件。分页组件及其常用方法如下：1234567891011121314from django.core.paginator improt Paginatorp = Paginator(one_list, 3) # one_list列表, 每页3个记录p.num_pages # 分了几页 p.page_range # 总记录数page = p.page(1) # 获取第一页page.number # 当前页页码page.object_list # 第一页的查询集page.paginator # 对应的分页器page.has_next() # 是否有下一页page.has_previous() # 是否有上一页page.previous_page_number # 前一页页码page.next_page_number # 后一页页码 Django 路由Path 语法Django Path默认支持五个转化器： 12345str：匹配除了路径分隔符（/）之外的非空字符串，这是默认的形式int：匹配正整数，包含0。slug：匹配字母、数字以及横杠、下划线组成的字符串。uuid：匹配格式化的uuid，如 075194d3-6885-417e-a8a8-6c931e272f00。path：匹配任何非空字符串，包含了路径分隔符 具体用法例如： 123456urlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles/&lt;int:year&gt;/', views.year_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/', views.month_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/&lt;slug&gt;/', views.article_detail),] 用户也可以自定义转化器，自定义的转化器需要使用实现转化器接口。实现方法如下：123456789101112131415161718192021222324252627282930# 例 1class IntConverter: # 正则表达式 regex = '[0-9]+' # value是匹配到的字符串，返回Python变量 def to_python(self, value): return int(value) # value是Python变量，返回字符串，用于url反向引用 def to_url(self, value): return str(value)# 例 2class StringConverter: regex = '[^/]+' def to_python(self, value): return value def to_url(self, value): return value# 例 3：匹配4位整数class FourDigitYearConverter: regex = '[0-9]&#123;4&#125;' def to_python(self, value): return int(value) def to_url(self, value): return '%04d' % value 定义完成后，将其注册到配置中。在需要的urls.py中添加：12345678from django.urls import register_converterfrom . import converters # 自制转化器，不嫌乱也可以把自制转化器放到urls.py中。register_converter(converters.FourDigitYearConverter, 'yyyy')urlpatterns = [ path('articles/&lt;yyyy:year&gt;/', views.year_archive),] 如果嫌自制转化器太繁琐，可以使用兼容Django 1中的正则表达式的方式直接匹配。123456urlpatterns = [ path('articles/2003/', views.special_case_2003), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/', views.year_archive), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/', views.month_archive), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;slug&gt;[^/]+)/', views.article_detail),] Django 模板模板加载顺序加载一个模板，首先是查找配置的模板目录，如果找不到，再去INSTALLED_APPS下的templates查找。这一过程是Django自动的。 模板变量模板变量，不能以下划线开头。1&#123;&#123; num &#125;&#125; 下面两种情况，有两种解析顺序。1&#123;&#123; author.name &#125;&#125; 其解析顺序为: 作为字典，取键值 作为对象，取属性 作为对象，当作对象的方法 都无法匹配，则替换为空字符串 1&#123;&#123; author_list.0 &#125;&#125; 其解析顺序为: 作为字典，取键值 作为列表，取下标 都无法匹配，则替换为空字符串 模板标签后端给标签变量赋值可以使用render函数。123render(request, 'index.html', &#123; 'author_list': AuthorModel.objects.all()&#125;) 前端的模板标签主要如下1234567891011121314151617181920for循环标签&#123;% for x in author_list %&#125;列表不为空时&#123;&#123; forloop.counter &#125;&#125; 记录循环第几次&#123;% empty %&#125;列表为空时&#123;% endfor %&#125;if标签&#123;% if 条件 %&#125;操作符旁边必须有空格&#123;% elif %&#125;&#123;% else %&#125;&#123;% endif %&#125;注释&#123;# 单行注释 #&#125;&#123;% comment %&#125;多行注释&#123;% endcomment %&#125; 模板过滤器过滤器是用在前端的标签函数，用于对模板变量做操作。12345678910过滤器格式为&#123;&#123; 变量|过滤器:参数 &#125;&#125;改变日期的显示格式&#123;&#123; book.publish_date|date:"Y年-m月-d日" &#125;&#125;求长度&#123;&#123; book.title|length &#125;&#125;设置默认值&#123;&#123; book.title|default:"No Title" &#125;&#125;自定义过滤器（是否是奇数）&#123;&#123; author.age|mod:1 &#125;&#125; 自定义过滤器的定义应在my_app目录下的templatetags下。templatetags应该有一个__init__.py文件，保证该目录可以被Python识别。 这里创建一个filters.py文件用于开发自定义过滤器。自定义标签也可以写到这里。filters.py123456789101112131415from django import templateregister = template.Library()# value：被判断的变量；arg：传入的参数def mod(value, arg): return value % arg# 完成后，注册过滤器register.filter('mod', mod)# 另外，只有一个参数的过滤器如下，外加另外一种注册方式@register.filter(name='lower')def lower(value): # Only one argument. return value.lower() 在需要使用的模板上加载过滤器。1&#123;% load filters %&#125; 模板继承网页往往会有很多重复的内容，因此我们可以制作一个父页面，子页面继承主页面显示以减少重复代码。 父页面base.html12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;&#123;% block topics %&#125;默认显示内容&#123;% endblock topics %&#125;&lt;/body&gt;&lt;/html&gt; 子页面sub_page.html123456789&#123;% extends 'base.html' %&#125;&#123;% block topics %&#125;新内容获取父模板的内容&#123;&#123; block.super &#125;&#125;&#123;% endblock topics %&#125; 模板转义默认情况下，模板上下文（由后端传递过来）中的html标记会被转义显示，即模板中的&lt;&gt;会被转化为&amp;lt;&amp;gt。因此要关闭转义显示，可以使用标签1234567方式 1&#123;&#123; 变量|safe &#125;&#125;方式 2&#123;% autoescape off %&#125;模板语言代码&#123;% endautoescape %&#125; Django 用户登录登录装饰器有些页面是用户登录之后才可以访问的，例如修改密码，修改昵称等，也就是这些页面首先要进行用户登录的判断，否则让用户跳转回登录页面。 我们可以通过函数装饰器的方式：12345678910111213141516# 定义一个闭包函数def login_required(view_func): def wrapper(request, *view_args, **view_kwargs) # 判断用户是否登录 if true: return view_func(request, *view_args, **view_kwargs) else: return redirect('/login') pass return wrapper# 使用函数装饰器，使用该函数会先调用login_required，相当于# login_required(change_pwd)(request, *view_args, **view_kwargs)@login_requireddef change_pwd(request): return HttpResponse('Change Password') CSRF 攻击CSRF 攻击即跨站请求伪造攻击。我们在访问某一网站时，例如银行网站，在访问的结束后再去访问其他的网站，就会致使我们所有保存在浏览器上的数据包都会暴露给第三方网站，如果第三方网站上有某些攻击脚本，例如在用户不知情的情况下，再次利用刚才的数据包（SessionID）访问银行网站进行一些危险的操作，我们的数据就会产生泄露甚至丢失的危险。 由于伪造的网站与真实的网站的IP或主机名是不一样的，所以根据这一特性，我们可以也防止这种跨站请求伪造攻击。 Django 默认是启用这种 CSRF 攻击保护的（只针对POST），但同时也带来了不便，因为我们有时自己的网站也会被防护，导致自己的网站都无法正常浏览。 解决这一问题，可以在模板中的表单里添加如下内容即可。1&#123;% csrf_token %&#125; 内置表单Django中内置了表单。用户可以通过Django内置的表单生成器自动生成表单。 1234567891011121314151617181920212223from django import formsclass LoginForm(forms.Form): username = forms.TextField() password = forms.TextField(widget=forms.PasswordInput)def login_handler(request): if request.method == "POST": login_form = LoginForm(request.POST) if login_form.is_valid(): user = login_form.cleaned_data['username'] pswd = login_form.cleaned_data['password'] if user: # 验证用户名，密码 return HttpResponse('成功登录') else: return HttpResponse('登录失败') else: return HttpResponse("输入不合法")def login(request): login_form = LoginForm() return render(request,'login.html', &#123;"forms":login_form&#125;) 12345&lt;form action="." method="post"&gt; &#123;% csrf_token %&#125; &#123;&#123; forms &#125;&#125; &lt;input type="submit" value="Login"&gt;&lt;/form&gt; 验证码django-simple-captcha 官方文档首先按照验证码库： 1pip install django-simple-captcha 在项目settings.py中配置：123456789101112131415161718192021INSTALLED_APPS = [ ... "captcha",]# Captcha 二者选其一# 字母验证码CAPTCHA_IMAGE_SIZE = (80, 45) # 设置 captcha 图片大小CAPTCHA_LENGTH = 4 # 字符个数CAPTCHA_TIMEOUT = 1 # 超时(minutes) # 加减乘除验证码CAPTCHA_OUTPUT_FORMAT = '%(image)s %(text_field)s %(hidden_field)s 'CAPTCHA_NOISE_FUNCTIONS = ('captcha.helpers.noise_null', 'captcha.helpers.noise_arcs', # 线 'captcha.helpers.noise_dots', # 点)CAPTCHA_CHALLENGE_FUNCT = 'captcha.helpers.random_char_challenge'CAPTCHA_CHALLENGE_FUNCT = 'captcha.helpers.math_challenge'CAPTCHA_TIMEOUT = 1 在项目urls.py中配置：1path('captcha/', include('captcha.urls')) 完成后迁移数据库12python manage.py makemigrationpython manage.py migrate 创建登录表单，验证码在登录时由表单自动完成验证。123456789101112131415161718192021222324from django import formsfrom captcha.fields import CaptchaFieldclass LoginForm(forms.Form): username = forms.TextField() password = forms.TextField(widget=forms.PasswordInput) captcha = CaptchaField()def login_handler(request): if request.method == "POST": login_form = LoginForm(request.POST) if login_form.is_valid(): user = login_form.username if user: '''用户登陆后，Django会自动调用默认的session应用，将用户的id存至session中''' return HttpResponse('成功登录') else: return HttpResponse('登录失败') else: return HttpResponse("输入不合法")def login(request): login_form = LoginForm() return render(request,'login.html', &#123;"forms":login_form&#125;) 如果想要点击验证码实现验证码更新，则可以使用如下操作（需要jQuery）。 123456789101112131415from captcha.helpers import captcha_image_urlfrom captcha.models import CaptchaStoreimport jsondef captcha_refresh(request): """ Return json with new captcha for ajax refresh request """ if not request.is_ajax(): # 只接受ajax提交 raise Http404 new_key = CaptchaStore.generate_key() to_json_response = &#123; 'key': new_key, 'image_url': captcha_image_url(new_key), &#125; return HttpResponse(json.dumps(to_json_response), content_type='application/json') 123456789101112131415161718192021222324252627282930&lt;script&gt; $(function()&#123; # 改变鼠标箭头 $('.captcha').css(&#123; 'cursor': 'pointer' &#125;) # ajax 刷新 $('.captcha').click(function()&#123; console.log('click'); $.getJSON("/captcha/refresh/", function(result)&#123; $('.captcha').attr('src', result['image_url']); $('#id_captcha_0').val(result['key']) &#125;);&#125;); # ajax动态验证 $('#id_captcha_1').blur(function()&#123; // #id_captcha_1为输入框的id，当该输入框失去焦点是触发函数 json_data=&#123; 'response':$('#id_captcha_1').val(), // 获取输入框和隐藏字段id_captcha_0的数值 'hashkey':$('#id_captcha_0').val() &#125; $.getJSON('/ajax_val', json_data, function(data)&#123; //ajax发送 $('#captcha_status').remove() if(data['status'])&#123; //status返回1为验证码正确， status返回0为验证码错误， 在输入框的后面写入提示信息 $('#id_captcha_1').after('&lt;span id="captcha_status" &gt;*验证码正确&lt;/span&gt;') &#125;else&#123; $('#id_captcha_1').after('&lt;span id="captcha_status" &gt;*验证码错误&lt;/span&gt;') &#125; &#125;); &#125;); &#125;)&lt;/script&gt; 当然，高级玩家可以自己画验证码。下面自制验证码： 安装Pillow包1pip install Pillow 定义一个验证码生成函数12345678910111213141516171819202122232425262728293031323334353637383940414243from PIL import Image, ImageDraw, ImageFontfrom django.utils.six import BytesIOdef verify_code(request): import random # 背景色，宽，高 bgcolor = (random.randrange(20, 100), random.randrange(20, 100), 255) width = 100 height = 25 # 创建画面 img = Image.new('RGB', (width, height), bgcolor) draw = ImageDraw.Draw(img) # 绘制噪点 for i in range(0, 100): xy = (random.randrange(0, width), random.randrange(0, height)) fill = (random.randrange(0, 255), 255, random.randrange(0, 255)) draw.point(xy, fill=fill) # 准备字符串 str_back = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890' rand_str = '' for i in range(0, 4): rand_str += str_back[random.randrange(0, len(str_back))] # 绘制字符串 font = ImageFont.truetype('FreeMono.ttf', 23) fontcolor = (255, random.randrange(0, 255), random.randrange(0,255)) for i in range(0, 4): draw.text((5 + 24*i, 2), rand_str[i], font=font, fill=fontcolor) # 释放画笔 del draw # 存储验证码到后端 request.session['verify_code'] = rand_str # 保存到内存文件 buf = BytesIO() im.save(buf, 'png') # 返回验证码 return HttpResponse(buf.getvalue(), 'image/png') URL 反向解析在模板里面，可以将链接到其他页面的超链接写成动态的，这样可以保证修改链接后自动修改所有链接到某页的路径。 在项目urls.py中，添加namespace属性：1234url_patterns = [ ... path('my_app/', include('my_app.urls', namespace='my_app'))] 在应用urls.py配置中，添加name属性：1234url_patterns = [ ... path('index_renamed/', views.index, name='index')] 在模板中：12345用法：url 'namespace:name' 参数&lt;a href="&#123;% url 'my_app:index' %&#125;"&gt;首页&lt;/a&gt;&lt;a href="&#123;% url 'my_app:index' arg1 arg2 %&#125;"&gt;带位置参数的首页&lt;/a&gt;&lt;a href="&#123;% url 'my_app:index' a=arg1 b=arg2 %&#125;"&gt;带关键字参数的首页&lt;/a&gt; 在视图中使用反向解析：1234567from django.core.urlresolvers import reversedef test_redirect(request): # 'namespace:name' url = reverse('my_app:index', args=('arg1', 'arg2')) url = reverse('my_app:index', kwargs=&#123;'a'='arg1', 'b'='arg2'&#125;) return redirect(url) 中间件是Django预留的函数接口，允许我们干预请求和应答。例如对客户端进行过滤，防止DDoS攻击等。 中间件可以允许我们在执行视图函数之前自动执行中间件。中间件的执行流程如下：1234567891011st=&gt;start: 请求到达服务器op1=&gt;operation: 产生Request对象op2=&gt;operation: 调用process_requestop3=&gt;operation: 匹配URLop4=&gt;operation: 调用process_viewop5=&gt;operation: 调用视图函数op6=&gt;operation: 调用process_responseop6=&gt;operation: 返回给浏览器e=&gt;endst-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;op5-&gt;op6-&gt;e 在setting.py中注册中间件，注册顺序与执行顺序相反。1234MIDDLEWARE = [ ... 'my_app.middleware.Block_Middleware'] 在my_app目录下建立middleware.py文件，编辑此文件：12345678910111213141516171819202122# 中间件类class Block_Middleware(object): # 匹配url之后，在进入视图函数之前调用 def process_view(self, request, view_func, *view_args, **view_kwargs): # 获取浏览器端的IP地址： user_ip = request.META('REMOTE_ADDR') if user_ip in ['127.0.0.1']: return HttpRequest('Go Back') # 服务器启动后接受第一个请求的时候调用 def __init__(self): pass # 产生request之后，匹配url路由之前调用 def process_request(self, request): pass # 调用视图函数之后，返回浏览器之前调用 # view_func 为将要调用的视图函数 def process_response(self, request, response): return response # 视图函数异常时候调用 def process_exception(self, request, exception): pass 注意：如果在中间件的任意一个函数返回response，后续的过程将不会执行，而是直接将结果交给process_response，再返回浏览器。 Django Shell就是带Django相关功能的Python Shell。可以方便开发者调试代码。例如，使用Django Shell添加一条数据库的记录。首先进入Shell1python manage.py shell 进入后，可以执行如下常用操作：12345from my_app.models import AuthorModel, MyBookModelfrom datetime import date# 获取作者A的所有书 的 第0本，注意要所有字母小写print(a.mybookmodel_set.all()[0]) Django Admin 模块Django标配的后台管理工具，使用方便，可以快速编辑很多内容。 首先创建用户：1python manage.py createsuperuser 填写用户名与密码，这里可能要求密码长度大于8位且不能为纯数字。 之后运行查看效果：1python manage.py runserver 8080 http://127.0.0.1:8080/admin/ 进入后台后，可以看到管理页面中出现 Groups 与 Users，编辑这两项添加用户与用户组。如果想将my_app的模型MyModel也加入其中，可以到my_app下的admin.py中编辑： 123from my_app.models import MyBookModel, AuthorModeladmin.site.register(MyBookModel)admin.site.register(AuthorModel) 也可以使用自定义管理页面：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class MyBookModelAdmin(admin.ModelAdmin): # 浏览页 # 显示的字段，方法 list_display = ['id', 'title', 'title_func'] # 如果想让传过来的方法也可以排序，要做模型里面添加 # title_func.admin_order_field = 'title' # 如果想改变显示内容 # title_func.short_description = 'T' # 如果想改变字段的显示内容 # title = models.CharField(verbose_name='T', max_length=20) # 每一页显示多少条 list_per_page = 10 # 动作 actions_on_bottom = True actions_on_top = False # 过滤栏 list_filter = [ 'title' # 列表页右侧的过滤栏 ] # 搜索框 search_fields = [ 'title' # 列表页上方的搜索框 ] # 编辑页 # 字段显示顺序 fields = [ 'title', 'id' ] # 分组显示 fieldsets = [ ('Base', &#123;'fields': ['title', 'id']&#125;), ('Advance', &#123;'fields': []&#125;) ] # 关联对象 inlines = [ AreaStackedInline, AreaTabularInline ]# 块状class AreaStackedInline(admin.StackedInline): # 写多类的名字 model = AreaInfo extra = 2 # 额外新建编辑2个子对象# 表状class AreaTabularInline(admin.TabularInline): # 写多类的名字 model = AreaInfo extra = 2 # 额外新建编辑2个子对象admin.site.register(MyBookModel, MyBookModelAdmin)admin.site.register(AuthorModel) 如果要重写模板，可以在templates下建立base_site.html文件：1234567891011121314151617181920&#123;% extends "admin/base.html" %&#125;&#123;# 标题 #&#125;&#123;% block title %&#125;&#123;&#123; title &#125;&#125; | &#123;&#123; site_title|default:_('Django site admin') &#125;&#125;&#123;% endblock %&#125;&#123;# 展框 #&#125;&#123;% block branding %&#125;&lt;h1 id="site-name"&gt; &lt;a href="&#123;% url 'admin:index' %&#125;"&gt; &#123;&#123; site_header|default:_('Django administrator') &#125;&#125; &lt;/a&gt;&lt;/h1&gt;&#123;% endblock %&#125;&#123;# 导航栏 #&#125;&#123;% block nav-global %&#125;&#123;% endblock %&#125; Django 上传配置settings.py文件：12MEDIA_URL = '/static/media'MEDIA_ROOT = os.path.join(BASE_DIR, 'my_app/static/media') 模板上，上传图片的表单配置如下：12345&lt;form method="post" action="/my_app/upload_action" enctype="multipart/form-data"&gt; &#123;% csrf_token %&#125; &lt;input type="file" name="pic"/&gt;&lt;br/&gt; &lt;input type="submit" value="upload file"/&gt;&lt;/form&gt; 视图中，获取文件并保存：12345678910111213141516def upload_handle(request): # 如果是小文件（&lt;2.5MB），则文件存储在内存中；如果是大文件（&gt;2.5MB），则文件存储在临时文件中。 image = request.FILES['pic'] # image.name：文件名 # image.chunks()：返回一个列表，里面存储文件的每一个区块 # image.size：文件大小 # image.content_type：文件类型，但是不确定 # 创建一个文件 save_path = '%s/my_book_model/%s'%(settings.MEDIA_ROOT, image.name) with open(save_path, 'wb') as f: for chk in image.chunks(): f.write(chk) # 将路径保存至数据库中 m = MyBookModel.objects.get(id=1) m.picture = 'my_book_model/%s'%image.name m.save() WebSocketDjango-channels开发流程总结需求分析网站设计数据库设计URL设计 URL 视图 模板文件 /login login login.html 创建项目模型编辑视图编辑路由配置其他虚环境虚环境的安装12sudo pip install virtualenv # 虚环境sudo pip install virtualenvwrapper # 虚环境扩展 虚环境的常用命令1234mkvirtualenv -p python3 name # 创建虚环境deactivate # 退出虚环境workon name # 进入虚环境rmvirtualenv name # 删除虚环境 CMD下进入虚环境： 1./venv/Scripts/activate.bat PowerShell下进入虚环境：1234# 首先开启脚本运行权限（管理员模式）Set-ExecutionPolicy RemoteSigned# 开启脚本./venv/Scripts/activate.psl 查看虚环境下已安装的包12pip list # 列出所有的包pip freeze &gt; requirements.txt # 输出安装的包（到文件） MySQL基本操作开启日志文件，需要修改mysql.conf文件。12# 实时查看日志文件tail -f mysql.log]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode 开发调试C++ 程序]]></title>
    <url>%2F2020%2F01%2F25%2FVSCodeCPPInit%2F</url>
    <content type="text"><![CDATA[配置编译环境 MinGW-64点击进入MinGW-64下载页面，下载完毕后，解压到一个固定的目录下，并将该目录的../bin目录添加至环境变量中。 打开CMD（或Power Shell）输入gcc测试环境是否配置成功。如果成功，则显示： 12gcc: fatal error: no input filescompilation terminated. 下载 Visual Studio Code点击下载Visual Studio Code，下载完毕后安装打开。进入程序后，在插件栏中安装Code Run，C/C++两款插件。安装完毕后重启编辑器。 Tips: 可以安装一个Chinese插件可以进行汉化。 创建第一个项目打开一个空文件夹，在其下面创建.vscode文件夹（注意有个点），依次点击菜单栏的调试-&gt;添加配置选项，添加一个C++(GDB/LLDB)配置，第二步选择g++.exe build and debug active file，之后会启动调试，并显示调试失败。这里点击取消，编辑器将自动创建launch.json文件和tasks.json文件，这个文件中可以配置启动程序和调试程序所需的相关内容。这两个文件默认情况下是不需要修改的。如果调试失败，可以参考如下两个配置文件进行修改。文件内容如下： launch.json1234567891011121314151617181920212223242526&#123; "version": "0.2.0", "configurations": [ &#123; "name": "(gdb) Launch", // 配置名称 "type": "cppdbg", // 这里只能为cppdbg "request": "launch", // 请求配置类型，可以为launch（启动）或attach（附加） "program": "$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe",// 将要进行调试的程序的路径 "args": [], // 程序调试时传递给程序的命令行参数，一般设为空即可 "stopAtEntry": false, // 设为true时程序将暂停在程序入口处，一般设置为false "cwd": "$&#123;workspaceFolder&#125;", // 调试程序时的工作目录，一般为$&#123;workspaceFolder&#125;即代码所在目录 "environment": [], "externalConsole": true, // 调试时是否显示控制台窗口，一般设置为true显示控制台 "MIMode": "gdb", "miDebuggerPath": "gdb.exe", // miDebugger的路径，注意这里要与MinGw的路径对应 "preLaunchTask": "g++", // 调试会话开始前执行的任务，一般为编译程序，c++为g++, c为gcc "setupCommands": [ &#123; "description": "Enable pretty-printing for gdb", "text": "-enable-pretty-printing", "ignoreFailures": true &#125; ] &#125; ] &#125; tasks.json12345678910111213141516171819202122232425&#123; // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format "version": "2.0.0", "tasks": [ &#123; "type": "shell", "label": "g++", "command": "g++.exe", "args": [ "-g", "$&#123;file&#125;", "-o", "$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe" ], "options": &#123; "cwd": "" &#125;, "problemMatcher": [ "$gcc" ] &#125; ]&#125; 配置完成后，添加一个简单的CPP文件，分别调试、直接运行一次测试功能是否正确。如果发现不能调试程序，可尝试重启编辑器。 main.cpp1234567#include &lt;iostream&gt;int main(void)&#123; std::cout&lt;&lt;"Hello World..."&lt;&lt;std::endl; return 0;&#125;]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git的使用方法]]></title>
    <url>%2F2020%2F01%2F17%2FGitUse%2F</url>
    <content type="text"><![CDATA[Git 的介绍与安装Git具有版本控制与合作开发的特点。它是一个分布式的版本控制系统，代码不仅在服务器上保存代码的完整版，还在各个客户端保存完整代码的副本。这个服务器可以是Github，也可以是自己搭建的代码管理系统，如Gitlab，码云等。 点击进入Git下载页面。 GIT的基本结构 工作区工作区就是当前的Git目录。 版本库版本库就是该目录下的.git目录。 暂存区暂存区就是用户执行add操作后，临时修改被放置的位置。暂存区的文件经过commit命令可以被提交到分支中（创建一个版本）。 GIT本地仓库的基本操作本节将介绍：Git仓库的初始化，版本切换，版本日志的查看，工作区修改情况查看，撤销等命令，命令如下：12345678910git init resp_name # 代码仓库初始化git add . # 添加所有改动到暂存区git commit -m "..." # 提交暂存区内容，形成版本git log # 打印当前版本库git reflog # 打印操作记录git reset --hard HEAD^ # 切换到上上个版本git checkout -- file_name # 将暂存区的文件恢复到工作区（丢弃工作区的改动）git reset HEAD file_name # 将版本库中的文件恢复到暂存区git diff HEAD -- file_name # 对比工作区文件与版本库文件的区别git diff HEAD HEAD^ -- file_name # 对比两个版本的某文件的区别 本地仓库的创建与提交新建一个目录，之后我们要在这里开发一个项目（编写代码）。首先使用Git Bash在该目录下执行，初始化一个Git仓库： 1git init 或1git init repository_name 完毕后，Git将创建一个版本控制系统在该目录下。之后我们创建一个文件，简单的编写一些内容，用于验证后面的版本控制的功能。例如，我们创建一个code.txt文件。内容如下： code.txt1Hello 保存退出，在Git Bash中执行以下命令，添加修改到工作区，并提交修改： 12git add . git commit -m '新增并初始化了code.txt文件' 这里的.表示该目录下的所有文件，也可以写某一个文件，还可以使用*.txt等格式书写；add操作表示将相应文件加入到版本控制系统中；commit命令表示提交修改，-m的参数表示相应的备注。 版本的切换输入如下命令，可以查看当前所有的代码版本。 1git log 或使log以简短形式呈现 12git log --pretty=onelinegit log --graph --pretty=oneline # 含有图形展示 下面我们创建第二个版本。修改刚刚的code.txt文件，内容如下 code.txt12HelloWorld 再次执行 12git add . git commit -m '修改了code.txt文件内容' 则我们添加了一个新的版本到我们的版本库中。执行git log即可查看到两个版本。 图中的commit 后的 1f96fe… 与 2f88a26… 则是对应的两个版本的版本代号。 那么如何回退到某一个版本？Git的版本是后一个版本依赖于前一个版本的，也就是后面的版本只记录修改的部分。所有的版本组成了一个链表，而HEAD指针永远指向的最新的版本。如果想找到上一个版本，可以使用HEAD^或HEAD~1；上两个版本，可以使用HEAD^^或HEAD~2。 Tips：HEAD实际上会指向master，而master才指向最新的版本。关于分支的部分可以到下一节查看。这里可以暂时理解为HEAD指向最新的版本。 回退到上一个版本，可以使用命令 1git reset --hard HEAD^ 打开文件code.txt可以看到，文件内容已经恢复到最初的版本了。如果又想切换到最新的版本，则可以使用命令 1git reset --hard 版本编号 版本编号可以使用git reflog命令，通过查看操作记录寻找版本编号。 恢复工作区的文件当工作区被编辑后，如果不知道已经做过哪些修改了，可以通过下面的命令查看当前工作区被修改的情况。 1git status 如果想撤销工作区中某一个文件的修改，可以使用如下命令 1git checkout -- 文件名 如果想撤销暂存区中某一个文件的修改，可以使用如下命令，使修改回归暂存区。回归暂存区后，再使用checkout命令使其回到工作区。 1git reset HEAD 文件名 如何对比文件与文件的不同？ 对比工作区与版本库中的文件的不同：使用diff命令，需要给出被对比的版本和文件名。1git diff HEAD -- 文件名 会输出其中的---表示版本库中的文件，+++表示工作区中的文件。下方的红色部分表示工作区中的文件相对于版本库删掉的部分，绿色的是添加的部分。 对比版本库中两个版本的文件的不同：使用diff命令，并给出被对比的两个版本和文件名。1git diff HEAD HEAD^ -- 文件名 这里输出的时候，---表示版本库中的HEAD版本，+++表示HEAD^版本。如果命令写成git diff HEAD^ HEAD，则---与+++所表示的内容也相反。 其他命令如果想删除某一个文件，并将这一改动添加到暂存区，可以使用git add命令，表示添加改动到暂存区；也可以使用git rm命令，表示添加删除操作到暂存区。示例如下： 1git rm 文件名 Git 的分支管理在Git中，所谓分支就是一个指针。例如master分支，就是一个master指针指向了该版本链表的某一个节点。如果是其他分支，例如dev分支，则是在这个链表上添加一个叫dev的指针，指向某一个版本节点。最终再由HEAD指针指向当前编辑的分支指针，也就是HEAD指向了当前编辑的分支。 分支的合并，就是将master指针指向dev所指节点，即图中第四个节点。这样就将dev分支合并到master分支当中了。 分支的删除，就是直接删除dev指针，这样就删掉了该分支。 分支的基本操作如下：123456789git branch # 查看所有分支git branch dev # 创建dev分支git branch -d dev # 删除dev分支git checkout master # 切换到master分支git checkout -b dev # 创建并切换到dev分支git merge dev # 合并dev分支到当前分支git stash # 临时存储工作区git stash list # 列出所有的工作区git stash pop # 恢复顶层的工作区 分支的查看，创建与切换使用下述命令，可以查看当前的所有分支。1git branch 如果要创建某一分支，可以使用这个命令（dev为分支名称）。1git branch dev 进行分支切换，可以直接使用如下命令。 1git checkout master 或创建并切换分支，可以一步到位，使用这个命令。1git checkout -b dev 切换的过程，就是由HEAD指向master指针变为了HEAD指向dev指针。新建的分支保留了原有分支的所有版本，也就是版本链表前边的部分，dev与master是共同享有的。这时，我们不论是add与commit操作，还是log操作，均是在dev分支上进行的。 分支的合并与分支管理当要进行分支合并，使用如下命令，但是分支合并，必须要在被合并的分支上进行，例如要将dev分支合并到master上，需要先切换到master分支上再执行合并操作。 1git merge dev 合并分为三种情况：有冲突的合并；没有冲突的快速合并；没有冲突的普通合并。 快速合并：只修改新的分支，原有分支不动。例如master指针可以直接指向dev指针的位置上，无需产生新的版本，也不会留下分支创建的记录。 没有冲突的普通合并（recursive合并）：两个分支上都有新版本产生，但是没有修改同一个文件。这种情况会在合并后产生一个新的版本。在执行合并操作后会提示提交新版本需要填写的信息。 有冲突的合并：两个分支上都有新版本产生，且修改了同一个文件。这会在合并后先产生合并失败，需要待手动修改冲突后再手动提交新的版本。 对于有冲突的合并，合并失败后，有冲突的文件会产生类似于如下内容的部分。通过手动修改这部分的内容，可以解决合并冲突。修改后，再次执行add与commit操作即可完成合并。 12345&lt;&lt;&lt;&lt;&lt;&lt; HEAD # 删除多余部分，保留需要的部分原分支的更改（被合并的分支）========新传入的更改&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev 有时为了保留分支的创建与合并的记录，我们会在合并时候禁用快速合并模式。执行方式如下：1git merge --no-ff -m "提交信息" dev 合并后，就可以删除dev分支了。这里使用如下命令删除dev分支。 1git branch -d dev Bug 分支与 stash 功能当我们遇到紧急Bug需要修复时，但又不能将当前的工作区提交到版本控制系统中，就可以使用stash功能。 1git stash stash功能可以将我们的工作区临时存储起来，存储完成后，工作区恢复到最近版本，就可以先去完成修复Bug的工作了。 修复bug时，首先创建bug分支，其次完成bug修复工作，完成后将bug分支合并到master分支即可。 待完成修复Bug的工作后，再去将我们原来的工作区恢复，继续进行工作。使用如下命令可以看到我们保存的所有的工作现场。 1git stash list 使用如下命令可以恢复工作现场。 1git stash pop Github 的使用之前的操作都是在本地计算机上所做的。但是我们合作开发的时候，往往需要借用Github之类的代码托管系统。Github的使用，与我们在本地使用Git类似，只是多了拉取与推送等操作。 创建代码仓库首先需要有一个Github账号，登录后点击New repository，输入仓库名称，配置相应设置后，点击Create repository即可。 .gitignore文件：保存了不需要同步的文件列表。 添加SSH如果是初次使用Github，需要配置SSH。 点击用户头像-&gt;settings-&gt;ssh and gpg keys-&gt;new ssh key，在这里添加SSH标题与电脑的SSH公钥。 电脑的SSH公钥生成方式：12cd ~/.ssh/ # 如果提示`No such file or directory`，可以手动的创建一个.ssh文件夹ssh-keygen -t rsa -C "your_email@youremail.com" 之后按提示输入两遍密码，这个密码可以自己设置一个。也可以什么都不写，直接两次回车键。 用记事本打开.ssh目录下的id_rsa.pub文件，复制里面的内容，到github添加即可。这个公钥也可以移动到其他电脑上使用，用于用户在push时登录Github账号使用，这里建议每台计算机一个公钥。 使用这个命令可以测试SSH是否配置正确。1ssh -T git@github.com 使用这两个命令填写用户的用户名和用户邮箱，这里主要是为了在commit时显示是谁提交的代码。这个配置会被保存到用户目录/.gitconfig文件中。12git config --global user.name "account" git config --global user.email "your_email@youremail.com" 后面的Push操作中，还会需要输入一次Github账号密码，这个账号密码与上面的邮箱和账号并不冲突，这个信息只会显示在commit记录上，而Push时输入的账号密码则是用来保证用户访问Github使用的。如果要修改本机上用于Push代码的Github账号密码，可到控制面板-&gt;用户账户-&gt;管理Windows凭据-&gt;普通凭据-&gt;git:https://user_name@github.com下修改。 Clone 代码我们先找到放置项目的目录，使用clone命令将项目克隆到本地。1git clone git@github.com:user_name/repo_name 或1git clone https://github.com/user_name/repo_name 如果在克隆的过程中出现错误，可以使用如下命令修复。 12eval "$(ssh-agent -s)"ssh-add Push 代码当代码克隆下来后，首先创建一个自己的分支进行开发。开发完成后，再提交到本地代码库。 12git add .git commit -m "..." 积累到一定的开发量，如果要推送到远程服务器，则使用如下命令进行远程推送。 1git push origin dev 其中origin是远程分支（这个名字固定），dev为本地的分支（这个名字随便起）。执行完毕后，远程仓库将创建dev分支。 首次Push时，可能会提示填写Github账号与密码。 如果本地仓库和远程仓库都有代码，且不是一套代码，这里可以使用强推操作。这样的强制操作应该尽量慎重使用。 1git push -f 也可以先将远程仓库代码与本地代码合并再推送。12git fetchgit merge 跟踪远程分支将本地分支跟踪服务器分支。跟踪后，Git将智能提示用户当前分支与服务器分支的进度差别。1git branch --set-upstream-to=origin/远程分支名称 本地分支名称 跟踪后，可以直接使用如下代码推送代码。1git push 拉去远程分支1git pull origin 远程分支名 拉去后，分支会默认进行跟踪。 管理远程分支 Remote 命令查看远程已存在的分支：1git remote 添加远程仓库，将远程仓库绑定到origin上：1git remote add origin 远程仓库 查看远程仓库：1git remote -v 可以删除远程主机：1git remote rm 主机名 可以修改主机名：1git remote rename 原主机名 新主机名 工作中使用Git 项目经理搭建项目框架，并放入代码管理工具。 普通员工在自己电脑上生成SSH公钥，交给项目经理。项目经理将SSH公钥上传至服务器。 项目经理给组员分发代码的克隆地址。组员将代码克隆到自己的电脑上。 普通员工创建自己的分支，在分支中进行每天的开发。 注意Master分支要保持发布的代码，Dev分支用于保存开发中的代码。 组员要把自己的Dev分支发布到远程Dev分支当中，但是发布之前需要确认代码可用，需要经过经理确认。 VS Code GIT在VS Code中可以看到如下图标，这个图标就是VS Code的Git可视化管理工具。 点击该按钮（源代码管理），点击+，选择当前文件夹，初始化Git本地仓库。这时，Git本地仓库就建立好了。 修改文件夹中的文件，再切换到源代码管理中，将鼠标移动到被修改的文件，可以看到右侧出现了+，点击+可以将操作暂存到暂存区。如果想取消暂存，可以再点-即可。如果选中了某个文件，可以在右侧预览该文件与工作区文件的区别。 最上方有一个√，这个是提交按钮，点击√后即可提交该版本到版本控制中。 如果想回退到某版本，还是需要借助命令行来实现。这里可以使用插件Git History查看某个版本，复制其ID，方便在命令行操作。 如果想添加远程仓库，也需要借助命令行。可以先执行初始化本地仓库操作，在本地版本库还是空的时候去pull远程代码。也可以跳过初始化操作，直接克隆远程代码。如果在本地版本库不是空的时候直接去pull代码，会出现下面的错误。 1fatal: refusing to merge unrelated histories 这时可以使用下面的命令强行拉取，这样Git就会不论之前的版本库是否一致，都会去拉去远程分支。 1git pull https://github.com/用户名/仓库名.git master --allow-unrelated-histories Visual Studio 2017（待更新）PyCharm GIT（待更新）创建本地Git仓库。VCS-&gt;VCS Operation Popup-&gt;Create Git Repositry 再次点击VCS，会与之前有所区别。左侧的文件菜单，文件名也会有颜色的变换。 右键左侧某文件或文件夹-&gt;Git-&gt;Add，将选中文件添加到版本控制中；或者在提交的时候，可以在上方的文件管理器中勾选。 查看版本历史VCS-&gt;Browse VCS Repository-&gt;Show Git Repository Log 如果想回退到某一个版本，可以右键一个版本，选择Checkout Revision。 如果想切换分支VCS-&gt;Git-&gt;Branches 使用远程仓库添加远程仓库：VCS-&gt;Checkout from Version Control 填写远程仓库地址与本地目录：https://github.com/用户名/仓库名.git 会有提示：Would you like to open ...这样就可以打开下载的代码了。 右键左侧某文件或文件夹-&gt;Git-&gt;Repository-&gt;Push推送代码到远程仓库。 PyCharm 其他技巧VCS-&gt;Git-&gt;Annotate 可以看到每一行代码的作者和日期。 自带版本控制，可以查看本地代码版本。在这里可以直接切换代码版本。VCS-&gt;Local History 参考视频 Git 版本管理链接：https://pan.baidu.com/s/1ua94DTk1MkUBlILNDN7LHQ提取码：m4un Git 练习网：https://learngitbranching.js.org/ Git 练习网 Github：https://github.com/pcottle/learnGitBranching]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发信息汇总]]></title>
    <url>%2F2020%2F01%2F14%2FWebInfoA%2F</url>
    <content type="text"><![CDATA[设计模式MVC 架构MVC 架构是Web前端，Web后端的常用架构，也是一些桌面端应用程序，手机程序的常用架构。 Model：模型，是网站访问数据库的接口。View：视图，用户能够看到的页面。Controller：控制器，用于操作数据库，处理用户业务，控制用户行为的程序。 三者的划分即是从功能的角度划分，也是从数据的处理流程的划分。一般流程为：用户发出请求-&gt;控制器处理请求-&gt;模型获取数据-&gt;视图渲染界面-&gt;用户得到反馈 ORM 框架Object：对象Relatioin：关系，MySQL中的表Mapping：映射 利用ORM框架，使对象与关系表对应，对象的属性与关系表中的字段对应，通过操作类和对象的方式来编辑修改数据库。 事件驱动算法NP 完全问题Web 概念前端后端前后端分离Ajax 技术Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。 这里就要建议用户使用IE6+以上的版本，因为之前的版本的Ajax技术的使用方法和主流浏览器不一样。如果非得使用旧版IE，那就要单独为旧版IE写一套代码了（使用jQuery框架可以屏蔽这种差异）。当然不止是Ajax，一些CSS也需要另外写一套。 CGI，WSGI 与 ASGICGI：CGI脚本简单地讲是个运行在Web服务器上的程序, 由浏览器的输入触发。这个脚本通常象服务器和系统中其他程序如数据库的桥梁。CGI是一种古老的Web技术，一般有C/C++编写，是PHP等语言出现之前就有的产物。当然，也可以用Lua，Python来编写。 WSGI：是一种服务器和客户端交互的接口规范，规定客户与服务器如何通信。 ASGI：由Django团队首创，支持WebSocket，HTTP2等服务。 运维理念GIT敏捷开发CI CD数据库常用数据库介绍数据库分类数据库分为关系型数据库和非关系型数据库。关系型数据库如MySQL，Oracle，SQL Server，SQLite等，是基于关系表的存储结构存储数据。而非关系型数据库如Redis，MongoDB等采用键值对、图等各种方式存储数据。这两类没有优劣之分，只有适用场景之分。 在关系型数据库中，一个关系（表）代表一个对象，每个关系都有多个属性（字段）。关系与关系之间也有着一对一、一对多、多对多的关联，例如老师与课程是一对多的关联，课程与学生是多对多的关联等。 关系型数据库的属性属性也分为超键，主键，候选键，外键以及普通字段。 假设有如下两个表： 学生（学号，姓名，性别，身份证号，教师编号）教师（教师编号，姓名，工资） 超键：在表中能唯一标识记录的属性集称为超键。学生表中含有学号或者身份证号的任意组合都为此表的超键。如（学号）（学号，姓名）（身份证号，性别）等。 候选键：不含有多余属性的超键称为候选键。也就是候选键属于超键，它是最小的超键，就是说如果再去掉候选键中的任何一个属性它就不再是超键了。学生表中的候选键为（学号）（身份证号）。 主键：用户选作元组标识的一个候选键程序主键。主键就是候选键里面的一个，是人为规定的，例如学生表中，我们通常会让“学号”做主键，教师表中让“教师编号”做主键。 外键：如果关系模式R1中的某属性集不是R1的主键，而是另一个关系R2的主键则该属性集是关系模式R1的外键。学生表中的外键就是“教师编号”。外键主要是用来描述两个表的关系。 关系型数据库的属性依赖字段直接含有依赖关系。一般分为三种依赖关系：部分依赖，完全依赖，传递依赖。 部分依赖：设X，Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分依赖于X。例如：通过AB能得出C，通过A也能得出C，通过B也能得出C，那么说C部分依赖于AB。 完全依赖：设X，Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全依赖于X。例如：通过AB能得出C，但是AB单独得不出C，那么说C完全依赖于AB. 传递依赖：设X，Y，Z是关系R中互不相同的属性集合，存在X→Y，Y→Z，，Y !→X，Z !→Y则称Z传递依赖于X。例如：通过A得到B，通过B得到C，但是C得不到B，B得不到A，那么成C传递依赖于A。 关系型数据库的设计范式设计数据库也要讲究原则，我们把这些原则叫做范式。一般情况下，我们设计数据库只需满足五大范式中的前三个范式。五大范式有： 第一范式 1NF：强调的是列的原子性，即列不能够再分成其他几列。每一列只代表一个属性，不能是多个属性的合并。例如，姓名和性别不能存储到一列中，而是应该存储在两列中。 第二范式 2NF：所有的非主属性都完全依赖于关键字。第二范式不存在非主属性对于部分候选关键字的部分依赖，不过允许非主属性之间存在着传递依赖。 下面是第二范式的优化实例： 假定选课关系表为： SelectCourse(学号，姓名，年龄，课程名称,成绩，学分)关键字为组合关键字：(学号，课程名称)因为存在如下决定关系：(学号，课程名称) → (姓名，年龄，成绩，学分) 这个数据库表不满足第二范式，因为存在如下决定关系： (课程名称) → (学分)(学号) → (姓名，年龄) 即存在组合关键字中的字段决定非关键字的情况。 由于不符合2NF，这个选课关系表会存在如下问题： (1) 数据冗余：同一门课程由n个学生选修，”学分”就重复n-1次；同一个学生选修了m门课程，姓名和年龄就重复了m-1次。 (2) 更新异常：若调整了某门课程的学分，数据表中所有行的”学分”值都要更新，否则会出现同一门课程学分不同的情况。 (3) 插入异常：假设要开设一门新的课程，暂时还没有人选修。这样，由于还没有”学号”关键字，课程名称和学分也无法记录入数据库。 (4) 删除异常：假设一批学生已经完成课程的选修，这些选修记录就应该从数据库表中删除。但是，与此同时，课程名称和学分信息也被删除了。很显然，这也会导致插入异常。 因此，把选课关系表SelectCourse改为如下三个表： 学生：Student(学号,姓名，年龄)；课程：Course(课程名称，学分)；选课关系：SelectCourse(学号，课程名称，成绩)。 这样的数据库表是符合第二范式的，消除了数据冗余、更新异常、插入异常和删除异常。 另外，所有单关键字的数据库表都符合第二范式，因为不可能存在组合关键字。 第三范式 3NF：每一个非主属性既不部分依赖于也不传递依赖于关键字，也就是在第二范式的基础上消除传递依赖（A＞B＞C）。 假定学生关系表为： Student(学号，姓名，年龄，所在学院,学院地点，学院电话) 关键字为单一关键字： “学号” 因为存在如下决定关系： (学号) → (姓名，年龄，所在学院，学院地点，学院电话) 这个数据库是符合2NF的，但是不符合3NF，因为存在如下决定关系： (学号) → (所在学院) → (学院地点，学院电话) 即存在非关键字段”学院地点”、”学院电话”对关键字段”学号”的传递依赖。 它也会存在数据冗余、更新异常、插入异常和删除异常的情况，读者可自行分析得知。 把学生关系表分为如下两个表： 学生：(学号，姓名,年龄，所在学院) 学院：(学院，地点，电话) 这样的数据库表是符合第三范式的，消除了数据冗余、更新异常、插入异常和删除异常。 BCNF：在第三范式的基础上进一步消除主属性对于码的部分依赖和传递依赖。BCNF需要符合3NF，并且，主属性不依赖于主属性。 假设仓库管理关系表为 StorehouseManage(仓库ID,存储物品ID,管理员ID,数量)且有一个管理员只在一个仓库工作；一个仓库可以存储多种物品。这个数据库表中存在如下决定关系：(仓库ID,存储物品ID) →(管理员ID,数量) (管理员ID,存储物品ID) → (仓库ID,数量) 所以，(仓库ID,存储物品ID)和(管理员ID,存储物品ID)都是StorehouseManage的候选关键字，表中的唯一非关键字段为数量，它是符合第三范式的。但是，由于存在如下决定关系： (仓库ID) → (管理员ID) (管理员ID) → (仓库ID) 即存在关键字段决定关键字段的情况，所以其不符合BCNF范式。它会出现如下异常情况： (1) 删除异常： 当仓库被清空后，所有”存储物品ID”和”数量”信息被删除的同时，”仓库ID”和”管理员ID”信息也被删除了。 (2) 插入异常： 当仓库没有存储任何物品时，无法给仓库分配管理员。 (3) 更新异常： 如果仓库换了管理员，则表中所有行的管理员ID都要修改。 因此，把仓库管理关系表分解为二个关系表： 仓库管理：StorehouseManage(仓库ID,管理员ID) 仓库：Storehouse(仓库ID,存储物品ID,数量) 这样的数据库表是符合BCNF范式的，消除了删除异常、插入异常和更新异常。 但是也有例外。又如，有这样一个配件管理表： WPE(仓库号，配件号，职工号，QNT) 有以下约束要求： （1）一个仓库有多名职工； （2）一个职工仅在一个仓库工作； （3）每个仓库里一种型号的配件由专人负责，但一个人可以管理几种配件； （4）同一种型号的配件可以分放在几个仓库中。 分析表中的依赖关系，可以得到： （1）职工号 -&gt; 仓库号; （2）（仓库号，配件号）-&gt; 数量 （3）（仓库号，配件号）-&gt; 职工号 （4）（职工号，配件号）-&gt; 数量 可以看到，候选键有：（职工号，配件号）(仓库号，配件号)。所以，职工号，配件号，仓库号均为主属性，数量为非主属性。显然，非主属性是直接依赖于候选键的。所以此表满足第三范式。 而我们观察一下主属性：（仓库号，配件号）-&gt; 职工号；职工号 -&gt; 仓库号。显然仓库号对于候选键（仓库号，配件号）存在传递依赖，所以不符合BCNF. 解决这个问题的办法是分拆为两个表 管理表EP（职工号，配件号，数量）工作表EW（职工号，仓库号）但这样做会导致依赖（仓库号，配件号）-&gt; 职工号丢失。虽然，不满足BCNF，也会导致一些冗余和一致性的问题。但是，将表分解成满足BCNF的表又可能丢失一些依赖。所以，一般情况下不会强制要求关系表要满足BCNF。&gt; 第四范式 4NF：当一个表中的非主属性互相独立时（3NF），这些非主属性不应该有多值。若有多值就违反了第四范式。有这样一个用户联系方式表TELEPHONE(CUSTOMERID,PHONE,CELL)CUSTOMERID为用户ID，PHONE为用户的固定电话，CELL为用户的移动电话。本来，这是一个非常简单的第3范式表。主键为CUSTOMERID，不存在传递依赖。但在某些情况下，这样的表还是不合理的。比如说，用户有两个固定电话，两个移动电话。这时，表的具体表示如下：|CUSTOMERID|PHONE|CELL||———-|—–|—-||1000|88281234|149088888888||1000|88381234|149099999999|由于PHONE和CELL是互相独立的，而有些用户又有两个和多个值。这时此表就违反第四范式。在这种情况下，此表的设计就会带来很多维护上的麻烦。例如，如果用户放弃第一行的固定电话和第二行的移动电话，那么这两行会合并吗？等等解决问题的方法为，设计一个新表NEW_PHONE(CUSTOMERID,NUMBER,TYPE)这样就可以对每个用户处理不同类型的多个电话号码，而不会违反第四范式。显然，第四范式的应用范围比较小，因为只有在某些特殊情况下，要考虑将表规范到第四范式。所以在实际应用中，一般不要求表满足第四范式。&gt; 第五范式 5NF：是最终范式。消除了4NF中的连接依赖。第五范式有以下要求：（1）必须满足第四范式（2）表必须可以分解为较小的表，除非那些表在逻辑上拥有与原始表相同的主键。第五范式是在第四范式的基础上做的进一步规范化。第四范式处理的是相互独立的多值情况，而第五范式则处理相互依赖的多值情况。有一个销售信息表SALES（SALEPERSON，VENDOR，PRODUCT）SALEPERSON代表销售人员，VENDOR代表供和商，PRODUCT则代表产品。在某些情况下，这个表中会产生一些冗余。可以将表分解为PERSON_VENDOR表（SALEPERSON，VENDOR）PERSON_PRODUCT表（SALEPERSON，PRODUCT）VENDOR­_PRODICT表（VENDOR，PRODUCT） 参考 1：超键，主键，候选键，外键参考 2：五大范式参考 3：依赖关系 连接合并左连接右连接内连接外连接视图触发器悲观锁与乐观锁SQLSQL练习 其他前端https://bost.ocks.org/mike/]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS 基础]]></title>
    <url>%2F2019%2F04%2F13%2FRosBase-1%2F</url>
    <content type="text"><![CDATA[近期做的东西和ROS有关，因此想做一些关于ROS的笔记。这篇文章主要分为以下几个部分。 ROS简介 ROS的工程架构 ROS的计算图集 ROS工具包 未完结 1. ROS简介ROS（Robot OS）是运行在Ubuntu上的次级系统，它内部由多个节点构成，每个节点即一个进程。这些节点之间各自分工，又相互合作，共同完成一些列任务。一般一个ROS工程由master节点和多个子节点构成，master负责管理各个节点，而子节点则负责各自具体的任务。 2. ROS的工程架构对于一个ROS工程，它一般分为三部分： build：编译产生的中间文件； devel：编译的结果文件； src：源代码目录。 项目架构概览 /catkin_ws /build /devel /src /folder_1 /package_1 /package_2 /folder_2 /package_3 /package_4 /metapackage 一个ROS工程的src部分，是由一个个Package组成的。每个Package一般对应一个应用或是一个节点。另外还有一类特殊的Package，叫做Metapackage，即虚包，它们没有自己的内容，但是由很多依赖，因此常用来做功能集使用。 Package架构概览： /package /msg x.msg /srv x.srv /action x.action /scripts x.py x.sh /launch x.launch /config x.yaml /include x.h /src x.cpp /other_dirs other_files CMakeLists.txt package.xml ROS支持C++和Python开发。在一个Package下，script下一般存放python文件，src、include文件夹下面分别存放了c++的.cpp文件和.h文件。launch文件夹下存放了ROS的启动文件，这些启动文件描述了这个包的启动过程中需要定义的参数，需要依赖的其它的包等内容。config文件夹下存放了一些配置文件，通过yaml语言定义。ROS自带了三种通信方式，其中msg描述了通过topic方式通信过程中的数据格式，srv、action则分别保存了service和action通信的数据格式。 3. ROS的计算图集计算图集，也叫通信架构，是ROS节点之间通信的工具。ROS节点之间的通信方式共有三种。 TopicTopic是最常见的通信方式，topic是一个独立于节点的存在。每个节点既可以发布topic，也可以订阅topic。发布者会始终无条件的发布消息，所以不论有没有其他节点在订阅消息，都会按照一定频率发布topic。并且topic的发布者可以不只是一个节点，偶尔也会有多个节点在同一个topic上发布消息。当然，订阅topic的节点也可以是多个。 一个节点如果想发布topic，必须先创建一个msg，这个msg就像是一个结构体，节点可以在这个msg中存放一些数据，然后发布到topic上。另一个节点如果想订阅这个topic，就必须按照这个msg的结构进行监听。 msg文件结构12float32 xfloat32 y Service当进行一些复杂的，计算量大的任务时，Topic却无法胜任这种情况了，因为Topic是不论有没有订阅者，发布者都会无条件发布消息，这就会导致大量的计算资源被浪费了。而Service这种通信方式正是弥补了这一缺陷。Service会根据服务请求者的请求，按需执行，因此大大节约了计算资源。 Service由服务的提供方提供相应服务，而请求方需要按照srv文件中定义的格式向服务提供方请求服务。 srv文件结构123456// 请求格式uint32 id---// 响应格式float32 xfloat32 y Action对于一些执行时间较长的服务，服务的请求方还需要知道服务的实时进度。这时候Action就派上用场了。Action除了像服务那样按需执行外，在执行的过程中，也会按照一定的频率向请求方发送一些其他的数据，这些数据都是在action文件中定义的。 action文件结构123456789// 请求格式uint32 id---// 结果格式float32 xfloat32 y---// 中间反馈格式string state 数据格式文件中的数据类型12345678boolstringint8, int16, int32, int64uint8, uint16, uint32, uint64float32, float64time, durationvariable-length array[], fixed-length array[C]other msg files 4. ROS工具包Gazebo 物理仿真工具可以对机器人进行物理仿真，可以对机器人设置重量，碰撞模型，转动惯量等设置。 Rviz 机器人可视化工具主要用于机器人调试，数据可视化操作。 MoveIt! 机械臂路径规划工具专门用于机械臂控制使用，里面集成了大量的关于机械臂的工具包。 Rqt ROS代码调试工具提供了一系列代码调试工具： rqt_graph 绘制计算图（通信架构图）rqt_plot 绘制数据变化曲线rqt_console 查看日志的工具rqt_* 其他工具 5. 未完结（停止更新）]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 博客搭建]]></title>
    <url>%2F2019%2F03%2F29%2FGitBlogInit%2F</url>
    <content type="text"><![CDATA[经过几天的研究，我终于搭起了一个Github博客网站。这篇文章将从以下几个步骤分别介绍博客的搭建。 前期准备 环境部署 配置域名（可选） 配置到个人服务器（可选） 附录 1. 前期准备首先，你需要拥有以下内容： Github账号个人域名（可选）个人服务器（可选） Github账号可以到Github官网申请，过程很简单，这里就不赘述了。个人域名可以选择阿里云，腾讯云等域名产品，申请过程也就不说了，这个不是必选，有需要的可以搞一个。 2. 环境部署这一步就正式开始搭建自己的博客了。首先是安装一些软件： GitNodeJS Git的安装过程首先到Git下载页面下载Git，这里建议下载64-bit Git for Windows Setup版本，涉及到一些环境变量的配置，安装版可以自动配置环境变量，省去手动配置的烦恼（32位系统则选择32-bit版）。 NodeJS的安装过程到NodeJS下载页面下载NodeJS，可以选择Windows 安装包 (.msi) x64版，原因同上。 安装博客框架可以选择Hexo，Jekyll等博客框架。这里以Hexo为例(参考文档，博客主题在这个官网中可以查看）。打开终端，执行如下命令安装（这一步需要管理员模式）：1npm install -g hexo 在本地新建一个目录，执行init命令初始化Hexo和Git： 12hexo initgit init 配置Github创建一个Repository，名字必须为your_user_name.github.io。（加粗部分替换为自己的用户名）下面配置SSH Key方便后续上传博客代码。在本地Git Bash中输入如下命令建立SSH Key：1ssh-keygen -t rsa -C "邮箱地址" -f ~/.ssh/github_blog_keys 中间会提示你输入文件，密码，可以不用管，直接回车即可。配置成功后，打开生成的ssh-key，新生成的公钥就是~/.ssh/github_blog_keys.pub。到在自己的账户设置中，找到 SSH and GPG keys ，点击New SSH Key 添加新的Key。将刚刚生成的公钥文件中的内容复制这里即可。 之后我们需要配置自己的Username和Email：12git config --global user.name "your_user_name" git config --global user.email "your_email" 之后将本地仓库再关联到远程仓库，首先复制远程仓库地址，到Git Bash中执行下述命令，这一步要保证当前打开的路径是Hexo的路径：1git remote add origin https://github.com/your_user_name/your_user_name.github.io.git 配置Hexo在Hexo目录下执行下面这句，安装该扩展程序。1npm install hexo-deployer-git --save 打开Hexo下的_config.yml文件，在文件末尾添加：1234deploy: type: git repository: git@github.com:your_user_name/your_user_name.github.io.git branch: master 并修改title，url，theme等配置。 开始编写下面就可以开始编写自己的博客了。执行下面命令新建Hexo页面。1hexo new "HelloWorld" 之后会在项目的/source/_post/下看到HelloWorld.md文件，使用MarkDown语言编辑这个文件即可。编辑完毕保存退出，执行下述命令开始编译项目并上传：1hexo g -d 打开连接https://your_user_name.github.io 就能看到你的博客了。也可以在本地看看效果：1hexo s 打开连接http://localhost:4000 即可看到效果。 3. 配置域名（可选）首先得需要一个域名（还得是备案过的）。这里以腾讯云的域名为例。在云解析服务中，选择你的域名点击右侧的解析，进入域名的配置页面。点击上方的添加记录，主机类型可以选www或者@，记录类型选择CNAME，记录值为your_user_name.github.io. （注意末尾有个点），之后保存即可。在你的项目中的/source/目录下创建CNAME文件，文件内容是你的一级域名，如下所示： your_user_name.cn 保存编译上传项目，过几分钟后即可配置成功。如果要开启HTTPS，则还需要购买SSH证书（有免费的证书），例如可以选择阿里云，腾讯云或CloudFlare的免费HTTPS服务。这里以腾讯云为例，选择为期一年的免费版SSH证书。在云产品中找到SSH 证书管理，点击申请免费证书，选择左侧的免费一年的证书。按照上面的要求输入相关信息，点击下一步，等待几分钟审核通过（也可能好久）。回到https://github.com/your_user_name/your_user_name.github.io 中，进入仓库设置页面，下拉找到GitHub Pages，在Custom domain中输入自己的域名，并开启Enforce HTTPS。 4. 配置到个人服务器（可选，Ubuntu版）当然，首先需要一台个人服务器。配置过程主要分为几个步骤： 安装Git-core安装Nginx配置Https 首先安装Git-core和Nginx。登入服务器执行如下代码1sudo apt-get install git-core nginx openssh-server 安装成功后，开始配置Nginx。在这里我们可以使用SSL给网站加点安全措施。首先从腾讯云上下载SSL证书（笔者用Chrome下载证书时浏览器会崩溃，于是换了一个浏览器才下载下来），压缩包下会有Nginx版对应的证书。复制里面的证书到服务器上，这里可以使用xftp或MobaXterm的sftp上传，放到 /etc/nginx/cert 目录下。在 /etc/nginx 下执行下述代码:1234sudo cp sites-available/default sites-available/default-sslsudo ln -s sites-available/default-ssl sites-enabled/sslsudo rm sites-enabled/defaultsudo vim sites-enabled/ssl 开始使用vim编辑刚刚得到的ssl文件，配置ssl访问，并设置80端口重定向到443端口。12345678910111213141516171819202122232425262728293031server &#123; # SSL configuration listen 443 ssl default_server; listen [::]:443 ssl default_server; root /home/git/tmp/blog; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name www.your_domain.com; ssl on; ssl_certificate /etc/nginx/cert/your_crt_file.crt; ssl_certificate_key /etc/nginx/cert/your_key_file.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; try_files $uri $uri/ =404; &#125;&#125;server &#123; listen 80; listen [::]:80; location / &#123; rewrite ^(.*)$ https://$host$1 permanent; &#125;&#125; 配置完成后，记得在腾讯云的域名解析上添加一条A记录，来指向自己的服务器IP地址。完成后别忘了访问一下自己的网站，看看是否能够访问成功。下面开始部署网站到自己的服务器上了。在自己的服务器上，首先搭建一个Git的服务器。首先将之前的github_blog_keys.pub中的公钥上传到服务器上，保存到 ~/.ssh/authorized_keys 文件中。在自己的服务器中创建git账号。12sudo useradd gitsudo passwd git 输入git账号的密码，之后登陆到git账号中，创建仓库。123456su gitcd ~git --bare init blog.git# 这两步后面有用mkdir tmpmkdir tmp/blog 这里回到本地，先测试一下能否正常访问自己的git。1git clone git@your_server_ip:~/blog.git 成功后利用hexo将博客代码部署到自己的服务器上。首先先配置自己的_config.yml文件。打开_config.yml文件，修改deploy部分的代码：1234567deploy: - type: git repository: git@github.com:your_user_name/your_user_name.github.io.git branch: master - type: git repository: git@your_server_ip:~/blog branch: master 保存后使用hexo提交博客代码。12hexo cleanhexo g -d 这样就可以提交代码到服务器上保存了。但是目前网站依然是无法访问的，需要再编写一个自动部署网站的脚本。进入服务器，进入到目录 /home/git/blog.git/hooks 下，创建提交后执行的脚本。12345#!/bin/bash -lGIT_REPO=/home/git/blog.gitTMP_GIT_CLONE=/home/git/tmp/blogrm -rf $&#123;TMP_GIT_CLONE&#125;git clone $GIT_REPO $TMP_GIT_CLONE 创建完成后，修改一下权限，并重启Nginx。123chmod +x post-receivechmod 777 -R /home/git/tmp/blogservice nginx restart 这次在客户端用hexo重新部署一次代码。1hexo d 到此结束，可以收工了。 附录A Hexo常用命令Hexo初始化1hexo init 编译到静态页面12hexo generate # 简写 hexo g 部署到Github上12hexo deploy # 简写 hexo d 使用本地浏览器查看 ( http://localhost:4000 )12hexo server # 简写 hexo s 创建新的Page1hexo new 配置主题 _config.yml首先给Hexo配置一个主题，之后就可以在Hexo的主题的目录下看到_config.yml文件。以NexT主题为例，目录下的_config.yml文件中有如下选项： Site Information Settings 站点信息设置 SEO Settings SEO设置 Menu Settings 菜单设置，包括显示的栏目，栏目图标等 Scheme Settings 主题风格设置 Sidebar Settings 菜单栏设置，包括友情链接，个人头像，侧边栏位置等 Post Settings 主页文章显示设置 Misc Theme Settings 主题其他设置，字体，代码风格等 Third Party Services Settings 第三方服务，数学插件，评论插件，统计插件，搜索插件等 Tags Settings 标签设置 Animation Settings 动画设置 创建分类与标签使用如下两个命令分别创建分类与标签：1234# 创建分类hexo new page categories# 创建标签hexo new page tags 创建完成后，需要在主题配置中开启相应的选项（例如NexT主题中的menu）。 安装插件图片本地化插件在Hexo目录下执行下面语句：1npm install https://github.com/CodeFalling/hexo-asset-image --save 之后配置根目录下的_config.yml中：1post_asset_folder:true 之后再创建文章的时候，就会同时在同一目录下创建一个与文章同名的文件夹，里面可以存放文章中使用到的图片。在文章中引用文件夹下的图片pic.jpg方法如下：1![image](pic.jpg) 评论插件这里推荐两款评论插件，来必得与LeanCloud。来必得支持多账号登录，但是评论数据无法导出，而LeanCloud是匿名评论，提供的对象存储支持每日30,000次请求，总共10GB存储。 搜索插件这里使用Local Search，直接安装即可实现本地搜索。安装代码如下：1npm install hexo-generator-searchdb --save 回到博客的_config.yml中添加如下设置：12345search: path: search.xml field: post format: html limit: 10000 在主题的_config.yml中找到local_search，并启用该功能：123# Local searchlocal_search: enable: true 动态壁纸线条背景：在主题文件夹下找到layout/_layout.swig文件，在&lt;/body&gt;上方添加代码123&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125; Live2D插件首先安装Live2D插件：1npm install --save hexo-helper-live2d 这里推荐到xiazeyu这里找一个喜欢的模型安装一下，我随便选一个为例：1npm install --save live2d-widget-model-hibiki 回到博客的_config.yml文件中，在最后添加代码，具体可以看EYHN里面的介绍：12345678910111213141516171819# Live2D## https://github.com/EYHN/hexo-helper-live2dlive2d: enable: true # enable: false scriptFrom: local # 默认 pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径) pluginJsPath: lib/ # 脚本文件相对与插件根目录路径 pluginModelPath: assets/ # 模型文件相对与插件根目录路径 # scriptFrom: jsdelivr # jsdelivr CDN # scriptFrom: unpkg # unpkg CDN # scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # 你的自定义 url tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中 debug: false # 调试, 是否在控制台输出日志 model: use: live2d-widget-model-hibiki # npm-module package name # use: wanko # 博客根目录/live2d_models/ 下的目录名 # use: ./wives/wanko # 相对于博客根目录的路径 # use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # 你的自定义 url pdf 插件安装PDF插件：1npm install --save hexo-pdf 在主题配置文件next/_config.yml中找到PDF配置，打开开关。 123456789pdf: enable: true # Default height height: 500px pdfobject: # Use 2.1.1 as default, jsdelivr as default CDN, works everywhere even in China cdn: //cdn.jsdelivr.net/npm/pdfobject@2.1.1/pdfobject.min.js # CDNJS, provided by cloudflare, maybe the best CDN, but not works in China #cdn: //cdnjs.cloudflare.com/ajax/libs/pdfobject/2.1.1/pdfobject.min.js]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
        <tag>博客</tag>
      </tags>
  </entry>
</search>
