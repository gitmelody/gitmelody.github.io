<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PythonFirst]]></title>
    <url>%2F2020%2F02%2F09%2FPythonFirst%2F</url>
    <content type="text"><![CDATA[数据类型数字型数字型包括： int：20 float：3.3 bool：True（True = 1, False = 0） complex：4+2j, complex(4, 2) 运算方式有：加(+)，减(-)，乘(*)，除-浮点(/)，除-整数(//)，取余(%)，乘方(**) 常用方法： range(n)：产生一个从0到n的序列。 range(m, n)：产生一个从m到n的序列。 sum()：对列表的所有元素求和 all()：判断列表中所有元素是否都是True any()：判断列表中是否包含True 运算方法： abs() max()：参数可以为序列。 min()：参数可以为序列。 pow()：乘幂运算。 round()：四舍五入，可以指定小数点后的位数。 math.ceil()：向上取整。 math.floor()：向下取整。 math.exp() math.fabs() math.log() math.log10() math.modf()：返回小数部分和整数部分（元组，先小数，后整数）。 math.sqrt() math.pi：内置常量，PI math.e：内置常量，E 随机函数： random.choice()：从给定的序列中随机选择一个元素。 random.randrange([start,] stop [, step])：在指定范围内按照基数底层的集合中获取一个随机数。基数默认为1。 random.random()：生成一个0到1之间的实数。 random.seed()：改变种子生成器。 random.shuffle()：将给定的序列随机排列。 random.uniform(x, y)：生成一个x到y之间的实数。 字符串可以使用&#39;inline&#39;、&quot;inline&quot;、&#39;&#39;&#39;multi lines&#39;&#39;&#39;方式。可以使用转义字符。索引从前面开始为0；从后面开始为-1。字符串只读，不能修改某一个字符。 运算方式有（设str_a=&quot;123456789&quot;）： 加(str_a + str_b)：字符串拼接。 乘(str_a * 2)：字符串重复。 切片(str_a[0:-1], str_a[3:])：返回字串”12345678”，”456789”，遵循左闭右开。 禁用转义字符(r&#39;\n&#39;)：返回”\n”，R作用一以。 in：查看是否在其中。 not in %：格式字符串 字符 描述 字符 描述 字符 描述 \ 续行 \\ 反斜线 \&#39; 单引号 \&quot; 双引号 \a 响铃 \b 退格 \0 空 \n 换行 \v 纵向制表符 \r 回车 \f 换页 \t 横向制表符 \oYY 八进制 \xYY 十六进制 常用方法 join()：连接字符串 split()：分隔字符串，返回列表 count(s)：返回子串s出现次数 len()：返回字符串长度 strip()：去掉两边空格 find()：查找子串位置，未找到返回 -1 replace(old, new)：替换子串 bytes.decode(encoding=’UTF-8’,errors=’strict’)：解码为字符串 encode(encoding=’UTF-8’,errors=’strict’)：编码为二进制数据 ljust(width, fillchar)：左对齐，返回填充后的字符串 rstrip(width, fillchar)：右对齐，返回填充后的字符串 center(width, fillchar)：居中对齐，返回填充后的字符串 原始格式化字符串原始格式化字符串： %c：字符 %s：字符串 %d：整数 %u：无符号整数 %o：无符号八进制 %x：无符号十六进制 %X：无符号十六进制（大写） %f：浮点，可以指定小数点后位数 %e：科学计数法 %E：科学计数法 %g：作用同%f%e %G：作用同%f%E %p：变量地址 例如：1"%s use python %f" % ('User', 3.7) 辅助指令： *：定义宽度或小数点精度 -：左对齐 +：在正数前面显示加号 &lt;sp&gt;：在正数前面显示空格 #：在八进制数前面显示零(‘0’)，在十六进制前面显示’0x’或者’0X’(取决于用的是’x’还是’X’) 0：显示的数字前面填充’0’而不是默认的空格 %：’%%’输出一个单一的’%’ var：映射变量(字典参数) m.n.：m 是显示的最小总宽度,n 是小数点后的位数 参考 增强型格式化字符串增强型写法：1234567891011121314# 指定输出位置"&#123;1&#125; &#123;0&#125; &#123;1&#125;".format("hello", "world")# 输出'world hello world'# 指定输出"姓名：&#123;name&#125;, 年龄 &#123;age&#125;".format(name="John", age=3)# 输出列表my_list = ['First', 'Second']print("姓：&#123;0[0]&#125;, 名 &#123;0[1]&#125;".format(my_list))# 格式化输出"&#123;:.2f&#125;".format(3.1415926) # 输出 3.14# 转义输出"&#123;&#123;&#125;&#125;".format() # 输出 &#123;&#125; 格式 描述 格式 描述 格式 描述 {:.2f} 保留小数点后两位 {:+.2f} 带符号保留 {:.0f} 不带小数 {:0&gt;2d} 数字补零 (填充左边, 宽度为2) {:x&lt;4d} 数字补x (填充右边, 宽度为4) {:x&lt;4d} 数字补x (填充右边, 宽度为4) {:,} 以逗号分隔 {:.2%} 百分比格式 {:.2e} 指数记法 {:&gt;10d} 右对齐 {:&lt;10d} 左对齐 {:^10d} 中间对齐 参考 f-stringPython 3.6 新增写法：字符串以f开头，字符串中的变量将会自动运算解析为结果。 123f'Hello &#123;name&#125;'f'&#123;1+2&#125;'f'&#123;w["name"]&#125;: &#123;w["age"]&#125;' Unicode 字符串在Python2中，普通字符串是以8位ASCII码进行存储的，而Unicode字符串则存储为16位unicode字符串，这样能够表示更多的字符集。使用的语法是在字符串前面加上前缀 u。 在Python3中，所有的字符串都是Unicode字符串。 列表列表中的元素的类型可以不同。 运算方式有（设list_a=[1, 2, &quot;a&quot;, True]）： 加(list_a + list_b)：列表拼接。 乘(list_a * 2)：列表重复。 切片(list_a[0:-1], list_a[3:])：返回列表[1, 2, &quot;a&quot;]，[True]。 常用方法： count()：统计某元素出现次数 len()：返回元素个数 append()：在末尾添加元素 pop(n)：移除第n个元素，默认最后一个 index()：返回该元素的索引 insert()：插入一个元素 extend()：在末尾追加另一个列表的所有元素 remove()：移除第一个此元素 reverse()：翻转列表 sort()：元素排序 clear()：清空 copy()：复制 del list[x]：删除第x个元素 内置函数： filter：过滤函数 12345def is_odd(n): return n % 2 == 1 newlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])print(newlist) # [1, 3, 5, 7, 9] map：映射函数 12345def square(x): return x ** 2map(square, [1,2,3,4,5]) # [1, 4, 9, 16, 25]map(lambda x: x ** 2, [1, 2, 3, 4, 5]) # 使用 lambda 匿名函数 reduce：累积函数 12345def add(x, y) : # 两数相加 return x + y reduce(add, [1,2,3,4,5]) # 计算列表和：1+2+3+4+5=15reduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数 元组元组的元素不可修改。元组中的元素的类型可以不同。如果元组包含了对象，那么对象是可以修改的。构造空元组写作tup1 = ()，构造单元素元组tup2 = (20,)，注意有逗号。 运算方式有（设tuple_a=(1, 2, &quot;a&quot;, True)）： 加(tuple_a + tuple_b)：元组拼接。 乘(tuple_a * 2)：元组重复。 切片(tuple_a[0:-1], tuple_a[3:])：返回元组(1, 2, &quot;a&quot;)，(True)。 集合集合中的元素类型必须一致。集合中的元素不能重复。创建一个空集合必须使用set()。 运算方式有： 求差集(a - b) 求并集(a | b) 求交集(a &amp; b) 求二者中不同时拥有的元素(a ^ b) 常用操作： add()：添加元素 update()：批量添加元素 remove()：移除元素，如果不存在，会报错 discard()：移除元素，如果不存在，不会报错 pop()：随机删除一个 len()：求元素个数 clear()：情况集合 x in s：判断使用包含元素 字典字典中的元素按照键值对存取。字典中Key必须是不可变的数据类型（字符串，元组，常量）。字典中Key值必须是唯一的。 常用操作： clear()：清空字典 copy()：浅拷贝 get()：返回某键的值，否则返回default值 key in dict：判断是否有该key pop()：删除某个key 类型转换int()：转换为整型，可以接受：字符串，Bytes对象，数字。float()：转换为浮点，可以接受：字符串，数字。str()：转换为字符串，可接受几乎所有对象，转换结果适用于人类阅读。repr()：转换为字符串，可接受几乎所有对象，转换结果适用于机器使用。eval()：将字符串作为Python语句执行，返回执行结果。tuple()：转化为元组，可以接受：列表，字符串等。list()：转化为列表，可以接受：元组，字符串等。set()：转化为集合。dict()：转化为字典，可以接受：(key, value)的序列。chr()：整数转化为字符。ord()：字符转整数。unichr()：整数转换为Unicode字符。hex()：整数转十六进制字符串。oct()：整数转八进制字符串。 chr()：将数字按照ASCII转化为字符ord()：转换ASCII字符为整数bytearray()：返回一个Byte数组，参数是整数n，则初始化数组长度为n；如果是字符串，则将字符串转换为Bytescompile(source, filename, mode)：将字符串编译为字节码，mode可以为exec、eval、single 内置函数input()：标准输入print()：标准输出12345678# 输出的结尾：以逗号结尾，默认是以换行结尾print(end=',')# 输出对象间隔号：以逗号间隔，默认是空格print(sep=',')# 输出到文件print(file='')# 是否强制刷新流print(flush=',') exec()：执行Python语句，无返回值eval()：将给定表达式用Python执行，并返回执行结果execfile(filename)：执行一个文件，返回执行结果file()：创建一个FILE对象，同open()memoryview()：查看对象的在内存的存储形式，对使用缓冲区的地方非常友好，尤其是对str与bytearray123456789101112a = 'aaaaaa'ma = memoryview(a)ma.readonly # True，只读的memoryviewmb = ma[:2] # 不会产生新的字符串a = bytearray('aaaaaa')ma = memoryview(a)ma.readonly # False，可写的memoryviewmb = ma[:2] # 不会会产生新的bytearraymb[:2] = 'bb' # 对mb的改动就是对ma的改动mb.tobytes() # 'bb' ma.tobytes() # 'bbaaaa' globals()：返回当前位置的全局变量，字典形式locals()：返回当前位置的局部变量，字典形式 id()：获取对象的内存地址hash()：返回对象的哈希值super()：调用父类vars()：将对象转化为字典 reload()：重新加载模块__import__()：动态加载类或模块help()：查看模块或函数的帮助信息 查看类型123type(x) # 查看变量的类型，子类与父类不一致。isinstance(x, int) # 查看变量是否是某种类型，子类和父类被认为一直。issubclass(father, son) # 判断是否为子类 基本操作for 循环1234567891011121314151617181920212223# 遍历列表for x in x_list: pass# 遍历字符串for c in "abcdefg": pass# 带索引遍历for i, name in enumerate(name_list, start_index): print(f'index is &#123;i&#125;,name is &#123;name&#125;')# 打包成元组遍历 a = [1,2,3], c = [4,5,6,7,8], zip(a,c) --&gt; [(1, 4), (2, 5), (3, 6)]for i in zip(albums, years): print(i)# 单行 for 循环s.split() for s in sentence# 相当于for s in sentence: s.split()# 遍历字典for k, v in knights.items(): print(k, v)# 遍历排序后的集合for f in sorted(set(basket)): print(f) 迭代器1234567list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=" ")it = iter(list) # 创建迭代器对象print (next(it)) # 输出迭代器的下一个元素print (next(it)) # 输出迭代器的下一个元素 StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 __next__() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 123456789101112131415161718class MyNumbers: def __iter__(self): self.a = 1 return self def __next__(self): if self.a &lt;= 20: x = self.a self.a += 1 return x else: raise StopIteration myclass = MyNumbers()myiter = iter(myclass) for x in myiter: print(x) 在 Python 中，使用了 yield 的函数被称为生成器。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 1234567891011121314151617import sys def fibonacci(n): # 生成器函数 - 斐波那契 a, b, counter = 0, 1, 0 while True: if (counter &gt; n): return yield a a, b = b, a + b counter += 1f = fibonacci(10) # f 是一个迭代器，由生成器返回生成 while True: try: print (next(f), end=" ") except StopIteration: sys.exit() 不定长传参转为元组传入 *1def printinfo( arg1, *vartuple ): 转为字典传入 **1def printinfo( arg1, **var_args_dict ): 匿名函数1sum = lambda arg1, arg2: arg1 + arg2 强制位置参数/前面的参数不能使用关键字参数。*后面的参数必须使用关键字参数。 12def f(a, b, /, c, d, *, e, f): print(a, b, c, d, e, f) 数据结构堆栈可以使用列表作为堆栈。 123stack = [1, 2, 3]stack.append(4)x = stack.pop() 可以使用模块。 12345from queue import LifoQueuestack = LifoQueue()stack.put(1)while not stack.empty(): x = stack.get() 队列使用列表作为队列，但是效率不高。 123que = [1, 2, 3]que.append(4)x = stack.popleft() 可以使用模块。 12345from queue import Queueque = Queue()q.put(1)while not q.empty(): x = q.get() 优先队列123456789101112131415from queue import PriorityQueueq = PriorityQueue()q.put(Task(5, 'Mid-level job'))while not q.empty(): next_job = q.get()class Task(object): def __init__(self, priority, description): self.priority = priority self.description = description return # 运算符重载 def __lt__(self, other): return self.priority &lt; other.priority 列表推导式可以方便用于创建列表 1234vec1 = [2, 4, 6]vec2 = [4, 3, -9][3*x for x in vec1] # [6, 12, 18][x*y for x in vec1 for y in vec2] # [8, 6, -18, 16, 12, -36, 24, 18, -54] 模块与包__name__属性来使该程序块仅在该模块自身运行时执行。 dir() 函数可以找到模块内定义的所有名称。以一个字符串列表的形式返回： 包：管理 Python 模块命名空间的形式，如sound包下的effects包下的echo模块，使用方法： 1import sound.effects.echo 对应的目录结构为： sound/ __init__.py effects/ __init__.py echo.py 包的下面必须有__init__.py文件（可以是空文件），否则将不会识别为包。 如果包定义文件 __init__.py 存在一个叫做 __all__ 的列表变量，那么在使用 from package import * 的时候就把这个列表中的所有名字作为包内容导入。 读写文件使用open()可以打开文件，其完整的参数表为： file: 必需，文件路径（相对或者绝对路径）。 mode: 可选，文件打开模式 buffering: 设置缓冲 encoding: 一般使用utf8 errors: 报错级别 newline: 区分换行符 closefd: 传入的file参数类型 opener: mode指定了文件打开模式，默认为只读，常见方式有： 模式 描述 模式 描述 模式 描述 x 写模式，文件已存在则报错 b 二进制 + 读写 r 只读 rb 只读，二进制 r+ 读写 rb+ 读写，二进制 w 只写 wb 只写，二进制 w+ 读写 wb+ 读写，二进制 a 追加写 ab 追加写，二进制 a+ 追加读写 ab+ 追加读写，二进制 123456789101112131415161718192021f = open(filename)# 读取n个字符或字节，默认是全部内容f.read(n)# 读取一行，如果为空，说明已经最后一行了f.readline()# 读取所有行f.readlines()# 写入f.write(data)# 返回当前指针位置f.tell()# 移动指针位置：0 从开头向后移动m个字节，1 从当前位置向后移动m个字节，2 从结尾向后移动m个字节f.seek(m, 0)# 获取文件描述符f.fileno()# 判断是否为终端设备f.isatty()# 刷新缓冲区到文件f.flush()# 关闭文件，释放资源f.close() 如果觉得打开文件再关闭文件操作繁琐，Python还提供了with as功能，可以打开后不管释放： 123# 执行完毕自动释放with open("/tmp/file.txt") as file: data = file.read() with语句不仅可以用来操作文件，线程等资源也可以使用。 pickle模块，可以用来序列化和反序列化对象。利用这个模块，我们可以用来保存数据结构到文件中。 1234import picklepickle.dump(obj, file)x = pickle.load(file) OS 模块目录与权限： 123456789101112131415161718192021222324252627282930313233343536# 检验权限模式，尝试使用UserID，GroupID访问目录，检验是否有权限访问。mode：# os.F_OK 测试path是否存在。# os.R_OK 测试path是否可读。# os.W_OK 测试path是否可写。# os.X_OK 测试path是否可执行。os.access(path, mode)# 更改当前进程的看到的根目录# 例如 os.chroot('/tmp')# 则 对于进程'/'目录就是系统的'/tmp'目录os.chroot(path)# 切换工作目录os.chdir(path)# 获取工作目录os.getcwd()# 更改权限os.chmod(path, mode)# 更改文件所有者os.chown(path, uid, gid)# 获取路劲下的文件和文件夹os.listdir(path)# 创建路径，mode为权限 0o755os.makedirs(path[, mode])# 删除路径为path的文件os.remove(path)# 删除空目录，如果非空则异常os.rmdir(path)# 重命名os.rename(src, dst)# 获取path信息os.stat(path)# 获取文件系统信息os.statvfs(path) 文件：123456789101112131415161718192021222324252627282930# 获取文件描述符fx = f.fileno()fx = os.open(filepath, os.O_RDONLY)# 关闭文件os.close(fx)# 关闭所有文件，左闭右开os.closerange(fx, fy)# 复制文件描述符os.dup(fx)# 通过描述符改变工作目录，fx指向目录os.fchdir(fx)# 修改文件所有权os.fchown(fx, uid, gid)# 强制写入磁盘os.fdatasync(fx)# 打开的文件的系统配置信息，name，'PC_LINK_MAX' 文件最大连接数，'PC_NAME_MAX' 文件名最长长度os.fpathconf(fx, name)# 获取描述符状态，包括设备信息，文件修改时间，用户ID等os.fstat(fx)# 获取描述符状态，包括文件系统块大小，可用块数，文件结点总数os.fstatvfs(fx) # 创建命名管道，mode为权限 默认0o666os.mkfifo(path[, mode])# 打开一个终端os.openpty()# 创建一个管道os.pipe()# 从command打开一个管道，command 使用的命令，mode r默认 w，bufsize 0无缓冲 1有缓冲os.popen(command[, mode[, bufsize]]) os.path 模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 绝对路径os.path.abspath(path)# 文件名os.path.basename(path)# 文件路径os.path.dirname(path)# 路径是否存在os.path.exists(path)# 文件访问时间os.path.getatime(path)# 文件修改时间os.path.getmtime(path)# 路径创建时间os.path.getctime(path)# 文件大小os.path.getsize(path)# 是否为绝对路径os.path.isabs(path)# 是否为文件os.path.isfile(path)# 是否为目录os.path.isdir(path)# 是否为链接os.path.islink(path)# 是否为挂载点os.path.ismount(path)# 合并目录与文件名os.path.join(path1[, path2[, ...]])# 转换path大小写与斜杠os.path.normcase(path)# 规范path形式os.path.normpath(path)# 返回path真实路径os.path.realpath(path)# 判断目录，文件是否相同os.path.samefile(path1, path2)# 判断是否指向同一文件os.path.sameopenfile(fp1, fp2)# 分割路径与文件名 元组os.path.split(path)# 返回驱动器名和路径 windows下 元组os.path.splitdrive(path)# 分割路径，返回路径名 扩展名 元组os.path.splitext(path)# 分割为加载点与文件os.path.splitunc(path)# 遍历path，每个目录都调用visit函数 visit(arg, dirname 目录, names 目录下所有文件名)os.path.walk(path, visit, arg) 异常与断言123456789101112try: pass# except 后可加元组，可以包含多个Exceptionexcept (ZeroDivisionError, KeyboardInterrupt): passelse: passexcept Exception: pass# finally不论发生异常与否都会执行，如果异常未被接住，则会在finally执行完毕后抛出finally: pass Python assert（断言）用于判断一个表达式，在表达式条件为 False 的时候触发异常。 1234# 语法 assert expression[, arguments] # 例如assert 3 + 2 == 5, '结果不为 5'# 输出 AssertionError: 结果不为 5 对象类的属性与方法的访问权限：123456# 默认为公有def fun():# 保护 一个下划线def _fun():# 私有 两个下划线def __fun(): 类的专用方法有：1234567891011121314151617181920212223242526272829303132333435363738394041# 构造函数def __init__():# 析构函数def __del__():# 打印def __repr__():# 按索引赋值def __setitem__():# 按索引取值def __getitem__():# 获取长度def __len__():# 比较def __cmp__():# 调用def __call__():# 运算符重载# 加def __add__():# 减def __sub__():# 乘def __mul__():# 除def __truediv__():# 取余def __mod__():# 乘方def __pow__():# 小于def __lt__():# 等于def __eq__():# 大于def __gt__():# 小于等于def __le__():# 不等于def __ne__():# 大于等于def __ge__(): 在类的继承中，子类不重写 __init__，实例化子类时，会自动调用父类定义的 __init__。子类重写 __init__，就不会调用父类的初始化函数。如果都想执行，可以使用super()调用。 标准库shutilshutil模块提供了针对日常的文件和目录管理任务： 123import shutilshutil.copyfile('a.txt','b.txt')shutil.move('/dir_a/a.txt','/dir_b') blogglob模块提供了一个函数用于从目录通配符搜索中生成文件列表 12import globglob.glob('*.py') # ['primes.py', 'random.py', 'quote.py'] syssys可以读取命令行参数 12import sysprint(sys.argv) # ['demo.py', 'arg1', 'arg2', 'arg3'] 也可以重定向输出，如stdin，stdout，stderr 1sys.stderr.write('Warning, log file not found starting a new one\n') rere模块为高级字符串处理提供了正则表达式工具。 12345import rere.findall(r'\bf[a-z]*', 'which foot or hand fell fastest')# ['foot', 'fell', 'fastest']re.sub(r'(\b[a-z]+) \1', r'\1', 'cat in the the hat')# 'cat in the hat' datetimedatetime模块为日期和时间处理同时提供了简单和复杂的方法。 12345678910111213141516171819from datetime import date, time, datetime# 格式化输出now = date.today()now.strftime("%m-%d-%y. %d %b %Y is a %A on the %d day of %B.")# '12-02-03. 02 Dec 2003 is a Tuesday on the 02 day of December.'# 日期天数差 birthday = date(1964, 7, 31)age = now - birthdayage.days # 14368# 当前时间戳time_stamp = time.time()# 转为日期时间datetime.fromtimestamp(time_stamp)# 转为时间戳int(time.mktime(today.timetuple()))# 补时差 today + datetime.timedelta(hours=8) 数据压缩以下模块直接支持通用的数据打包和压缩格式：zlib，gzip，bz2，zipfile，以及 tarfile。 1234567import zlibs = b'witch which has which witches wrist watch'len(s) # 41t = zlib.compress(s)len(t) # 37zlib.decompress(t) # b'witch which has which witches wrist watch'zlib.crc32(s) # 226805979 计时器123456789101112from timeit import TimerTimer('t=a; a=b; b=t', 'a=1; b=2').timeit()# 测试函数调用时间def test(): L = [] for i in range(100): L.append(i)if __name__ == '__main__': import timeit print(timeit.timeit("test()", setup="from __main__ import test")) 测试doctest模块提供了一个工具，扫描模块并根据程序中内嵌的文档字符串执行测试。12345678910def average(values): """Computes the arithmetic mean of a list of numbers. &gt;&gt;&gt; print(average([20, 30, 70])) 40.0 """ return sum(values) / len(values)import doctestdoctest.testmod() # 根据所给注释，自动验证本文档所有函数 unittest模块可以在一个独立的文件里提供一个更全面的测试集。 1234567891011import unittestclass TestStatisticalFunctions(unittest.TestCase): def test_average(self): self.assertEqual(average([20, 30, 70]), 40.0) self.assertEqual(round(average([1, 5, 7]), 1), 4.3) self.assertRaises(ZeroDivisionError, average, []) self.assertRaises(TypeError, average, 20, 30, 70)unittest.main() # 从命令行调用，执行所有测试 进阶内容正则表达式 模式 描述 模式 描述 模式 描述 ^ 开头 $ 末尾 . 任意字符，除了换行符 [...] 一组字符 [^...] 不在[]中的字符 re* 匹配0个或多个的表达式 re+ 匹配1个或多个的表达式 re? 匹配0个或1个表达式片段 re{n} 匹配n个前面表达式片段 re{n,} 精确匹配n个前面表达式片段 re{n,m} 匹配 n 到 m 次由前面的正则表达式片段 `a b` 匹配a或b (re) 匹配括号内的表达式 (?#...) 注释 \w 数字字母下划线 \W 非数字字母下划线 \s 任意空白字符 \S 任意非空字符 \d 任意数字 \D 任意非数字 \A 字符串开始 \Z 字符串结束或换行前 \z 字符串结束 \G 最后匹配完成的位置 \b 单词边界 \B 非单词边界 \n,\t 换行符，制表符 \1,…,\9 匹配第n个分组的内容 re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。 1234567891011# pattern 正则表达式# string 要匹配的字符串# flag 标志位# 未匹配返回Noneprint(re.match('a', 'a.b.c').span()) # span 返回匹配开始与结束的位置 返回(0, 1)print(re.match('c', 'a.b.c')) # 返回 Noneobj = re.match(pattern, string, flags=0)obj.group() # 原始对象obj.group(1) # 获取匹配的值obj.group(2) # 获取匹配的值 re.search 扫描整个字符串并返回第一个成功的匹配。 1re.search(pattern, string, flags=0).span() # 返回匹配的位置 re.sub用于替换字符串中的匹配项 1234# repl 替换的字符串，也可以是函数# count 最大替换次数# 返回 替换次数re.sub(pattern, repl, string, count=0, flags=0) compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。 1234pt = re.compile(pattern[, flags])# 例如pt = re.compile(r'\d+')m = pt.match("abcd") findall()在字符串中找到正则表达式所匹配的所有子串，并返回一个列表。 1234pt.findall(string[, pos[, endpos]])# 例如pt = re.compile(pattern[, flags])pt.findall("abcd") split 方法按照能够匹配的子串将字符串分割后返回列表 1re.split(pattern, string[, maxsplit=0, flags=0]) 网络HTTPHTTP请求头部格式为：HTTP 字段名: 字段内容，主要有以下几种： 头部 描述 头部 描述 Content-type:text/html 请求的MIME信息 Expires: Date 响应过期的日期和时间 Location: URL 重定向接收方到非请求URL的位置 Last-modified: Date 请求资源的最后修改时间 Content-length: N 请求的内容长度 Set-Cookie: String 设置Http Cookie HTTP响应头部还包括了： Allow：服务器支持的协议 Content-Encoding：编码 Location：如果是重定向301，则跳转到该页面 Date：服务器时间 Last-Modified：文档最后修改时间 Server：服务器名字 Set-Cookie：设置cookie 比较复杂的是Content-type，它包含： text/html ： HTML格式 text/plain ：纯文本格式 text/xml ： XML格式 image/gif ：gif图片格式 image/jpeg ：jpg图片格式 image/png：png图片格式 application/xhtml+xml：XHTML格式 application/xml：XML数据格式 application/atom+xml：Atom XML聚合格式 application/json：JSON数据格式 application/pdf：pdf格式 application/msword：Word文档格式 application/octet-stream：二进制流数据（如常见的文件下载） multipart/form-data：需要在表单中进行文件上传时，就需要使用该格式 SocketSocket API 中定义的协议族（family）参数是指调用者期待返回的套接字地址结构的类型，主要包含（AF有时也写作PF）： 12345678910111213141516171819202122232425262728293031323334353637383940414243AF_UNSPEC 0 /* 未指定 */ AF_UNIX 1 /* Unix domain sockets */AF_LOCAL 1 /* POSIX name for AF_UNIX */AF_INET 2 /* IPv4 */AF_AX25 3 /* 业余无线电 AX.25 */AF_IPX 4 /* Novell IPX */AF_APPLETALK 5/* AppleTalk 地址 */AF_NETROM 6 /* 业余无线电 NET/ROM */AF_BRIDGE 7 /* 多协议网桥 */AF_ATMPVC 8 /* ATM PVCs */AF_X25 9 /* 保留 for X.25 project */AF_INET6 10 /* IPv6 */AF_ROSE 11 /* 业余无线电 X.25 PLP */AF_DECnet 12 /* 保留 for DECnet project */AF_NETBEUI 13/* 保留 for 802.2LLC project*/AF_SECURITY 14/* Security callback pseudo AF */AF_KEY 15 /* PF_KEY key management API */AF_NETLINK 16 /* Only for Linux */AF_ROUTE AF_NETLINK /* Alias to emulate 4.4BSD */AF_PACKET 17 /* Packet family */AF_ASH 18 /* Ash */AF_ECONET 19 /* Acorn Econet */AF_ATMSVC 20 /* ATM SVCs */AF_RDS 21 /* RDS sockets */AF_SNA 22 /* Linux SNA Project (nutters!) */AF_IRDA 23 /* IRDA sockets */AF_PPPOX 24 /* PPPoX sockets */AF_WANPIPE 25 /* Wanpipe API Sockets */AF_LLC 26 /* Linux LLC */AF_IB 27 /* Native InfiniBand address */AF_CAN 29 /* Controller Area Network */AF_TIPC 30 /* TIPC sockets */AF_BLUETOOTH 31/* Bluetooth sockets */AF_IUCV 32 /* IUCV sockets */AF_RXRPC 33 /* RxRPC sockets */AF_ISDN 34 /* mISDN sockets */AF_PHONET 35 /* Phonet sockets */AF_IEEE802154 36/* IEEE802154 sockets */AF_CAIF 37 /* CAIF sockets */AF_ALG 38 /* Algorithm sockets */AF_NFC 39 /* NFC sockets */AF_VSOCK 40 /* vSockets */AF_MAX 41 /* 保留 */ 参考 定义的类型（type）包含： 1234567SOCK_STREAM = 1, // TCPSOCK_DGRAM = 2, // UDPSOCK_RAW = 3, // 原始类型，可以自定义SOCK_RDM = 4, // 提供可靠的数据包连接SOCK_SEQPACKET= 5, // 提供连续可靠的数据包连接SOCK_DCCP = 6, // 数据报拥塞控制协议，具有内置拥塞控制的不可靠数据报的传输SOCK_PACKET = 10, // 与网络驱动程序直接通信 定义的协议（protocol）包含： 12345678910111213141516171819202122232425enum&#123; IPPROTO_IP = 0, /* Dummy protocol for TCP */ IPPROTO_ICMP = 1, /* Internet Control Message Protocol */ IPPROTO_IGMP = 2, /* Internet Group Management Protocol */ IPPROTO_IPIP = 4, /* IPIP tunnels (older KA9Q tunnels use 94) */ IPPROTO_TCP = 6, /* Transmission Control Protocol */ IPPROTO_EGP = 8, /* Exterior Gateway Protocol */ IPPROTO_PUP = 12, /* PUP protocol */ IPPROTO_UDP = 17, /* User Datagram Protocol */ IPPROTO_IDP = 22, /* XNS IDP protocol */ IPPROTO_DCCP = 33, /* Datagram Congestion Control Protocol */ IPPROTO_RSVP = 46, /* RSVP protocol */ IPPROTO_GRE = 47, /* Cisco GRE tunnels (rfc 1701,1702) */ IPPROTO_IPV6 = 41, /* IPv6-in-IPv4 tunnelling */ IPPROTO_ESP = 50, /* Encapsulation Security Payload protocol */ IPPROTO_AH = 51, /* Authentication Header protocol */ IPPROTO_BEETPH = 94, /* IP option pseudo header for BEET */ IPPROTO_PIM = 103, /* Protocol Independent Multicast */ IPPROTO_COMP = 108, /* Compression Header protocol */ IPPROTO_SCTP = 132, /* Stream Control Transport Protocol */ IPPROTO_UDPLITE = 136, /* UDP-Lite (RFC 3828) */ IPPROTO_RAW = 255, /* Raw IP packets */ IPPROTO_MAX&#125;; 在Python中，主要的使用方式如下： 1socket.socket([family[, type[, proto]]]) family，套接字协议族，常见有： socket.AF_UNIX：只能够用于单一的Unix系统进程间通信 socket.AF_INET：服务器之间网络通信，IPv4 socket.AF_INET6：服务器之间网络通信，IPv6 type: 套接字类型，包括： socket.SOCK_STREAM：流式socket，用于TCP socket.SOCK_DGRAM：数据报式socket，用于UDP socket.SOCK_SEQPACKET：可靠的连续数据包服务 socket.SOCK_RAW：原始套接字，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以；其次，SOCK_RAW也可以处理特殊的IPv4报文；此外，利用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头。 protocol: 写 0 即可 连接方面： s.bind()：绑定地址到套接字，IPv4下，使用(host, port)绑定。 s.listen()：开启TCP监听。 s.accept()：等待连接（阻塞）。 s.connect()：主动连接服务器，IPv4下，使用(host, port)，如果连接失败，返回socket.error。 s.connect_ex()：主动连接服务器，出错时返回出错码。 s.close()：关闭套接字。 s.getpeername()：返回远程地址。 s.getsockname()：返回自己的地址。 s.settimeout(timeout)：设置超时时间，例如连接等待时间。 s.gettimeout()：获取超时时间。 数据传输： s.recv()：接收TCP数据，可以指定最大接收量。 s.send()：发送TCP数据，返回发送的字节数。 s.sendall()：发送完整TCP数据，如果失败抛出异常。 s.recvfrom()：接收UDP数据，返回(data, address)。 s.sendto()：发送UDP数据，参数为(data, (ip, port))，返回发送的字节数。 s.setsockopt(level,optname,value)：设置套接字。 s.getsockopt(level,optname[.buflen])：获取设置。 s.fileno()：返回套接字的文件描述符。 s.setblocking(flag)：设置为非阻塞模式。 s.makefile()：创建套接字文件。 uWSGIuWSGI 是Python搭建Web服务所用的中间件，是调和Web服务于Web应用直接的协议问题。 首先安装uWSGI：123pip install uwsgi# uwsgitop 用于监控数据pip install uwsgitop 假设当前Nginx配置为：1234location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:3031;&#125; 我们启动一个uWSGI服务：1234567# --processes 添加更多的进程，用于并发# --threads 添加更多的线程，用于并发# --stats 使用 stats 子系统，可以执行监控任务 (uwsgitop)# --http-socket 启动地址，结合Nginx用# --wsgi-file 指定入口文件# --chdir 指定项目目录，如Django项目目录uwsgi --http-socket 127.0.0.1:3031 --chdir /home/foobar/myproject/ --wsgi-file myproject/wsgi.py --master --processes 4 --threads 2 --stats 127.0.0.1:9191 也可以写成配置文件：1234567[uwsgi]socket = 127.0.0.1:3031chdir = /home/foobar/myproject/wsgi-file = myproject/wsgi.pyprocesses = 4threads = 2stats = 127.0.0.1:9191 接着执行：1uwsgi yourfile.ini 如果不用Django框架，而是单独文件server.py，或是Flask框架：1234# uWSGI Python 加载器将会搜索的默认函数 application def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b"Hello World"] 多线程Python代码的执行由Python虚拟机（也叫解释器主循环）来控制。Python在设计之初就考虑到要在主循环中，同时只有一个线程在执行。虽然 Python 解释器中可以“运行”多个线程，但在任意时刻只有一个线程在解释器中运行。对Python虚拟机的访问由全局解释器锁(GIL)来控制，正是这个锁能保证同一时刻只有一个线程在运行。也就是说，尽管有了线程模块，Python几乎依然是单线程处理。 尽管如此，在IO密集型的多线程应用中，Python的多线程threading库表现却依然还行。但在并行计算型应用中，如果想真正实现多线程，就得在Python中可以使用多线程threading，并自行设计锁结构，或使用多进程multiprocessing，并在主进程设置消息队列，共享内存，管道等方式传递数据。 threading 模块创建线程，可以直接使用： 12345678910from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name)if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.start() print('主线程') 也可以通过子类继承后使用： 123456789101112131415from threading import Threadimport timeclass Sayhi(Thread): def __init__(self,name): super().__init__() self.name=name def run(self): time.sleep(2) print('%s say hello' % self.name)if __name__ == '__main__': t = Sayhi('egon') t.start() print('主线程') Thead 对象的常用方法有： isAlive()：是否运行 getName()：获取线程名称 setName()：设置线程名称 x.join()：当前线程等待x线程结束再继续执行。 setDaemon(True)：设置为守护线程 守护线性：如果设置一个线程为守护线程，就表示这个线程是不重要的，在进程退出的时候，不用等待这个线程退出。主线程只会等待所有非守护线程都结束后才退出。 threading 模块的常用方法有： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 使用 同步锁 可以防止数据竞争问题：123456R = threading.Lock()R.acquire()'''临界区'''R.release() 但是使用锁的时候，一定要解决好死锁的问题。解决方法可以参考《操作系统》相关章节。 线程间通信，可以使用消息队列，可以使用共享内存的方式进行通信。下面使用队列方式通信（注意互斥访问队列）： 12345678910111213141516171819# JoinableQueue# 队列长度，多线程下不够准确Queue.qsize()# 队列判空Queue.empty()# 队列判满Queue.full()# 入队，是否阻塞Queue.put(item, block=True, timeout=None)# 入队，不阻塞Queue.put_nowait(item)# 出队，是否阻塞Queue.get(block=True, timeout=None)# 出队，不阻塞Queue.get_nowait()# 提示让出队列，提示join停止阻塞Queue.task_done()# 阻塞直到队列为空Queue.join() multiprocessing 模块多进程的创建： 1234567891011121314from multiprocessing import Processimport osdef work(): print('hello',os.getpid())if __name__ == '__main__': # 会发现每一个进程都有不同的 PID # 且进程的数据各自保留一份，互不相关 # 之间传递数据必须使用工具 p1=Process(target=work) p2=Process(target=work) p1.start() p2.start() print('主线程/主进程pid',os.getpid()) 创建共享内存实现主进程与子进程通信： 123456789101112import multiprocessing def f(a): a[0] = 5# 创建共享内存arr = multiprocessing.Array('i', range(10))# 子进程处理p = multiprocessing.Process(target=f, args=(arr,))p.start()p.join()print(arr[0]) 使用Manger通信，本质也是共享内存：12345678910111213141516import multiprocessingdef f(ls): ls.append('Hello')# Manager 要在主进程创建server = multiprocessing.Manager()# 每调用一次list产生一个共享内存# 除了list外，也可以是其他形式，如队列、锁、字典、数组等ls = server.list()# ls = server.Queue()# 子进程处理proc = multiprocessing.Process(target=f, args=(ls,))proc.start()proc.join()print(ls) ctypesctypes可以让Python直接调用任意的C动态库的导出函数，由于ctypes会在调用C函数前释放GIL，因此也可以实现多线程。 我们可以将写好的Task编译为C的动态库，例如lib_task.so或lib_task.dll，然后在Python中调用该库。打包动态库可以使用Visual Studio建立相关项目，Visual Studio就会自动生成一个DLL模板。或使用GCC创建： lib_task.h123456789101112131415#ifndef LIB_TASK_H#define LIB_TASK_H#ifdef __cplusplusextern " C " &#123;#endif// DLL 关键字 __declspec (dllexport)extern __declspec (dllexport) void Task(int arg);#ifdef __cplusplus&#125;#endif#endif lib_task.c12345678#include "print.h"// 在这里实现多线程void Task(int arg)&#123; while(arg); return;&#125; 编辑DLL：1gcc --share lib_task.c -o lib_task.dll 12345678910from ctypes import *from threading import Thread# lib_task.h 与 lib_task.dll 必须在这个目录下# 给DLL传递参数时，要将参数转化为C的类型lib = cdll.LoadLibrary("lib_task.dll")t = Thread(target=lib.Task, args=(1,))t.start()lib.Task() 线程池线程池可以帮助我们自动调度线程，在需要多线程任务量巨大的情况下是非常好用的工具，省去我们考虑线程同步的问题，也节省了上下文切换的时间。 第三方线程池 threadpool： 1pip install threadpool 12345678910111213from threadpool import ThreadPool, makeRequests# 创建一个容纳4个线程的线程池pool = ThreadPool(4)requests = makeRequests( some_callable, # 多线程的任务 list_of_args, # 参数 callback # 回调函数，可空 )for req in requests: pool.putRequest(req) # 等待线程池完成任务pool.wait() 另外还有ThreadPoolExecutor，ProcessPoolExecutor，线程（进程）池也可以使用。 Executor提供了以下常用的方法： submit(fn, *args,**kwargs)：将fn函提交给池子；*args是传给fn函数的参数；**kwargs表示以关键字的形式为fn的参数。 map(func, *iterables, timeout=None, chunksize=1)：类似于全局函数的map，只是该函数将会启动多个线程，以异步的方式立即对*iterables执行map处理，就是把for循环和submit结合在一起了。 shutdown(wait=True)：关闭池子，wait=True时等待池内所有任务执行完毕回收完资源后才继续；wait=False时立即返回，并不会等待池内的任务执行完毕；但不管wait参数为何值，整个程序都会等到所有任务执行完毕才会清空池子，所以submit和map必须在shutdown之前执行。 ​程序将task函数submit之后，submit会返回一个Future对象，Future类主要用于获取线程或进程任务函数的返回值。Future中提供了一下方法： cancel()：取消Future代表的线程或者进程任务，如果任务正在执行，不可取消，返回False；否则任务取消，返回Ture。 cancelled()：返回Future代表的任务是否被成功取消。 running()：返回Future代表的任务是否增正在执行。 done()：返回Future代表的任务是否已经结束。 result(timmeout=None)：返回Future代表的任务的结果，如果任务没有完成，该方法将会阻塞当前线程，timeout指定阻塞多长时间。 exception()：返回Future代表的任务的异常，如果没有异常，则返回None。 add_done_callback(fn)：给Future代表的任务加一个’回调函数’，当该任务成功之后，执行这个fn函数。 创建线程池 ThreadPoolExecutor： 123456789101112131415161718import time,threadingfrom concurrent.futures import ThreadPoolExecutordef f(n): time.sleep(2) print(f"线程号 &#123;threading.get_ident()&#125;",n) return n*nif __name__ == '__main__': # 创建线程池，线程数 5 t_pool = ThreadPoolExecutor(max_workers=5) t_l = list() for i in range(1,5): t = t_pool.submit(f,i) t_l.append(t) t_pool.shutdown() for i in t_l: print('===',i.result()) 创建进程池 ProcessPoolExecutor： 12345678910111213141516171819202122232425import time,threadingfrom concurrent.futures import ProcessPoolExecutordef callback_fun(x): passdef f(n): time.sleep(2) print(f"进程PID &#123;os.getpid()&#125;",n) return n*nif __name__ == '__main__': # 创建进程池，进程数 5 p_pool = ProcessPoolExecutor(max_workers=5) p_l = list() for i in range(5): t = p_pool.submit(f,i) # 也可以设置回调函数，回调的参数由任务函数提供 # t.add_done_callback(callback_fun) p_l.append(t) # 也可以写成 # s = p_pool.map(f,range(1,5)) p_pool.shutdown(wait = True) for i in p_l: print('===',i.result()) multiprocessing 模块也提供了进程池： 12345678910111213141516171819202122232425import os,timefrom multiprocessing import Process,Pooldef f(n): print(f"进程PID &#123;os.getpid()&#125;") time.sleep(1) return n*n # 返回值交给回调函数def cb_fun(n): passif __name__ == '__main__': # 创建工作进程 p = Pool(3) p_l = list() for i in range(1,10): re = p.apply( f, # 多线程工作函数 args=(i,), # 传递的参数 callback=cb_fun # 回调函数 ) p_l.append(re) print(p_l) p_l.close() p_l.join() XML 与 JSONXMLXML 指可扩展标记语言（eXtensible Markup Language），形式同HTML，是一种用于标记电子文件使其具有结构性的标记语言。XML也可以用于数据以文本格式存储下来。格式如下（DOM）： 123456789101112131415161718192021222324252627282930313233&lt;collection shelf="New Arrivals"&gt;&lt;movie title="Enemy Behind"&gt; &lt;type&gt;War, Thriller&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;2003&lt;/year&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Talk about a US-Japan war&lt;/description&gt;&lt;/movie&gt;&lt;movie title="Transformers"&gt; &lt;type&gt;Anime, Science Fiction&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;1989&lt;/year&gt; &lt;rating&gt;R&lt;/rating&gt; &lt;stars&gt;8&lt;/stars&gt; &lt;description&gt;A schientific fiction&lt;/description&gt;&lt;/movie&gt; &lt;movie title="Trigun"&gt; &lt;type&gt;Anime, Action&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;episodes&gt;4&lt;/episodes&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Vash the Stampede!&lt;/description&gt;&lt;/movie&gt;&lt;movie title="Ishtar"&gt; &lt;type&gt;Comedy&lt;/type&gt; &lt;format&gt;VHS&lt;/format&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;2&lt;/stars&gt; &lt;description&gt;Viewable boredom&lt;/description&gt;&lt;/movie&gt;&lt;/collection&gt; 解析 XML 可以使用 SAX 模块，SAX 模块用事件驱动模型，通过在解析 XML 的过程中触发一个个的事件并调用用户定义的回调函数来处理 XML 文件。SAX 模块非常适用于对大型文件进行处理，且只需要文件部分信息时使用。 通过使用ContentHandler类读取数据。ContentHandler的方法有： startDocument()：文档启动时调用。 endDocument()：到达结尾时调用。 startElement(name, attrs)：遇到开始标签&lt;..&gt;调用。 endElement(name)：遇到结束标签&lt;/..&gt;调用。 characters(content)：分情况看，有 从行开始，遇到标签之前，若存在字符，则content的值为这些字符串。 从一个标签，遇到下一个标签之前，若存在字符，则content的值为这些字符串。 从一个标签，遇到行结束符之前，若存在字符，则content的值为这些字符串。 标签可以是开始标签，也可以是结束标签。 12345678910111213141516171819202122232425import xml.saxclass MovieHandler( xml.sax.ContentHandler ): def __init__(self): # 此处定义对象属性 pass # 元素开始调用 def startElement(self, tag, attributes): pass # 元素结束调用 def endElement(self, tag): pass # 读取字符时调用 def characters(self, content): pass# 创建XML阅读器parser = xml.sax.make_parser()# 关闭命名空间parser.setFeature(xml.sax.handler.feature_namespaces, 0)# 创建对象Handler = MovieHandler()# 设置XML阅读器parser.setContentHandler(Handler)# 开始解析parser.parse("movies.xml") 如果解析的文件不大，且需要文件的全部信息，可以使用DOM解析器。这个解析器可以一次性将整个文档读入内存，且可读可写到文件。 1234567891011from xml.dom.minidom import parseimport xml.dom.minidom# 使用minidom解析器打开 XML 文档DOMTree = xml.dom.minidom.parse("movies.xml")collection = DOMTree.documentElementif collection.hasAttribute("shelf"): print (f"Root element : &#123;collection.getAttribute('shelf')&#125;")# 在集合中获取所有电影movies = collection.getElementsByTagName("movie") JsonJSON (JavaScript Object Notation) 是一种轻量级的数据交换格式，适合于网络间传输数据，如前后端使用Ajax传输，则偏向于传输Json。 123456789101112import jsondata = &#123; 'no' : 1, 'name' : 'Runoob', 'url' : 'http://www.runoob.com'&#125;# Python 字典类型转换为 JSON 对象json_str = json.dumps(data)# 将 JSON 对象转换为 Python 字典data = json.loads(json_str) 数据与科学计算爬虫Robots 协议Robots 协议指定了一个网站可以爬取的信息，例如：http://www.taobao.com/robots.txt 12345678910111213User-agent: BaiduspiderAllow: /articleAllow: /oshtmlAllow: /ershouAllow: /$Disallow: /product/Disallow: /User-Agent: *Disallow: /# 站点信息Sitemap: ... 为了防止被反爬虫技术封锁，应： 要伪装User-Agent，且需要多个，随机选取 保存服务器下发的Cookies URL Lib 包urllib.request，负责打开读写 url，包含了几个方法：123456789101112131415161718192021from urllib.request import urlopen, Request# 直接打开一个url，Request对象，返回HTTPResponse对象，用法类似文件res = urlopen(url, data)# 构造Requestreq = Request(url, headers=&#123; 'User-agent': 'user agent'&#125;)# 或 req.add_header('', '')res = urlopen(req)# 查看结果res.closed # 查看是否关闭，Falsewith res: res.status # 状态码 res.reason # 状态 res.getrul() # 真正的URL，例如重定向后的URL res.info() # headers res.read() # 返回读取的内容res.closed # 查看是否关闭，True urllib.error， urllib.parse， urllib.robotparser，用于分析robots.txt文件。 MatplotlibNumPyPandas]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker 入门]]></title>
    <url>%2F2020%2F02%2F04%2FDockerFirst%2F</url>
    <content type="text"><![CDATA[Docker 准备工作Docker PlaygroundDocker Playground 这是一个不用下载的，在线就可以用的Docker。使用需要使用Docker的账号密码，可以去注册一个。 下载 DockerDocker分为社区版和企业版。这里主要介绍社区版。 进入官方DockerToolbox下载页面，按照安装教程安装Docker Toolbox。 国内阿里云[DockerToolBox下载页面](http://mirrors.aliyun.com/docker-toolbox/windows/docker-toolbox/DockerToolbox-18.03.0-ce.exe)，如果官方的速度太慢，可以切换到这里。这里的Docker不是最新版的。 其他下载页面，包含Ubuntu下的一键安装脚本。 安装过程会自动安装VirtualBox，Dokcer，Docker-compose以及Kitematic。 Docker 容器查询Docker 官方文档W3C Docker 参考文档 配置 Docker使用Docker，Docker会默认为我们创建一个虚拟机，下载的Image也都会存储在虚拟机中。默认情况下，虚拟机会存储在用户文档下的.docker目录下。若想改变虚拟机默认存储，可以配置环境变量MACHINE_STORAGE_PATH即可。 （如果遇到Waiting for an IP无限等待，可能是OpenSSH的问题，这个是Win10上内置的功能） 运行桌面上的Docker Quickstart Terminal，首次启动Docker会为我们创建一台虚拟机，并在这个虚拟机目录下创建配置文件。打开配置文件（如果修改过就去改后的目录找）：1C:\Users\用户名\.docker\machine\machines\default\config.json 在HostOptions-&gt;EngineOptions-&gt;RegistryMirror中配置为： 123&#123; "RegistryMirror": ["https://sfpj1t4c.mirror.aliyuncs.com"],&#125; 此处的镜像地址最好是到阿里云找一个。登录阿里云，点击产品与服务，选择容器镜像服务-&gt;镜像中心-&gt;镜像加速器。 配置完成后，重新运行桌面上的Docker Quickstart Terminal。 首次使用 Docker首先进入Docker Quickstart Terminal后，在项目目录执行如下内容，用来测试docker是否正常。 1docker run ubuntu:16.04 /bin/echo "Hello world" 提示Hello World说明配置成功。 Docker 安装了什么安装完成后，我们来简单梳理一下都做了什么。 Docker在我们的电脑上安装了： VirtualBox：虚拟机工具。 Docker Machine：虚拟机管理工具。 Docker Compose：Docker脚本执行工具。 Docker Client 完成安装后，首次运行Docker Quickstart Terminal，Docker就会创建一个虚拟机，作为我们的Docker Server，而我们的本地系统则成为了Docker Client。 之后我们使用的容器将全部运行在这个虚拟机中。查看虚拟机的IP可以使用命令： 1docker-machine env Ubuntu 下的 Docker如果图个方便，那么直接安装：1sudo apt-get install -y docker.io containerd runc docker-compose 如果想去官方下载最新版，那么可以按照官方的程序来一遍。 Docker for Linux安装方法 按照官网给出的安装方法安装Docker。此外，官网还给出了下载Docker包安装和卸载Docker的方法。 12345678910111213141516171819202122232425262728293031323334353637383940# 首先删除旧版本sudo apt-get remove docker docker-engine docker.io containerd runc# 更新下载源sudo apt-get update# 配置aptsudo apt-get install -y \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common# 添加Docker源秘钥curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 添加秘钥sudo apt-key fingerprint 0EBFCD88# 添加Docker源sudo add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable"sudo apt-get update# 安装 Docker Communitysudo apt-get install -y docker-ce docker-ce-cli containerd.io# 如果想要安装其他版本，可以尝试下面的操作# 列出可以按照的Docker Community版本apt-cache madison docker-ce# 选择一个版本安装Docker Community，注意替换下面&lt;...&gt;内容sudo apt-get install -y docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io# 安装完成，测试安装结果sudo docker run hello-world 修改Docker配置文件： 在/etc/docker/daemon.json中增加如下内容：123&#123; "registry-mirrors": ["https://sfpj1t4c.mirror.aliyuncs.com"]&#125; 此处的镜像地址最好是到阿里云找一个。登录阿里云，点击产品与服务，选择容器镜像服务-&gt;镜像中心-&gt;镜像加速器。 Docker 原理与架构Docker 是一个平台，它通过Docker Engine把底层的设备与上层应用隔离开。Docker Engine是一个后台进程，即是一个REST API Server，它还有一个CLI接口（docker）。 Docker 包含 Client 与 Server 。Docker Client 通过命令方式控制 Docker Server，在Server上操作Container，Image等。Docker Server通过代码仓库或Docker Hub获取Docker镜像。 Docker ImageImage 本身是只读的。Docker搭建的应用的过程就是将几个Image一层一层叠加上去的过程。例如在Ubuntu Image层上叠加Apache Image层，在上面再叠加一个PHP Image层，就可以实现一个网站。Image之间可以共享同一层，例如Apache与MySQL可以在同一层上。 使用 Image1234567891011# 查看 imagedocker image ls# 删除 imagedocker image rm image_id# 获取 imagedocker pull ubuntu:14.04# 通过 Dockerfile 创建 image -t 表示 Tag . 表示当前目录docker build -t author/name:version . 如果要查询Image，可以去Docker Hub上查找。 创建 Image如果想要自己创建一个Base Image，可以这样做。 例如我们编写一个 c 程序。1vim main.c 编辑程序代码：123456#include &lt;stido.h&gt;int main(int argc, char* argv[])&#123; printf("hello\n");&#125; 编译程序：1gcc -static main.c -o main 执行程序查看效果：1./main 编写Dockerfile文件：1vim Dockerfile 1234# scratch 表示没有BaseFROM scratchADD main /CMD ["/main"] 构建运行Image：123456# 构建docker build -t author/image_tag .# 查看Image层数docker history image_id# 运行docker run author/image_tag 删除 Image删除Image：12docker image rm image_iddocker rmi image_id Docker ContainerContainer 是一种可读可写的层。我们在运行一个Image时，Docker会在这个Image上添加Container层，用于读写程序运行时产生的数据。 我们也可以把Container与Image类比成对象和类。Image只读，负责存储app，可以当做是一个类；Container则是负责运行app，可以当做是一个对象。 使用 Container运行一个Image，就创建了一个Container。Container在运行完成后就会退出。 1docker run ubuntu 运行完成后：123456# 查看所有容器，-a 表示包括已经结束运行的docker container ls -a# 或docker ps -a# 只显示container iddocker container ls -aq 使用如下命令可以进入容器内做交互，注意，这里的所有数据会在Container结束运行时消失：12# -i 表示交互 -t 表示标准输入输出docker run -it ubuntu 删除Container：1234567docker container rm container_id# 或docker rm container_id# 批量删除所有containerdocker rm $(docker container ls -aq)# 批量删除所有退出的containerdocker rm $(docker container ls -f "status=exited" -q) 当我们在container中产了数据，做了某些操作，我们就可以通过commit方式将修改后的contianer变为image。 从Container创建Image12345docker container commit # 同docker commit# 例如docker commit contaienr_name image_name 我们也可以从Dockerfile创建container。首先创建一个空的目录，这个目录下的除配置文件外的所有文件将会被打包进入image。我们创建一个配置文件Dockerfile： 12FROM ubuntuRUN sudo apt-get install -y vim 执行命令打包：1234docker container build # 同 docker build# 例如docker build -t image_name . 进入运行中的container：1234# 进入命令行docker exec -it container_id /bin/bash# 显示ipdocker exec -it container_id ip a 停止container：1docker stop container_id 运行时给container命名：1docker run -d --name=demo image_name 这样就可以不用再操作container_id了，而是可以直接操作name。 查看container信息：1docker inspect container_id 查看container输出信息：1docker logs container_id 上传自制 Image首先注册登录Docker，并进入Docker Hub。 在本地命令行：12345# 登录账号docker login# 推送 imagedocker push author/image:latest# 被推送的image必须是 author/image:latest 格式，否则没有权限推送 进入Docker Hub就可以看见自己推送的Image了。 也可以让Docker与Github关联。在Docker页面，Create，Create Automated Build里面，选择Link Accounts关联Github。在Github里创建Repository，将Dockerfile上传到代码仓库。Docker的服务器会帮我们Build镜像。 如果要搭建自己的Image仓库，可以在Docker hub里面搜索registry，按照里面的教程操作即可。 打包一个Python程序到Image创建一个Python脚本首先创建Docker打包目录，在目录下创建文件app.py： 1234567from flask import Flaskapp = Flask(__name__)@app.route('/')def hello(): return "hello docker"if __name__ == '__main__': app.run() 创建一个 Dockerfile再创建Dockerfile： 1234567FROM python:2.7LABEL maintainer="Author"RUN pip install flaskWORKDIR /appCOPY app.py /app/EXPOSE 5000CMD ["python", "app.py"] 创建 Image123docker build -t author/image_name .# -d 参数后台执行docker run -d author/image_name 如果创建失败，遇到bug想要调试，可以查看build日志，找到最后一个创建成功的Step，复制其id，并通过命令进入bash环境： 1docker run -it id /bin/bash Docker 压力测试进入docker容器中：1docker run -it ubuntu 安装stress工具：1sudo apt-get update &amp;&amp; sudo apt-get install -y stress 使用stress：123456# vm Worker数 # verbose 打印日志# 功能：反复分配释放内存，默认256MBstress --vm 1 --verbose# vm-bytes 申请释放内存大小 或使用Dockerfile1234FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y stressENTRYPOINT ["/usr/bin/stress"]CMD [""] # 从命令行接受参数 12docker build -t image_tag .docker run -it image_tag --vm 1 --verbose 创建一个常开的Container使用busybox这个Image，可以创建一个常开的Container：1docker run -d --name test busybox /bin/sh -c "while true; do sleep 3600; done" 限制Container资源在开启Container时，可以通过添加参数限制Container的资源，包括cpu个数，内存大小等：1234# --memory 内存 --cpu-shares cpu相对占用docker run --memory=200M --cpu-shares=10 image_tag --vm 1 --cpu 1 --verbosedocker run --memory=200M --cpu-shares=5 image_tag --vm 1 --cpu 1 --verbose# 想当与2:1占用一个cpu Docker Network单机Network有三种模式： Bridge Network Host Network None Netw 多机Network有 Overlay Network。 手工配置 Linux Network 命名空间Network命名空间（Namespace）是一种虚拟化技术，它可以将一个物理机虚拟化成多个虚拟机。一个命名空间相当于一个虚拟主机。我们可以通过配置命名空间下的虚拟端口，可以完成虚拟机，也就是命名空间中的网络连接。这也是docker容器的底层技术。 Linux的Network命名空间有关命令： 123456789# 查看所有命名空间sudo ip netns list# 添加命名空间sudo ip netns add net_test1# 删除命名空间sudo ip netns delete net_test1# 查看命名空间下的IPsudo ip netns exec net_test1 ip a# 会看到该命名空间下的IP没有任何启动的虚拟网卡 配置虚拟网络的过程如下：123456789101112131415# veth即为端口，首先创建一对连起来的端口sudo ip link add veth_test1 type veth peer name veth_test2# 将端口添加到命名空间中。sudo ip link set veth_test1 netns net_test1sudo ip link wet veth_test2 netns net_test2# 为端口分配IP地址sudo ip nets exec net_test1 ip addr add 192.168.1.1/24 dev veth_test1sudo ip nets exec net_test2 ip addr add 192.168.1.2/24 dev veth_test2# 启动命名空间网络sudo ip netns exec net_test1 ip link set dev veth_test1 upsudo ip netns exec net_test2 ip link set dev veth_test2 up# 查看结果sudo ip netns exec net_test1 ip linksudo ip netns exec net_test2 ip link# 会看到网络已经启用了，两个Network命名空间也连起来了 Bridge NetworkBridge Network 原理探索 查看Linux本机IP：1ifconfig 可以看到docker0网桥，veth453e607端口以及其他的网络设备。其中： docker0：是一个网桥，是Docker服务端上用于连接其他设备的端口。 veth…：是Docker Container上的端口。它是成对出现的，而它的另一端连接到docker0上。 可以使用下面的工具查看这个拓扑结构。12sudo apt-get install -y bridge-utilsbrctl show Bridge Network 使用查看所有的Docker网络：1docker network ls 我们这里创建两个容器，并让第二个通过桥接方式连接到第一个容器上。 1234docker run -d --name test1 busybox /bin/sh -c "while true; do sleep 3600; done"# 使用 --link 连接到另一个容器docker run -d --name test2 --link test1 busybox /bin/sh -c "while true; do sleep 3600; done"# link 命令并不常用 这样test2就可以直接通过hostname访问test1，但是test1无法通过hostname访问test1。但是二者可以通过IP访问。 另外，我们也可以通过network方式连接两个容器。创建好的容器默认连接到bridge上。我们新建一个bridge，并让两个容器联入新的bridge。12345678910# 创建网桥docker network create -d bridge test_bridge# 查看网桥docker network ls# 新建容器并联入网桥docker run -d --name test3 --network test_bridge busybox /bin/sh -c "while true; do sleep 3600; done"# 对已经有的容器联入网桥docker network connect test_bridge test2# 查看连接状态docker network inspect netword_id 之后，我们还要将端口映射出来。 新建一个Nginx服务器用于测试。12# 将本地8030端口映射到容器的80端口docker run --name web -d -p 8030:80 nginx 访问本地8030端口即可查看。 Host NetworkHost网络是与主机共享一个Network命名空间。启动一个连接Host网络的容器：1docker run -d --name test4 --network host busybox /bin/sh -c "while true; do sleep 3600; done" 这样的容器将直接使用主机上的端口工作。 None NetworkNone网络是一个孤立网络。启动一个连接None网络的容器：1docker run -d --name test6 --network none busybox /bin/sh -c "while true; do sleep 3600; done" 这个容器将不接入任何网络。 Overlay Network通过Overlay Network可以实现不同物理机上的Docker容器通信，Docker通过VXLAN技术实现了Docker容器在不同物理机上的通信。这里可以使用etcd实现分布式存储，用于辅助Overlay网络。 使用方法：1docker network create -d overlay network_name 这样不论在哪个物理机上操作Docker，都操作的是同一个服务，也就是两台物理机上使用的同一个Docker。 Docker 数据持久化Data VolumeVolume有两种，一种是作为本地文件存储的Volume，另一种是通过第三方插件，如NAS，AWS等。 创建的Volume有两种，一种是作为Docker对象呈现，可以用命令查看：1docker volume ls 另一种是直接挂在到本地目录。 对于前者，首先使用Dockerfile定义Volume： 1VOLUME ["/var/lib/mysql"] 创建的时候再指定参数：1docker run -d --name mysql_test -v mysql:/var/lib/mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql Bind Mouting这种模式不必创建Volume，而是可以直接使用，也就是将目录挂载到本地，实现目录的同步： 123docker run -v /home/aaa:/root/aaa# 例如docker run -d 80:80 -v $(pwd):/usr/share/nginx/html --name web nginx Docker ComposeDocker Compose可以通过脚本快速搭建容器集群，适用于开发环境。 一个例子12345678docker run -d --name mysql-test -v mysql-data:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=root \-e MYSQL_DATABASE=wordpress \mysqldocker run -d --name wordpress-test \-e WORDPRESS_DB_HOST=mysql-test:3306 \--link mysql -p 8080:80 wordpress 简介Docker Compose相当于一个批处理工具，可以定义，管理多个docker应用。 Docker Compse有三大概念： Services：代表一个容器，可以指定Network和Volume。 Network： Volumes： 使用方法12345678910111213141516171819202122232425262728293031323334353637383940version: "3"services: db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - back-tier worker: build: ./worker ports: - 8080:80 environment: ENV_A: value_a links: - db - redis # 不用links，可以用networks networks: - back-tier worker_2: build: context: . dockerfile: Dockerfile ports: - 8000:5000 environment: ENV_B: value_bvolumes: db-data:networks: back-tier: driver: bridge front-tier: driver: bridge 12345678910111213141516# 启动一个脚本docker-compose -f docker-compose.yml up# 如果脚本文件名就是docker-compose.yml，可以简写：docker-compose up# 后台执行docker-compose up -d# 查看服务docker-compose ps # 停止服务docker-compose stop# 启动服务docker-compose start# 停止并删除服务docker-compose down# 进入服务docker-compose exec name bash 弹性伸缩当我们需要做负载均衡时，可以使用伸缩的功能创建多个Web服务器，并用redis来存储客户的sessions。我们可以设计如下的架构： 负载均衡器 $\begin{Bmatrix}Web服务 1 \Web服务 2 \Web服务 3 \\end{Bmatrix}$Redis数据库 命令行方式创建多个服务： 1docker-compose up --scale service_name=3 -d 使用脚本方式创建负载均衡器，多个Web服务，以及Redis数据库： 123456789101112131415161718192021version: "3"services: redis: image: redis web: build: context: . dockerfile: Dockerfile environment: REDIS_HOST: redis lb: image: dockercloud/haproxy links: - web port: - 8080:80 volumes: - /var/run/docker.sock:/var/run/docker.sock 启用脚本： 1docker-compose up 将web服务增加到3个： 1docker-compose up --scale web=3 -d Docker SwarmDocker Swarm可以快速搭建容器集群，适用于生产环境。在生产环境中，为了保障服务的正常使用，我们决不能停止当前的服务。不仅如此，我们还需要实时监控服务的状态，甚至在宕机时能够自动恢复。另外，服务还要有足够的安全性，防止数据泄露，扛得住网络攻击。 Swarm 架构 在Swarm中有两种角色。一种是Worker，一种是Manager。Manager是管理Worker的节点，可以有多个，且他们之间数据可以同步，同步使用Raft，。Worker是处理数据的节点，也可以有多个，他们之间通过Gossip network通信。 在Swarm中还定义了Service与Replicas。Service代表了一种服务，而Replicas则是服务下属的节点，一个服务可以有多个下属的节点。每一个Replica是一个容器。 创建集群首先创建三台虚拟机，命名为Manager，Worker1，Worker2。 12345678# 创建虚拟机docker-machine create swarm-managerdocker-machine create swarm-worker1docker-machine create swarm-worker2# 查看虚拟机IP，例如得到ManagerIP为192.168.205.10docker-machine ls# 登录Managerdocker-machine ssh swarm-manager 在Manager节点上执行： 1docker swarm init --advertise-addr=192.168.205.10 之后会返回一条指令，这条指令是给要加入Manager的Worker节点使用的： 1docker swarm join --token SWMTKN-1-3cv6sadfwe...asfwef 192.168.205.10:2377 进入Worker1节点，执行刚刚得到的指令，即可加入集群。 在Manager节点可以查看Worker情况： 1docker node ls 横向扩展横向扩展是指通过创建多个服务来做负载均衡，以保证服务的可靠性。依然是上面的三个虚拟机的集群，在Manager上搭建服务： 1docker service create --name demo busyBox sh -c "while true; do sleep 3600; done" 查看刚刚搭建的服务： 1docker service ps demo 可以看到一个REPLICAS属性，这个属性就是扩展的节点数。下面我们扩展这个服务： 1docker service scale demo=5 再次查看操作结果： 1docker service ps demo 会发现5个服务被平均分配到3台虚拟机上了。如果某个服务宕机了，Swarm会自动新建一个节点，修复集群。 停止服务： 1docker service rm demo 在线更新为了保证更新过程，服务不宕机，Swarm提供了动态更新的功能。 首先创建一个overlay网络： 1docker network create -d overlay demo 在这个网络上创建一个服务，这个服务是一个旧版的Nginx，一会我们通过动态更新换为最新版Nginx。更新之前，首先保证服务节点数大于一个： 12docker service create --name web --publish 8080:5000 --network demo nginx:1.16.1docker service scale web=4 更新Image： 1docker service update --image nginx:latest web 更新端口： 1docker service update --publish-rm 8080:5000 --publish-add 8088:5000 web 在更新过程中，会有旧版和新版同时服务的状况。 搭建WordPress使用WordPress，需要有WordPress和MySQL两个服务。 首先在Manager节点，创建Overlay网络： 1docker network create -d overlay demo 创建服务： 123456789101112docker service create --name mysql \--env MYSQL_ROOT_PASSWORD=root \--env MYSQL_DATABASE=wordpress \--network demo \--mount type=volume,source=mysql-data,destination=/var/lib/mysql \mysqldocker service create --name wordpress -p 80:80 \--env WORDPRESS_DB_PASSWORD=root \--env WORDPRESS_DB_HOST=mysql \--network demo \wordpress 之后三个节点的IP地址都可以访问WordPress服务了。 DNS 服务在Docker内部拥有一个DNS服务，这个服务维护了每一个服务以及其服务IP。如果这个服务有3个节点，那么这个服务就会另外有3个IP，对应3个容器的IP。也就是说，这个服务一共有4个IP：1个虚拟的IP用于对外提供服务，这个IP会保持不变；另外还有3个用于对应容器，可以随时扩展收缩。 我们可以通过访问虚拟机集群，不论访问哪个虚拟机的IP，都能访问容器中的服务。在这个过程中，Docker DNS会自动为我们寻找需要的服务和它的虚拟IP。但是我们请求这个服务，最终会看到容器所在的虚拟机的主机名。 对比Docker Overlay网络，Overlay实现了多个虚拟机之间的容器通信，使用的技术是VXLAN Tunnel；而服务之间则是通过虚拟IP，基于Docker DNS通信，使用LVS（Linux Virtual Server）技术。 使用 Stack 通过 Docker Compose 部署服务使用Stack通过Docker Compose更新服务，首先要确保image不能是在本脚本build，而是必须使用已经build好的image。 deploy属性指定了更新的策略，包括部署数量，部署方式等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950version: "3"services: redis: image: redis:alpine ports: - "6379" networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: web networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager]networks: frontend: backend:volumes: db-data: 使用docker compose脚本搭建的集群，需要脚本中包含deploy属性，并使用docker stack使用与更新服务： 12345678# 部署服务docker stack deploy example --compose-file=docker-compose.yml# 查看服务docker stack ls# 查看服务情况docker stack services example 最后删除服务： 1docker stack rm example 另外推荐一个服务visualizer，可以可视化查看集群中每个虚拟机上的容器状况。 如果更新服务，可以直接修改docker compose文件，然后重新部署：1docker stack deploy example --compose-file=docker-compose.yml Secret 管理在生产环境中，用于管理系统的密码一般不会明文写到docker compose中，而是使用一些手段隐藏起来。 因此用到Secret管理。这里的Secret管理主要包括： 用户名/密码 SSH Key TLS 认证 机密数据 在Manager节点中，有一个内置的分布式存储。在这个存储中我们就可以存储我们的Secret。当Worker上有容器想要使用时，就可以请求分布式存储获取Secret。 首先创建一个文件password.txt，将我们的密码写到这个文件中。创建一个Secret： 1docker secret create demo-password password.txt 之后删掉password.txt。 查看创建的Secret：1docker secret ls 不创建文件而直接创建Secret也可以，通过管道的方式即可： 1echo "admin123456" | docker secret create demo-password2 删除Secret可以： 1docker secret rm demo-password2 使用Secret：1docker service create --name client --secret demo-secret busybox sh -c &quot;while true;do sleep 3600;done&quot; 在容器的/run/secrets/下可以看到刚刚的secret，是可以看到密码原文的。在MySQL中，可以使用MYSQL_ROOT_PASSWORD_FILE指定密码文件。 在compose中也可以使用Secret。 123456789101112131415161718version: "3"services: image: mysql secrets: - demo-password environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/demo-password volumes: - mysql-data:/var/lib/mysqlvolumes: mysql-data:# 不推荐下面的创建方法，而是推荐命令行管道方式创建Secretssecrets: demo-password: file: ./password KubernetesKubernetes，简称k8s，也是容器编排工具，功能上与Swarm相同。在前期时，Docker一直以Swarm为主，后面将逐步过渡至k8s上。 Kubernetes由谷歌制作，因此国内可能会无法访问。 Kubernetes的重要人物，通过该页面可以查看一些关于Kubernetes的介绍。 Kubernetes Playground，通过该页面可以不安装Kubernetes就可以使用。 架构 Kubernetes也分为两种角色：Master节点与Node节点。 Master主要包含： API Server：是外界访问集群的接口； Scheduler：是均衡调度容器的模块； Controller：控制容器的伸缩； etcd：分布式存储。 Node主要包含： Pod：是调度的最基本单位，是具有相同（network） namespace的容器的组合。 Docker：也可以使用其他容器技术，这里使用Docker。 kubelet：是Master控制节点的接口，负责管理Pod。 kube-proxy：负责负载均衡，端口转发等功能。 Fluentd：查询与采集日志。 Optional Add-ons: DNS, UI, etc. 另外还有Image Registry负责保存Image。 创建单节点Kubernetes集群Minikube：安装教程使用教程示例 其他参考：Ubuntu 安装 KVM安装kubectl工具 以下过程为基于Ubuntu的，其他系统自行参考。 首先安装kubectl工具： 1234567891011# 下载kubectl工具（注意有Google，你懂）curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl# 修改为可执行文件chmod +x ./kubectl# 将文件放置到环境变量bin中sudo mv ./kubectl /usr/local/bin/kubectl# 查看版本信息kubectl version --client 可以使用Minikube创建单节点Kubernetes集群。首先安装Minikube（Ubuntu）： 123456789101112131415# 下载安装Minikubecurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \ &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikube# 查看是否支持虚拟化egrep -q 'vmx|svm' /proc/cpuinfo &amp;&amp; echo yes || echo no# 使用VirtualBox作为驱动启动集群minikube start --vm-driver=virtualbox# 配置VirtualBox为默认驱动minikube config set vm-driver virtualbox# 也可以使用KVM作为驱动启动集群minikube start --vm-driver=kvm2 下面开始创建单节点集群：123456789101112# 创建集群minikube start# 查看集群配置kubectl config view# 查看context，每一个context表示一种配置kubectl config get-contexts# 配置minikubekubectl config use-context minikube# 查看集群情况kubectl cluster-info# 登录虚拟机minikube ssh PodPod是调度的最基本单位，一个Pod拥有一个IP，并且可以包含Volume，Container等，它们之间可以通过localhost相互访问，就像是一台机器上的两个进程相互访问。 这里创建一个pod_nginx.yml脚本： 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: app: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 80 下面是一些常用命令： 12345678910111213# 创建这个Pod：kubectl create -f pod_nginx.yml# 删除Pod：kubectl delete -f pod_nginx.yml# 查看部署的Pod：# -o wide 可以显示详细信息kubectl get pods -o wide# 进入第一个Pod，-c表示第几个，不加表示默认的第一个kubectl exec -it nginx -c 1 sh# 查看Pod的详细信息kubectl describe pods nginx# 映射集群端口到本地，格式 本地端口:集群端口kubectl port-forward nginx 8080:80 Replicate首先创建一个文件rs_nginx.yml： 1234567891011121314151617181920appVersion: v1# 如果是高版本，可以用ReplicaSetkind: ReplicationControllermetadata: name: nginxspec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 创建Replicate并可以做如下实验： 123456789# 创建Replicatekubectl create -f rs_nginx.yml# 查看Replicatekubectl get rc# 查看内部的Podkubectl get pods# 删除单个Pod，pod_name可以用get pods查看kubectl delete pods pod_name# 删除后会发现会有新的Pod被创建 如果要扩展Pod数量（或收缩Pod数量）：1kubectl scale rc nginx --replicas=4 最后删除Replicate：1kubectl delete -f rc_nginx.yml 关于ReplicaSet，可以参考如下文档：12345678910111213141516171819202122apiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx labels: tier: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: metadata: name: nginx labels: tier: frontend spec: containers: - name: nginx image: nginx ports: - containerPort: 80 扩展的时候使用1kubectl scale rs nginx --replicas=4 DeploymentDeployment指明了我们期望创建的集群，以及相应容器的版本，而其他内容则全部交给Kubernetes来实现。使用Deployment可以实现版本升级。 首先创建deployment_nginx： 123456789101112131415161718192021appVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: container: - name: nginx image: nginx:1.12.2 ports: - containerPort: 80 12345678# 创建kubectl create -f deployment_nginx.yml# 查看deployment，-o wide表示更多信息kubectl get deployment -o wide# 查看ReplicaSetkubectl get rs# 查看Podskubectl get pods 更新升级Deployment： 12345kubectl set image deployment nginx-deployment nginx=nginx:1.13# 再次查看deployment，可以发现nginx已经更新kubectl get deployment -o wide# 查看更新日志kubectl rollout history deployment nginx-deployment 撤销更新1kubectl rollout undo deployment nginx-deployment 创建多节点Kubernetes集群创建多节点Kubernetes集群，可以使用kubeadm，kops或是Tectonic（10 Nodes以内免费）。这里使用Tectonic（基于Vagrant）。 Tectonic官网Tectonic Sandbox Github页 非官方 安装好Tectonic后，配置Tectonic与minikube并存可以到kubernetes官网查看Configure Access to Multiple Clusters。 查看Node：1kubectl get node 可以看到刚刚创建的两个Node，即两个虚拟机。 集群使用的网络插件可以在此页查看。 ServiceService主要有三种类型： ClusterIP：只有集群内部可以访问的IP。 NodePort：可以对外提供访问。 LoadBalancer：由服务商（阿里云，腾讯云）提供，可以让我们将服务交给服务商管理。 ClusterIP12345# 对外暴露Pod端口，默认是ClusterIPkybectl expose pods nginx-pod# 查看服务kybectl get svc# 这样可以在集群内部访问Pod提供的服务 创建文件deployment_python_http.yml： 1234567891011121314151617181920212223apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: service-testspec: replicas: 2 selector: matchLables: app: service_test_pod template: metadata: labels: app: service_test_pod spec: containers: - name: simple-http image: python:2.7 imagePullPolicy: IfNotPresent command: ["/bin/bash"] args: ["-c", "echo \" &lt;p&gt;Hello from $(hostname)&lt;/p&gt;\" &gt; index.html; python -m SimpleHTTPServer 8080"] ports: - name: http containerPort: 8080 创建Department： 123456# 创建Deploymentkybectl create -f deployment_python_http.yml# 创建服务kubectl expose deployment service-test# 查看服务kubectl get svc 下面编辑yml文件，准备更新：1kubectl edit deployment service-test 更改echo内容，保存退出，Pod就被更新了。 12# 删除服务kubectl delete services nginx-deployment NodePort创建文件pod_nginx.yml：12345678910111213apiVersion: v1kind: Podmetadata: name: nginx-pod labels: app: nginxspec: containers: - name: nginx-container image: nginx ports: - name: nginx-port containerPort: 80 创建Pod： 1kubectl create -f pod_nginx.yml 为Pod指定服务： 123kubectl expose pods nginx-pod --type=NodePort# 查看服务kubectl get svc 这样就可以通过Node访问到服务了。但是一但Pod被关闭，服务就无法使用了。因此可以使用下面的方法： 创建service_nginx.yml： 12345678910111213apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: ports: - port: 32333 # 此两处必须介于30000到32768 nodePort: 32333 targetPort: nginx-port protocol: TCP selector: app: nginx type: NodePort 开启服务： 1kubectl create -f service_nginx.yml 之后就可以访问了。 kopskops是Kubernetes自己开发的用于生产环境的工具。 kops Github页面 安装方法：123curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64chmod +x kops-linux-amd64sudo mv kops-linux-amd64 /usr/local/bin/kops 建立集群：1kops create cluster --node-count=2 --name=k8s 删除集群：1kops delete cluster --name=k8s --yes 运维与监控Docker 命令行查看查看容器内状况： 1docker top container_id 查看节点所有容器情况： 1docker stats WeaveScopeWeaveScope Github页面 安装过程：123sudo curl -L git.io/scope -o /usr/local/bin/scopesudo chmod a+x /usr/local/bin/scopescope launch 打开4040端口的页面，即可看到WeaveScope。通过这个页面，我们可以可视化管理容器。 添加其他节点到监控中，要在两个节点都执行：1scope launch node_1_ip node_2_ip DevOps 推荐工具： 代码管理 Github Gitlab 码云 bitbucket 代码持续集成 TravisCI GitlabCI Jenkins 代码测试与检查 Codecov SonarQube GitLabGitLab 官网 GitLab CE 下载页 Ubuntu Ubuntu 安装 Gitlab首先开一台虚拟机，用于安装Gitlab（配置要求：推荐4GB内存）： 123456# 安装必要扩展程序sudo apt-get updatesudo apt-get install -y curl openssh-server ca-certificates# 安装邮件提醒工具sudo apt-get install -y postfix# 在安装过程中会出现配置页面，选择Internet Site，其他默认 下载Gitlab： 安装官方版本：12curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashsudo apt-get install gitlab-ee 安装国内镜像版本（仅限Ubuntu 16.04）：在文件/etc/apt/sources.list.d/gitlab-ce.list中写入：1deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial main 再安装Gitlab：1234# 配置GPG公钥curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/nullsudo apt-get updatesudo apt-get install gitlab-ce 安装完成后配置GitLab： 12# 配置GitLabsudo gitlab-ctl reconfigure 安装完毕后，首次登陆需要设置密码。 配置GitLab，可以到/etc/gitlab/gitlab.rb文件中： 12# URLexternal_url '' 修改完成后，让配置生效：1sudo gitlab-ctl reconfigure GitLab CI/CDCI是代码持续化工具，可以在代码提交后自动化执行代码风格检查，单元测试，项目编译等。当然也可以用Jenkins代替。 安装 Runner另开一台虚拟机，首先安装Docker： 1curl -sSL https://get.docker.com/ | sh 安装Gitlab CI Runner：123curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | sudo bashsudo apt-get install -y gitlab-ci-multi-runner 检查是否安装成功：1sudo gitlab-ci-multi-runner status 设置Docker权限：123sudo gpasswd -a gitlab-runner dockersudo service docker restartsudo gitlab-ci-multi-runner restart 注册Runner：12345678910sudo gitlab-ci-multi-runner register# 1. 输入 gitlab_ci 的URL# 2. 输入gitlab-ci的token# 2.1 进入gitlab中随便打开一个Repository-&gt;Setting-&gt;CI/CD# 2.2 进入Runners settings-&gt;Setup a specific Runner manually，复制Token# 3. 输入描述，保存默认即可# 4. 输入Runner Tags，例如demo,test等# 5. 是否Run Untagged builds，false# 6. 是否Lock Runner to current project，false# 7. 选择执行器，shell 查看Runner：1sudo gitlab-ci-multi-runner list 回到Gitlab页面，可以看到runner settings里面多了一个runner。 使用 Runner一个项目要使用Runner，首先需要在项目下建立文件.gitlab-ci.yml。进入一个项目，选择CI/CD-&gt;Pipeline。这时可以看到一个Pipeline。每次提交代码，Pipeline就会自动执行一次，且每一个Stage顺次执行。 使用CI/CD可以自动化执行测试、编译、部署等步骤。 1234567891011121314151617181920212223242526272829# .gitlab-ci.yml# 定义阶段stages: - build - test - deploy# 定义任务 1job1: stage: test # 指定runner tags: - demo script: - echo "First" - echo "Second"# 定义任务 2job2: stage: build tags: - demo script: - echo "Build First" - echo "Build Second"job3: stage: deploy tags: - demo script: - echo "Deploy" 检查代码风格首先注册一个Docker类型的Runner：1234567891011sudo gitlab-ci-multi-runner register# 1. 输入 gitlab_ci 的URL# 2. 输入gitlab-ci的token# 2.1 进入gitlab中随便打开一个Repository-&gt;Setting-&gt;CI/CD# 2.2 进入Runners settings-&gt;Setup a specific Runner manually，复制Token# 3. 输入描述，保存默认即可# 4. 输入Runner Tags，这里是python3.7# 5. 是否Run Untagged builds，false# 6. 是否Lock Runner to current project，false# 7. 选择执行器，docker# 8. 选择Docker Image，python:3.7 提前把Image拉取到本地：1docker pull python:3.7 在项目中加入：12345678910# .gitlab-ci.ymlstages: - stypejob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8 自动化部署CD是持续化部署，即在原来的基础上再进行项目部署。例如有一个项目，经过代码检查后做部署： 12345678910111213141516171819202122# .gitlab-ci.ymlstages: - stype - deployjob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8deploy-job: stage: deploy script: - docker build -t program . - if [$(docker ps -ap --filter name=web)]; then docker rm -f web;fi - docker run -d --name web -p 8030:5000 program tags: - demo # 这个demo是那个runner # 只有master分支变化才执行该job only: - master 如果风格检查不能通过的话，部署是无法进行的。 另外，为了不让用户每一次push代码都触发一次CI/CD，我们可以把master分支锁定住，防止任何人提交。任何人必须在分支中改动。 在Gitlab中配置：Repository-&gt;Protected Branches-&gt;master分支-&gt;Allowed to push 改为No one。 General-&gt;Merge request settings-&gt;Only allow merge requests to be merged if the pipeline succeeds. 用户在提交代码后，进入Gitlab平台，填写Merge Request，等待Pipeline通过。 管理员用户在收到Merge Requst后，则可以执行Merge操作，部署将自动执行。 版本发布首先搭建一个Docker Registry，类似于Docker Hub。 这里创建第三个服务器，作为Docker Host。首先安装Docker，然后执行： 1docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry:2 回到Gitlab-CI服务器上，编辑/etc/docker/daemon.json文件： 123&#123; "insecure-registries": ["Docker_Registry_IP:5000"]&#125; 重启Gitlab-CI服务器上的Docker服务：12sudo systemctl daemon-reloadsudo systemctl restart docker 再从Docker Hub拉取一个镜像： 1234# 拉取busyboxdocker pull busybox# 为其打上标签docker tag busybox Docker_Registry_IP:5000/busybox 再Push到我们的私有仓库：1docker push Docker_Registry_IP:5000/busybox 如果这些步骤成功，则说明配置成功了。 下面修改文件.gitlab-ci.yml，增加一个Release操作： 12345678910111213141516171819202122232425262728293031323334353637# .gitlab-ci.ymlstages: - stype - deploy - releasejob1: stage: stype tags: - python3.7 script: - pip install tax - tax -e pep8 # 当代码库新增一个Tag，该任务不执行 except: - tagsdeploy-job: stage: deploy script: - docker build -t program . - if [$(docker ps -ap --filter name=web)]; then docker rm -f web;fi - docker run -d --name web -p 8030:5000 program tags: - demo only: - master# 增加Release操作release-job: stage: release script: - docker build -t Docker_Registry_IP:5000/demo:$CI_COMMIT_TAG - docker push Docker_Registry_IP:5000/demo:$CI_COMMIT_TAG tags: - demo # 只有代码库新增一个Tag，就会触发一次Release only: - tags $CI_COMMIT_TAG是Gitlab定义的环境变量，是版本的标签，可以通过Git工具提交代码时添加新的Tag。 其他Docker尝试Docker GPU(Docker GPU)[https://blog.opskumu.com/docker-gpu.html] Docker Gitlab(Docker Gitlab)[https://www.jianshu.com/p/080a962c35b6] 安装Gitlab： 1234# 拉取镜像docker pull gitlab/gitlab-ce# 运行容器docker run -d -p 8443:443 -p 8030:80 -p 32222:22 --name gitlab --restart always -v ~/gitlab/config:/etc/gitlab -v ~/gitlab/logs:/var/log/gitlab -v ~/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce 配置Gitlab文件./gitlab/config/gitlab.rb： 123456# 配置http协议所使用的访问地址external_url 'http://192.168.199.231:8030'# 配置ssh协议所使用的访问地址和端口gitlab_rails['gitlab_ssh_host'] = '192.168.199.231'gitlab_rails['gitlab_shell_ssh_port'] = 32222 # 此端口是run时22端口映射的32222端口 配置完成后，重启Gitlab：1docker restart gitlab Docker DNS拉取镜像 1docker pull dns-server 其他机器启动时可以使用参数--dns指定DNS容器。 1docker run --dns=xx.xx.xx.xx images Docker Machine在安装Docker Toolbox时，也自动安装了docker machine。利用docker machine可以创建虚拟机（借助VirtualBox），这个虚拟机小巧且精简，附带Docker，但是功能有限。用户如果想要更全功能的Linux虚拟机，可以使用后面的Vagrant。 创建虚拟机创建虚拟机：1docker-machine create name 常用命令1234docker-machine ls # 列出所有虚拟机docker-machine ssh name # 登录虚拟机docker-machine stop name # 停止虚拟机docker-machine env name # 查看环境变量 切换Docker服务端默认情况下，我们在开机后初次运行Docker Quickstart Terminal时，它就会为我们启动一个虚拟机，这个虚拟机包含了一个Docker Server，所以 这里不必切换Docker服务端 。 利用Docker Machine可以实现切换Docker Server。如果不想把自己本地的计算机搞乱，我们可以直接安装Docker Client，而服务端通过其他方式创建，也可以正常使用。 切换本地Docker服务端首先利用上面的docker-machine命令创建带docker server的虚拟机，然后执行下面的操作。 12345678910111213# 使用命令查看虚拟机的环境变量docker-machine env name# 之后会得到虚拟机的环境变量以及一条命令# eval $(docker-machine env name)# 执行这条语句，我们就切换了Docker服务端eval $(docker-machine env name)# 执行这条语句取消切换docker-machine env --unset# 之后会得到一条命令，我们执行它# eval $(docker-machine env --unset)eval $(docker-machine env --unset) 切换阿里云Docker服务端使用阿里云的ECS，首先得保证账号内有钱。其他云平台道理相同。 官方参考页面 进入官方参考页面，点击第三方驱动插件（3rd-party driver plugins），就可以找到Aliyun ECS（点击进入）。 首先是下载驱动，解压文件，修改得到的文件的后缀为.exe，并将驱动的所在目录添加到环境变量。 打开阿里云平台，管理控制台，访问控制，用户管理，创建AccessKey和Secret。 注意 ：Secret只显示一次，一定要保存好。 回到本地命令行，执行： 123docker-machine create -d aliyunecs --aliyunecs-io-optimized=optimized --aliyunecs-instance-type=ecs.c5.large --aliyunecs-access-key-id=用户ID --aliyunecs-access-key-secret=用户Secret --aliyunecs-region=cn-qingdao 虚拟机name# 这些参数的值可以在阿里云平台上的创建页面查看。 创建好以后，就可以按照上一节的内容切换服务端了。 Vagrant（可选）Vagrant是一个虚拟机管理工具。可以用脚本的方式快速创建虚拟机（需要安装VirtualBox）以及虚拟机集群。如果不想直接在自己的电脑上安装Docker，可以尝试Vagrant。 Vagrant官网Vagrant下载页VirtualBox官网 Vagrant 镜像官方镜像首先进入Vagrant官网，点击Find Boxes，输入要查找的虚拟机。例如输入Unbutu 16.04，搜索后进入，选择New，会出现如下页面： 1234# 创建Vagrantfilevagrant init ubuntu/xenial64# 执行Vagrantfilevagrant up 执行页面中提示的操作，Vagrant会在当前目录创建该虚拟机。 非官方镜像如果上面的过程太漫长，可以自定义添加Box。打开vagrantbox.es，按照上面的提升操作添加虚拟机镜像。 例如： 123vagrant box add ubuntu_new https://atlas.hashicorp.com/envimation/boxes/ubuntu-xenial-dockervagrant init ubuntu_newvagrant up 如果命令行下载速度较慢，可以使用迅雷等工具下载到本地，再使用： 123vagrant box add ubuntu_new /path/to/boxvagrant init ubuntu_newvagrant up Vagrant SSH在虚拟机目录下执行： 1vagrant ssh 即可进入虚拟机。 Vagrant 常用命令12345678910111213141516vagrant box add # 添加一个boxvagrant box list # 列出所有的boxvagrant box remove # 删除boxvagrant init ubuntu/trustry64 # 初始化一个新的虚拟机vagrant up # 启动虚拟机vagrant ssh # 登录虚拟机vagrant halt # 关闭虚拟机vagrant reload # 重启虚拟机vagrant suspend # 挂起虚拟机vagrant resume # 恢复挂起vagrant destory [name|id] # 销毁虚拟机vagrant package # 打包当前虚拟机到boxvagrant global-status # 查看当前所有虚拟机状态vagrant ssh-config # 查看ssh连接信息 Vagrant 配置文件通过编辑脚本也可以利用vagrant同时创建多台虚拟机。 我们在使用之前的方法创建虚拟机时，目录下会自动生成Vagrantfile文件，这就是Vagrant虚拟机的配置文件，里面包含虚拟机的配置，SSH的配置以及Vagrant的基础配置，这些配置是基于Ruby语法的。 单机模式配置： 1234567891011121314151617181920212223# boxconfig.vm.box = "CentOs7"# hostnameconfig.vm.hostname = "for_work"# 虚拟机网络设置# 虚拟机网络有两种连接方式：# 主机模式（host-only），虚拟机只能和主机通信，其他人无法访问到虚拟机。# 桥接模式（bridge），虚拟机成为同主机在同一局域网下的独立主机。config.vm.network "private_network", ip: "192.168.33.10"#config.vm.network "public_network"# 同步目录设置config.vm.synced_folder "/Users/path/www", "/vagrant"# 端口转发设置config.vm.network :forwarded_port, guest: 80, host: 80# 配置多行脚本config.vm.provision "shell", inline: &lt;&lt;-SHELL sudo apt-get updateSHELL 参考脚本配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 例 1：Vagrant.configure("2") do |config| config.vm.define :web do |web| web.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "web", "--memory", "512"] end web.vm.box = "base_box" web.vm.hostname = "web" web.vm.network :private_network, ip: "192.168.33.10" end config.vm.define :redis do |redis| redis.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "redis", "--memory", "512"] end redis.vm.box = "base_box" redis.vm.hostname = "redis" redis.vm.network :public_network, ip: "192.168.33.11" endend# 例 2：Vagrant.require_version "&gt;=1.6.0"boxes = [ &#123; :name =&gt; "node1", :eth1 =&gt; "192.168.205.10", :mem =&gt; "1024", :cpu =&gt; "1", :port =&gt; "8888" &#125;, &#123; :name =&gt; "node2", :eth1 =&gt; "192.168.205.11", :mem =&gt; "1024", :cpu =&gt; "1", :port =&gt; "9999" &#125;]Vagrant.configure(2) do |config| config.vm.box = "base_box" boxes.each do |opts| config.vm.define opts[:name] do |config| config.vm.hostname = opts[:name] config.vm.provider "vmware_fusion" do |v| v.vmx["memsize"] = opts[:mem] v.vmx["numvcpus"] = opts[:cpu] end config.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--memory", opts[:mem]] v.customize ["modifyvm", :id, "--cpus", opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] # config.vm.network :public_network config.vm.network "forwarded_port", guest: 80, host: 8050 end end config.vm.synced_folder "./labs", "/home/vagrant/labs" # 本地需要手动创建同步目录 config.vm.provision "shell", privileged: true, path: "./setup.sh" # 初始化脚本，包括更换源，安装Docker，参考下面的编写end 参考文档 配置一个带Docker的Vagrant虚拟机创建一个目录，并配置如下文件： VirtualBox labs sources.list setup.sh 编辑setup.sh如下：12345678910111213141516171819202122232425262728293031sudo cp /etc/apt/sources.list /etc/apt/sources.list.backsudo rm /etc/apt/sources.listsudo touch /etc/apt/sources.listsudo cp /home/vagrant/labs/sources.list /etc/apt/sources.list sudo apt-get remove docker docker-engine docker.io containerd runcsudo apt-get updatesudo apt-get install -y \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable"sudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.iosudo mkdir -p /etc/dockersudo gpasswd -a ubuntu dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://sfpj1t4c.mirror.aliyuncs.com"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart dockersudo service docker restartsudo reboot 编辑sources.list内容如下（适用于ubuntu 16.04，其他版本可以自行搜索）：123456789101112131415deb http://mirrors.aliyun.com/ubuntu/ xenial maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial maindeb http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 在VirtualBox下执行1vagrant init 会生成Vagrantfile文件。打卡文件，编辑：12345678910# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;box_base&quot; config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8030 config.vm.network &quot;public_network&quot; config.vm.synced_folder &quot;./labs&quot;, &quot;/home/vagrant/labs&quot; config.vm.provision &quot;shell&quot;, privileged: true, path: &quot;./setup.sh&quot;end 保存后：1vagrant up 即可创建虚拟机。输入如下命令登录虚拟机： 1vagrant ssh 安装扩展123456# 查看插件列表vagrant plugin list# 安装插件vagrant plugin install vagrant-scp# 使用 scp 复制文件到虚拟机vagrant scp ../node3/labs/ docker-node1:/home/vagrant/labs/ 参考文档Dockerfile 语法命令 FROM定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 123FROM scratch # 制作base imageFROM ubuntu # 使用base imageFROM ubuntu:14.04 # 使用特定版本的image LABEL相当于注释： 123LABEL maintainer="author@web.com"LABEL version="1.0"LABEL description="The Description" RUN用于执行后面跟着的命令行命令。 123456789101112FROM nginxRUN echo '这是一个本地构建的nginx镜像' &gt; /usr/share/nginx/html/index.html# RUN 有以下俩种格式：# 1. shell 格式：RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。# 2. exec 格式：RUN ["可执行文件", "参数1", "参数2"]# 例如：# RUN ["./test.php", "dev", "offline"] 等价于 RUN ./test.php dev offline 另外，Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 12345678910FROM centosRUN yum install wgetRUN wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz"RUN tar -xvf redis.tar.gz# 以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum install wget \ &amp;&amp; wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz" \ &amp;&amp; tar -xvf redis.tar.gz# 以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 编辑保存之后就可以构建Docker镜像了。1docker build -t nginx:test . CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build用的。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效；如果在docker run中指明了命令，CMD就会被忽略。 12345# Shell 格式CMD &lt;shell 命令&gt; # Exec 格式CMD ["&lt;可执行文件或命令&gt;","&lt;param1&gt;","&lt;param2&gt;",...] CMD ["&lt;param1&gt;","&lt;param2&gt;",...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 ENTRYPOINTENTRYPOINT会让容器以应用程序或服务的方式运行。它类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，此选项的参数可当作要运行的程序覆盖 ENTRYPOINT 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 1ENTRYPOINT ["&lt;executeable&gt;","&lt;param1&gt;","&lt;param2&gt;",...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT ["nginx", "-c"] # 定参CMD ["/etc/nginx/nginx.conf"] # 变参 123456789# 1、不传参运行docker run nginx:test# 容器内会默认运行以下命令，启动主进程。# nginx -c /etc/nginx/nginx.conf# 2、传参运行docker run nginx:test -c /etc/nginx/new.conf# 容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件)# nginx -c /etc/nginx/new.conf WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 12WORKDIR &lt;工作目录路径&gt;WORKDIR /test # 会自动创建 COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 12345678910COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] ["&lt;源路径1&gt;",... "&lt;目标路径&gt;"]# [--chown=&lt;user&gt;:&lt;group&gt;]：可选参数，用户改变复制到容器内文件的拥有者和属组。# &lt;源路径&gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：COPY hom* /mydir/COPY hom?.txt /mydir/# &lt;目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格式一致（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点：在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 12345WORKDIR /rootADD main test/ # /root/test/mainWORKDIR /ROOTCOPY main test/ 如果想要添加远程文件，还是要用命令的方式（curl、wget）较好： ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 1234567891011ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...# 例如ENV NODE_VERSION 7.2.0RUN curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz" \ &amp;&amp; curl -SLO "https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc"# 不加/bin/bash，会导致无法识别ENV变量RUN ["/bin/bash", "-c", "echo $ENV_KEY"] ARG构建参数，与 ENV 作用一至。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷，可以通过 -v 参数修改挂载点。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。 12VOLUME ["&lt;路径1&gt;", "&lt;路径2&gt;"...]VOLUME &lt;路径&gt; EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 1EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 1USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这是执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 1ONBUILD &lt;其它指令&gt; 总结 应使用LABEL注明文件作用以及内容； 应使用ENV注明主要变量，方便维护； 应当使用WORKDIR注明工作路径，且推荐使用绝对路径； 应使用COPY为主，需要解压时可以使用ADD； 应当在使用RUN时，尽量合并命令，防止产生多个层； 应当在使用Exec格式时使用”/bin/bash -c”来识别ENV变量，且被执行的指令应放到一起； 参考 菜鸟教程 YAML 语法YAML脚本的后缀为yml或yaml，基本语法如下： 大小写敏感； 使用缩进表示层级关系； 缩进不允许使用tab，只允许空格； 缩进的空格数不重要，只要相同层级的元素左对齐即可； ‘#’表示注释。 YMAL 支持三种数据类型： 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值 YAML 对象对象键值对使用冒号结构表示 key: value，冒号后面要加一个空格。 也可以使用 key:{key1: value1, key2: value2, …}。 还可以使用缩进表示层级关系； 123key: child-key: value child-key2: value2 较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value，意思即对象的属性是一个数组[complexkey1,complexkey2]，对应的值也是一个数组[complexvalue1,complexvalue2]： 123456? - complexkey1 - complexkey2: - complexvalue1 - complexvalue2 YAML 数组以 - 开头的行表示构成一个数组： 123456789101112131415161718192021222324# 多行表示- A- B- C# 行内表示：key: [value1, value2, ...]# 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。- - A - B - C# 一个相对复杂的例子：companies: - id: 1 name: company1 price: 200W - id: 2 name: company2 price: 500W# 也可以表示为companies: [&#123;id: 1,name: company1,price: 200W&#125;,&#123;id: 2,name: company2,price: 500W&#125;] 复合结构数组和对象可以构成复合结构，例： 123456789languages: - Ruby - Perl - Python websites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 纯量 字符串 布尔值 整数 浮点数 Null 时间 日期 表示方法如下 123456789101112131415161718192021boolean: - TRUE #true,True都可以 - FALSE #false，False都可以float: - 3.14 - 6.8523015e+5 #可以使用科学计数法int: - 123 - 0b1010_0111_0100_1010_1110 #二进制表示null: nodeName: 'node' parent: ~ #使用~表示nullstring: - 哈哈 - 'Hello world' #可以使用双引号或者单引号包裹特殊字符 - newline newline2 #字符串可以拆成多行，每一行会被转化成一个空格date: - 2018-02-17 #日期必须使用ISO 8601格式，即yyyy-MM-dddatetime: - 2018-02-17T15:02:31+08:00 #时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 引用&amp; 用来建立锚点，&lt;&lt; 表示合并到当前数据，* 用来引用锚点: 123456789101112131415161718192021222324252627defaults: &amp;defaults adapter: postgres host: localhostdevelopment: database: myapp_development &lt;&lt;: *defaultstest: database: myapp_test &lt;&lt;: *defaults# 相当于defaults: adapter: postgres host: localhostdevelopment: database: myapp_development adapter: postgres host: localhosttest: database: myapp_test adapter: postgres host: localhost 参考 菜鸟教程]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云物联网平台使用]]></title>
    <url>%2F2020%2F02%2F04%2FALI-IOT%2F</url>
    <content type="text"><![CDATA[数据的流程数据从节点设备产生，到用户自己的服务器这一过程，我们把它分为两部分。前半部分是节点设备产生数据，经过网络传递到阿里云物联网平台，这一过程使用MQTT协议。后半部分则有阿里云物联网平台将数据转交给阿里云的其他产品，如用户自己的云平台。 节点接入的两种方式。资源受限的节点设备。使用Paho MQTT Client协议栈接入没有TLS透传模式MQTT通信协议与服务器约定： 消息负载的二进制表达 消息主题 资源丰富的节点设备。使用Linkkit SDK接入FreeRTOS，Json，TLS物模型MQTT通信协议安装物模型规定（解耦设备端与应用端开发） Web 后端基于阿里云物联网平台HTTP/2 SDK订阅设备数据使用SpringBoot + Mybatis轻量级框架可开发服务端逻辑MySQL存储设备数据 Web 前端ReactUmi.js Antd 框架组件dva.js数据管理Bizcharts数据可视化定时向后端请求数据 软件STM32CubeMXIAR Embedded WorkbenchPahoo MQTT Client StackLinkkit C-SDKMbedTLSFreeRTOS JDK 8Intellij IDEANode.jsMySQLNavicat for MySQLVSCodeGit MQTTMQTT 介绍MQTT（消息队列遥测传输）是一种基于TCP开发的协议，工作在应用层，使用异步通信模式，解耦通信双方。 MQTT协议具有许多优点，如可靠性，双向传输性，低开销，有序性，低带宽等，采用发布订阅模式。 MQTT协议中包含了四类关键字。 客户端（client）服务器端/代理（server/broker） 会话（session） 消息（message）主题（Topic） 订阅（subscribe）发布（publish） 角色：代理，负责收发数据；发布者，发布消息到代理；订阅者，订阅消息，接收代理推送的消息。 发布者和订阅者通过不同的Topic进行消息的双向传输。二者可以从Topic中发布和订阅消息。 每个产品会定义Topic类，下属的所有设备都会生成相应的Topic。例如某设备的气压，温度，湿度等Topic。 MQTT 协议格式主题：主题具有层级结构，支持通配符。通配符有单级通配符+与多级通配符#。 连接与会话：连接由客户端发起，服务器根据连接参数（客户端ID，用户名，密码，心跳间隔，消息-主题-遗嘱，会话保持等）对客户端鉴权和授权，连接参数也将决定此次会话是否是持久会话。 MQTT报文格式：固定报头：2~5 Bytes，是所有报文必须包含的（MSB在前，LSB在后）。 4 bits 1 bit 2 bits 1 bit 1 ~ 4 Bytes Message Type UDP QoS Level RETAIN Remaining Length 可变报头：长度由Remaining Length决定； 有效载荷：长度由Remaining Length决定。 Message Type：共14种。UDP，QoS Level，RETAIN：只有PUBLISH报文使用。QoS：0 – 最多收到一次，接收方不产生应答；1 – 最少收到一次，接收方返回PUBACK报文；2 – 保证仅收到一次，且消耗资源较大。RETAIN：当客户端发送的消息中Retain置位，则服务器保留该条消息以及QoS级别，当有新的订阅发生，并与该消息主题一致，服务器就会马上把该Retain置位的消息转发给订阅者（相当于给订阅者写了留言，订阅者一上线就收到了这条消息）。服务器仅保留最近一个Retain置位的消息。删除Retain置位的消息是通过客户端发送一条Payload为空的Retain为空的消息。Remaining Length：决定可变报头与有效载荷的总长度。 CONNECT – 连接报文（0x01）： 可变报头 2 Bytes 4 Bytes 1 Byte 1 bit 1 bit 1 bit 2 bits 1 bit 1 bit 1 bit 2 Bytes 可变报头长度 MQTT 版本（0x03） 用户名Flag 密码Flag Will Retail Will QoS Will Flag Clean Session 保留 Keep Alive Timer 标志位 为 1 时表示负载中包含该部分信息。 负载 1 Byte 1 Byte 1 Byte 1 Byte 1 Byte Client Indentifier Will Topic Will Message 用户名 密码 遗嘱（Will）：是连接服务器时告诉服务器的消息，服务器会保存这些消息。当连接意外断开时，服务器会将遗嘱消息转发给所有订阅该设备上Topic的设备。 SUBSCRIBE – 订阅报文（0x08）： 可变报头 2 Bytes Message ID 负载 2 Bytes N Bytes 6 bits 2 bits Topic name String Length Topic Name 保留 QoS Level QoS Level：作用于服务器到客户端的下行链路。 PUBLISH – 发布报文（0x03）： 可变报头 2 Bytes N Bytes 2 Bytes Topic name String Length Topic Name Message ID 负载 N Bytes Publish Message（可选） QoS Level：作用于客户端到服务器的上行链路。 UNSUBSCRIBE – 取消订阅（0xA）：有可变头部和负载 PINGREQ – 发送心跳（0xC）：无可变头部和负载 DISCONNECT – 断开连接（0xE）：无可变头部和负载 阿里云物联网平台物联网体系应用层应用层主要包括了关于物联网的Web应用，例如智慧交通，智能家居等服务端应用，也包括物联网应用接口。 在阿里云物联网体系中还加入了阿里云物联网平台作为物联网应用的总接口。 网络层终端与应用层的各个应用通信，需要借助网络。例如：2/3/4G，NB-IoT，WiFi，蓝牙，LoRaWAN等。 感知层包括物联网终端设备，例如传感器，芯片，控制器，通信模组等。 平台功能设备接入：支持多种通信协议，提供多种通信协议SDK，即可满足长连接，也满足短连接，提供多种入网接入访问。设备通信：可以实现双向通信。设备管理：支持完整的设备声明周期管理，包括设备注册，功能定义，脚本解析，在线调试，远程配置，固件升级，远程维护，实时监控，分组管理，设备删除等。提供上下线通知，数据存储，OTA升级，设备影子缓存（用于解决不可靠网络通信问题）。安全能力：一机一密的设备认证，安全级别高；一型一密的安全机制，安全级别普通。支持TLS（HTTP，MQTT），DTLS（CoAP），安全级别高；支持TCP（MQTT），UDP（CoAP），安全级别普通。数据转发：可配置规则实现设备与设备的通信；支持消息转发至消息队列，表格存储，流计算，TSDB，函数计算等应用中。 另外还有：服务端订阅设备消息：平台数据可以通过HTTP/2通道至服务器，并提供HTTP/2 SDK，实现数据订阅功能。服务器也可以使用SDK传输数据至平台。 产品产品是设备的集合，指通常具有相同功能的一组设备。每一个产品都有一个ProductKey。 设备归属于某个产品之下，指具体的某一个终端。每一个设备都有一个DeviceName。 设备直连设备直接连接物联网平台。 网关连接网关：网关是可以直接连接物联网平台的设备，可以拥有子设备。网关是代理子设备连接云端的设备。 子设备：只能通过网关连接平台。 三元组平台会为每一台设备分配一个三元组。三元组内容如下：ProductKey：产品标识，在全网具有唯一性。DeviceName：设备标识，仅在产品维度内具有唯一性。DeviceSecret：设备秘钥，与DeviceName成对出现。 认证方案一共有三种认证方案：一机一密：该方案要求设备事先烧录自己的三元组，在建立连接时，设备携带自己的三元组在平台上进行认证，认证通过后才可以传输数据。一型一密：所有设备可以烧录相同的固件（ProductKey和DeviceName），设备在认证通过后接收自己的DeviceSecret。子设备认证：网关联入平台后，子设备的认证方案。 通信模式发布/订阅模式：平台维护所有的Topic的发布/订阅用户列表，当有发布者发布某Topic消息的时候，平台会在用户列表中查询所有订阅者，并将消息下发给订阅某Topic的订阅者。适用于非实时场景。 RRPC模式：基于MQTT协议封装的同步通信模式，服务端下发消息，设备可以同步得到响应。适用于实时场景。 设备声明周期管理创建设备：在平台上创建设备。激活设备：由设备申请激活。启用设备：由平台控制设备的启用。禁用设备：由平台控制设备的禁用。删除设备：在平台上删除设备。 设备状态：可以查看设备是否激活，是否在线等。设备标签：可以查看设备厂商、型号等。 物模型属性：设备运行状态，支持GET与SET服务，应用可以发起对属性的读取和设置请求。服务：设备可以被外部调用的方法，可以设置输入参数与输出参数。事件：设备运行时的事件在感知外部和处理通知消息后等激发，可以包含多个输出参数，如设备故障、完成某任务的消息等。事件可以被订阅和推送。 消息流程终端设备 MQTT协议 阿里云平台 HTTP/2协议 个人服务器 HTTPS/HTTP 浏览器，用户终端 设备管理查看数据：支持一次数据快照与历史数据查看。固件升级：支持OTA升级。 数据传输Alink协议接入：用于设备与云端的双向通信，格式为Json。透传接入：设备直接上传二进制数据，云端对数据进行解析，并转化为Alink协议的格式。 服务端订阅配置HTTP/2服务端订阅后，物联网平台会将消息推送到服务端，服务端通过接入HTTP/2 SDK后就可以接收物联网平台的消息。HTTP/2 SDK提供身份认证，Topic订阅，消息发送和接收的能力，并支持设备接入和云端接入。HTTP/2 SDK即适用于服务端与平台传输大量信息，也支持设备与物联网平台之间的消息传输。 规则引擎当设备基于Topic与平台进行消息通信时，用户可以通过规则引擎实现对设备数据的处理和转发，实现将数据转发至阿里云其他产品中。 转发支持转发到RDS，Table Store，HiTSDB等数据库，DataHub进行流计算、离线计算，函数计算，另一个Topic，消息队列五种形式。 设备端开发设备端开发SDK包含： C SDK Android SDK NodeJS SDK Java SDK Python SDK iOS SDK 云端开发云端开发SDK支持 Java Python PHP .NET。 API 包含： 产品管理 设备管理 分组管理 规则引擎 Topic管理 消息通信 设备影子 温湿度传感器案例功能描述配置一个温湿度检测物联网终端设备，可以监测当前温湿度，可以配置温度阈值，当高于温度阈值时，发出报警。 设备方面： 设备每5秒上报温湿度，闪烁绿灯； 温度超过阈值，亮红灯，并每10秒向用户报警一次； 收到用户解除警报信息后红灯闪烁； 温度正常后，灭掉红灯。 平台方面： 温湿度值转发到用户服务器，同时在Web端显示温湿度曲线； 报警消息转发到用户服务器，在Web端显示； Web页面可以解除警报。 Web页面可以设置阈值。 物模型属性： 当前温度 当前湿度 温度阈值 事件： 属性达到上限 温度超过阈值 服务： 设置阈值 获取属性值 解除警报 项目流程节点方面： 初始化 系统初始化 平台初始化 MQTT连接参数计算 连接阿里物联网平台 订阅相关主题 主循环 MQTT连接是否正常 读取温湿度 判断是否报警 发布设备属性 MQTT订阅回调函数 收到设置阈值Topic消息 更新温度阈值 收到解除警报Topic消息 解除警报 阿里云IoT平台配置打开阿里物联网云平台页面，登录并进入产品管理页面。点击创建产品，选择基础版，输入产品名称，选择设备，认证选择否。 进入设备页面，点击添加设备，输入设备名称，就可以生产三元组了。 回到产品页面，在Topic类列表定义Topic类实现自定义Topic。 在服务端订阅中设置：设备上报消息与设备状态变化通知，点击保存。 服务端应用开发开发流程为： 需求分析：功能、交互 系统设计：UI设计、API设计、数据库设计 编码开发：前端编码、后端编码 联调测试：功能测试、交互测试 系统运维：发布上线、持续运维 后端开发流程 数据库设计 API 约定 后端编写 前后端联调 部署上线运维 框架 MySQL Mybatis：在Java中操作MySQL SpringBoot：整合了MyBatis + SpringMVC等 Maven：跨平台项目管理工具 使用 IoT Studio 快速开发在IoT Studio中，用户可以快速构建Web应用，手机APP，以及后端服务。 进入IoT Studio，选择开发服务，新建项目，在项目产品和项目设备中关联自己的设备。 之后选择Web可视化开发或移动应用开发，编辑相关内容，生成应用程序。例如生成Android App，经过几分钟编译打包后，在移动应用开发界面的设置，构建管理中下载安装APP。]]></content>
      <categories>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>物联网</tag>
        <tag>STM32</tag>
        <tag>阿里云</tag>
        <tag>NodeMCU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 入门]]></title>
    <url>%2F2020%2F02%2F03%2FRedisFirst%2F</url>
    <content type="text"><![CDATA[NoSQLNoSQL是一类新出现的数据库，不支持SQL语法，也不是关系型数据库，而是基于KEY-VALUE方式存储数据。他们没有通用的语言，而是各自有各自的语法和用法。他们往往适用于关系简单，而对事务强的业务有很好的支持。 NoSQL数据库常见的有： Mongodb Redis Hadoop Redis 简介官方网站参考文档 支持数据的持有化 不仅支持key-value，还支持list，set，zset，hash等结构。 支持数据备份 性能极高 拥有丰富的数据类型 操作都是原子性的 Redis常常用来做缓存，其读写效率很高，适用于社交平台等大型系统等。 Redis 安装与配置安装配置打开配置文件redis.conf bind：绑定的IPport：绑定的端口daemonizs：是否为守护进程（改为yes）dbfilename：数据存储文件名dir：存储路径logfile：日志文件database：数据库数量slaveof：设置主从（一般不用） 启动1234567891011121314# 直接运行sudo redis-server /etc/redis/redis.confps -ef | grep redis # 得到PID号sudo kill -9 PID号# 以服务方式运行sudo service redis startsudo service redis stop# 进入redis，默认进入0号数据库redis-cli# redis-cli 命令ping # ping数据库select 5 # 切换数据库 Redis数据类型 string：字符串，可以接受任意二进制数据，最大可容纳512MB。 hash：哈希，用于存储对象，包含属性、值，值的类型为string。 list：列表，每个元素都是string，按照插入顺序排序。 set：集和（无序），元素具有唯一性，且不可修改。 zset：有序集和，元素具有唯一性，且每个元素具有一个权重，并按照权重从小到大排序，也是没有修改操作。 数据操作基本操作123456789# 键命令keys pattern # 支持正则表达式keys * # 查看所有键keys 'a*' # 查看所有a开头的键exists key # 查看是否存在键type key # 查看类型del key # 删除键expire key seconds # 设置过期时间ttl key # 查看键的剩余时间 字符串操作123456789# 保存set key valuesetex key seconds value # 设置过期时间mset key1 value1 key2 value2 # 设置多个键值append key value # 追加值# 获取get key # 如果不存在返回(nil)mget key1 key2 key3 哈希操作12345678910# 设置hset key field value # 设置单个属性hmset key field1 value1 field2 value2 # 设置多个值# 获取hkeys key # 获取属性hget key field # 获取值hmget key field1 field2 # 获取多个值hvals key # 获取所有值# 删除hdel key field1 field2 # 删除属性 执行hset可能会抛出无法保存快照的错误，可以执行如下命令：1config set stop-writes-on-bgsave-error no 列表操作123456789# 插入lpush key value1 value2 # 左侧插入rpush key value1 value2 # 右侧插入linsert key before/after old_key new_key # 在old_key前/后插入数据new_key# 显示lrange key start stop # 从几到几，-1表示最后一个# 修改lset key index value lrem key count value # 删除几个某元素，0表生所有；&gt;0表示从左向右；&lt;0表示从右向左 集和操作123456# 增加sadd key value1 value2 # 获取smmbers key # 获取所有元素# 删除srem key value1 value2 # 删除某些元素 有序集和123456789# 增加zadd key score1 member1 score2 member2# 获取zrange key start stop zrangebyscore key min max # 查看权重在区间的元素zscore key member # 查看权值# 删除zrem key member1 member2zremrangebyscore key min max # 删除权重在区间的元素 与 Pyhton 交互安装Redis包1pip install redis 使用123456789from redis import *# 连接数据库，参数：主机名；端口；数据库编号sr = StrictRedis(host='localhost', port=6379, db=0)res = sr.set('key', 'value') # 返回布尔值，表示是否成功。res = sr.get('key') # 如果有，返回该值；没有，返回Noneres = sr.delete('key') # 返回删除成功的数量res = sr.keys(pattern='*') # 返回列表 配置Django中保存session到Redis1pip install django-redis-sessions 在setting.py中配置Redis1234567SESSION_ENGINE = 'redis_sessions.session'SESSION_REDIS_HOST = 'localhost'SESSION_REDIS_PORT = 6379SESSION_REDIS_DB = 2SESSION_REDIS_PASSWORD = '' # 键前缀SESSION_REDIS_PREFIX = 'session' 使用方法依然不变12request.session['key'] = 1num = request.session['key'] Redis 主从在Redis中，主从的数据是共享的，也就是实现了数据的冗余保存，这样可以防止一台机器挂掉后数据丢失的问题。一个Redis主机可以有多个从机，一个从机也可以有多个从机。写数据要在主机中，从机可以读取数据。这样也可以实现数据的读写分离。一般情况下，一个网站的数据读写比例为 10:1 ，因此可以配置多个从机用于读取数据。 主机配置可以保存不变，只是IP地址应该使用局域网或公网IP。配置完成运行服务。从机配置，并启动。123bind 本机IPslaveof 主机IP 主机PORTport 从机PORT，不能与主机冲突 查看某机角色以及状态。1redis-cli -h 某机IP -p 某机PORT info Replication Redis 集群当用户量达到一定量级时，就需要将Redis服务规模升级为集群。 配置过程首先配置3个配置文件， 12345678port 7000bind 本机IPdaemonize yespidfile 7000.pidcluster-enabled yescluster-config-file 7000_node.confcluster-node-timeout 15000appendonly yes 12345678port 7001bind 本机IPdaemonize yespidfile 7001.pidcluster-enabled yescluster-config-file 7001_node.confcluster-node-timeout 15000appendonly yes 12345678port 7002bind 本机IPdaemonize yespidfile 7002.pidcluster-enabled yescluster-config-file 7002_node.confcluster-node-timeout 15000appendonly yes 之后依据这3个配置文件启动3个Redis服务。 使用命令运行集群12345678# 复制程序sudo cp /usr/share/doc/redis-tools/examples/redis-trib.rb /usr/local/bin# 安装依赖sudo gem install redis# 安装Ruby，保证是最新版sudo apt-get install ruby# 创建集群redis-trib.rb create --replicas 1 IP_1:PORT_1 IP_2:PORT_2 IP_3:PORT_3 创建完成后，会输出几个Redis主机和从机，几个主机分别存储一部分数据，按数据槽存储，槽编号范围是0 ~ 16383。 与Python交互1pip install redis-cluster 123456789101112from rediscluster import *startup_nodes = [ &#123;'host': '', 'port': PORT_1&#125; # Redis主机]src = StrictRedisCluster( startup_nodes=startup_nodes, decode_responses=True)result = src.set('key','val')]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>NoSQL</tag>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 入门]]></title>
    <url>%2F2020%2F01%2F30%2FDjangoFirst%2F</url>
    <content type="text"><![CDATA[绪论Django 3 官方参考文档点击进入 Django 2.2 官方参考文档点击进入 Django 2.2 其他参考文档点击进入 Django 1.11 官方参考文档点击进入（英文） Django 1.11 中文参考文档点击进入 Django 2 及后续版本不再支持 Python 2； Django 3 及后续版本不再支持 Python 3.5 及以下版本。 Django 1 与 2 的区别主要区别如下： url 用法：Django 1 主要使用 url 来配置，参数部分使用()做匹配；Django 2 使用 path 来配置，参数部使用&lt;&gt;做匹配，不支持传统的正则表达式。这里Django 2 兼容 Django 1 ，可以用re_path来做Django 1中url的操作。 路由分发 include。 ORM 外键：Django 2 的外键必须加on_delete属性 参考文章一参考文章二 Django 3.0 新特性（2019年12月 推出） 仅支持 Python 3.6以上版本。 支持使用 MariaDB 10.1 或更高版本的数据库。 开始将新增对 ASGI 的支持。这意味着 Django 3 可以支持异步操作，消除阻塞操作对程序的影响。 新增枚举类型 TextChoices 和 IntegerChoices 类。 枚举示例：12345678910111213141516171819class Student(models.Model): FRESHMAN = 'FR' SOPHOMORE = 'SO' JUNIOR = 'JR' SENIOR = 'SR' GRADUATE = 'GR' YEAR_IN_SCHOOL_CHOICES = [ (FRESHMAN, 'Freshman'), (SOPHOMORE, 'Sophomore'), (JUNIOR, 'Junior'), (SENIOR, 'Senior'), (GRADUATE, 'Graduate'), ] year_in_school = models.CharField( max_length=2, choices=YEAR_IN_SCHOOL_CHOICES, default=FRESHMAN, ) Django 基本操作django-admin 基本命令12345678910django-admin startproject # 创建Django项目django-admin startapp # 创建Django应用django-admin check # 检查项目完整性django-admin test # 执行单元测试django-admin runserver # 启动服务器django-admin shell # 进入Django Shelldjango-admin makemigrations # 创建数据库迁移文件django-admin migrate # 执行迁移文件django-admin dumpdata # 导出数据库数据django-admin loaddata # 导入数据库数据 目录结构项目结构 A （本次使用） Project # 项目目录 manage.py # 项目管理文件 project_name # 项目配置目录 asgi.py # Django 3.0 新增文件 settings.py # 项目配置 urls.py # 项目路由 wsgi.py # Web 与 Django 交互入口 my_app # 创建的Django应用目录 migrations # 数据库迁移文件目录 static # 静态文件目录 templates # 模板目录 index.html templatetags # 自定义标签过滤器目录 __init__.py urls.py # 应用路由 apps.py # 应用声明 models.py # 应用模型 test.py # 单元测试 admin.py # Admin模块 views.py # 应用视图 创建过程如下：1234567django-admin startproject project_namecd project_namedjango-admin startapp my_appcd my_appmkdir templatesmkdir templatetagsmkdir static 项目结构 B部分Django项目也会用到这种结构，即将模板，过滤器，静态文件等目录放在应用的外部。 Project manage.py project_name settings.py urls.py wsgi.py （ Web 与 Django 交互入口） templates my_app_templates index.html templatetags # 自定义标签过滤器 __init__.py my_app migrations urls.py apps.py models.py test.py admin.py views.py 配置过程123456789101112131415161718192021222324252627282930313233343536373839404142# 每创建一个应用，都要在项目setting.py中声明该应用INSTALLED_APPS=[ ... 'my_app', # 或写成 'my_app.apps.MyAppConfig' # 具体可以到应用的apps.py文件中查看命名]# 配置项目的数据库，可以保持默认SQLiteDATABASES=[ 'default': &#123; 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), &#125;]# 如果要改为MySQL，配置如下。注意：首次运行可能需要安装所提示的Python扩展包。DATABASES=[ 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': '数据库名称', # 必须手动创建 'USER': 'root', 'PASSWORD': '123456', 'HOST': 'localhost', 'PORT': 3306, &#125;]# 如果使用项目结构 B，则做下面的配置，配置要渲染的模板的目录TEMPLATES = [ ... 'DIR' = [os.path.join(BASE_DIR, 'templates')] ...]# 修改默认语言和时区LANGUAGE_CODE = 'zh-hans'TIME_ZONE = 'Asia/Shanghai'# 如果项目完成后，在交付阶段，要将DEBUG关闭，并配置允许访问的主机DEBUG = FalseALLOWED_HOSTS = ['*'] 配置完成后，在应用my_app下的views.py中添加一个简易的视图：123456from django.shortcuts import renderfrom django.http import HttpResponsedef hello(request): return HttpResponse("Hello World") 同时应该配置路由文件，在my_app中创建并配置urls.py。 1234567# Django 2.0 以上推荐此写法，后续写法均为 2.0 写法。from django.urls import path, re_path, includeimport my_app.viewsurlpatterns = [ path('hello/', my_app.views.hello),] 12345678910# Django 1.11 以及之前的写法。from django.conf.urls import url, includeimport my_app.viewsurlpatterns = [ # 写法 1：这里的'hello'是按照字符串进行匹配，如果用户写作helloabcd，也会命中该记录，如果想修正这种错误，可以写作'hello/'。 url('hello', my_app.views.hello), # 写法 2：使用正则表达式，r表示该串为正则表达式，^与$分别标记了正则表达式匹配的开始和结尾，这样，用户写helloabcd就不会命中了。使用正则表达式的好处，例如匹配GET参数等，都会使操作变得很方便。 url(r'^hello/$', my_app.views.hello),] 之后再配置项目路由器：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('my_app/', include('my_app.urls'))] 配置到这里就可以运行项目看效果了。1python manage.py runserver 8080 进入如下地址，出现Hello World就算配置成功了。http://127.0.0.1:8080/my_app/hello/ Django 模型模型（Models）是用于对接数据库的接口，在所有的MVC应用中都是如此。Django的模型的定义如下： 数据类型 整型：IntegerField 定长文本：CharField 不定长文本：TextField 日期：DataField 时间：TimeField 日期时间：DateTimeField 自增ID：AutoField （可以不定义，自动生成） 布尔：BooleanField Null型布尔：NullBooleanField 十进制浮点数：DecimalField （精度更高，例如钱数） 浮点型：FloatField 文件：FileField 图片：ImageField 主要属性 主键：primary_key 长度：max_length 默认值：default 唯一性：unique（不允许重复出现） 索引：db_index 自定义字段名称：db_column 是否允许为空：null 是否允许空白：blank 十进制浮点数： 数字数：max_digits 小数点数：decimal_places 日期（二者只能用一个） 更新时间：auto_now 创建时间：auto_now_add 外键：’其他表’ （赋值时直接写该对象，2.0以上版本还要求on_delete属性） 创建模型1234567891011121314151617181920212223from django.db import modelsclass MyBookModel(models.Model): # 注意：属性名不能出现两个连续的下划线， # title title = models.CharField(max_length=20) # publish_date publish_date = models.DateTimeField(auto_now=True) # author author = models.ForeignKey('AuthorModel', on_delete=models.CASCADE) # Django 1 版本中不要求on_delete def __str__(self): return self.titleclass AuthorModel(models.Model): # name name = models.CharField(max_length=20) # age age = models.IntegerField(default=0) def __str__(self): return self.name 完成后，迁移数据库到sqlite：12python manage.py makemigrationspython manage.py migrate 使用模型简单查询操作 get：返回模型对象；查到多条或是未查到都会抛出异常。 all：返回查询集；返回所有数据 filter：返回查询集；返回满足条件的数据 exclude：返回查询集；返回不满足条件的数据 order_by：返回查询集；对查询结果排序 对于 get，filter，exclude 这三个查询操作，可以填写查询条件，例如：123456789101112131415161718192021222324252627# 精确查询MyBookModel.objects.get(id=1)MyBookModel.objects.get(title__exact="First Book") # 同 title="First Book"# 模糊查询MyBookModel.objects.filter(title__contains="First")MyBookModel.objects.filter(title__startswith="First")MyBookModel.objects.filter(title__endswith="Book")# 空查询MyBookModel.objects.filter(title__isnull=False)# 范围查询MyBookModel.objects.filter(id__in=[1, 3, 5])# 比较查询MyBookModel.objects.filter(id__gt=2)MyBookModel.objects.filter(id__lt=2)MyBookModel.objects.filter(id__gte=2)MyBookModel.objects.filter(id__lte=2)# 日期查询MyBookModel.objects.filter(publish_date__year=1990)MyBookModel.objects.filter(publish_date__month=2)MyBookModel.objects.filter(publish_date__day=2)MyBookModel.objects.filter(publish_date__gt=date(1980,3,2))# 排序MyBookModel.objects.all().order_by('id', 'title') # 升序MyBookModel.objects.all().order_by('-id') # 降序，前面加一个 减号# 查看是否有数据m = MyBookModel.objects.filter(id=1)m.exists() 也就是说，其参数格式为模型属性名__条件名=值。（注意是双下划线） 高级查询操作1234567891011121314151617181920from django.db.models import F, Q# 直接书写，默认为“且”的关系MyBookModel.objects.filter(id__gt=2, title__contains="First")# Q 对象，实现“与或非”的关系MyBookModel.objects.filter(Q(id__gt=2) &amp; Q(title__contains="First")) # 且的关系MyBookModel.objects.filter(Q(id__gt=2) | Q(title__contains="First")) # 或的关系MyBookModel.objects.filter(~Q(id=2)) # id 不为 2# F 对象，实现“属性（字段）”之间的比较MyBookModel.objects.filter(publish_date=F('publish_date')) # 查询出版日期与出版日期相等的对象MyBookModel.objects.filter(publish_date=F('publish_date') / 3) # 查询出版日期与出版日期除以三相等的对象# 聚合函数 sum count avg max minfrom django.db.models import Sum, Count, Avg, Max, MinMyBookModel.objects.all().aggregate(Count('id')) # 返回字典 &#123;'id_count': 2&#125;MyBookModel.objects.aggregate(Count('id')) # 返回字典 &#123;'id_count': 2&#125;，与前者功能一致MyBookModel.objects.filter(id__gt=2).count() # id 大于 2 的记录数目 查询集： 惰性查询：只有需要具体数据的时候才发生查询。 缓存：第一次查询到的查询集数据会缓存下来，第二次再访问这个查询集的时候就会使用缓存的内容。 切片：对一个查询集切片会产生新的查询集，且切片参数不可为负数。 模型关系模型（数据表）关系分为： 一对一 一对多 多对多 关系属性： 多对多：ManyToManyField(‘表名’)，可以任意定义到其中一个模型中。 一对一：OneToOneField(‘表名’)，可以任意定义到其中一个模型中。 多对一：ForeignKey(‘表名’)，定义在多的模型中。 关联查询（一对多）1234567891011# 查询一表一表.objects.filter(多表__属性__条件='...') # 这里的多表要小写AuthorModel.objects.filter(mybookmodel__title__contains='First')# 查询多表多表.objects.filter(外键__属性__条件='...') MyBookModel.objects.filter(author__name__contains='W')# 查询多表查询集x = 一表.objects.get(id=1)查询集y = 查询集.多表_set.all() # 多表也要小写x = AuthorModel.objects.get(id=1)y = x.mybookmodel_set.all() 插入，更新与删除使用举例：1234567891011121314151617181920212223242526from my_app.models import AuthorModel, MyBookModelfrom datetime import date# 创建一条作者记录a = AuthorModel()a.name = "Wang"a.age = 80a.save()# 创建一条作者记录a = AuthorModel.objects.create(name='Li', age=10)# 创建一条书籍记录m = MyBookModel()m.title = "First Book"m.date = date(1999,1,1)m.author = am.save()# 修改m = MyBookModel.objects.get(id=1)m.title = "Second Book"m.save()# 删除m = MyBookModel.objects.get(id=1)m.delete() 自关联自关联是一种特殊的一对多关系，例如“省-&gt;市-&gt;县”的关系。设计这种关系，一种方法是设计三张表，利用外键关联三个表；另外一种方法是将他们设计到一张表中，利用一个字段指向其父级ID，这样就形成了自关联的关系。 123456class AreaModel(models.Model): title = models.CharField(max_length=100) parent = models.ForeignKey('self', null=True, blank=True, on_delete=False) def __str__(self): return self.title on_delete有CASCADE、PROTECT、SET_NULL、SET_DEFAULT、SET()五个可选择的值。 CASCADE：此值设置，是级联删除。PROTECT：此值设置，是会报完整性错误。SET_NULL：此值设置，会把外键设置为null，前提是允许为null。SET_DEFAULT：此值设置，会把设置为外键的默认值。SET()：此值设置，会调用外面的值，可以是一个函数。 管理器 objects就是MyBookModel.objects的objects。自制管理器的优势有： 改变查询结果 添加个性化方法 自制管理器的方式如下：1234567891011121314151617181920212223242526class AuthorModelManager(models.Manager): def all(self): a = super().all() return a.filter(age__gt=10) # 此方法与下面的create任选一个： def create_author(self, name, age): a = self.model() # a = AuthorModel() a.name = name a.age = age a.save() return aclass AuthorModel(models.Model): ... # 管理器 objects = AuthorModelManager() ... @classmethod def create(cls, name, age): a = cls() a.name = name a.age = age a.save() return a 一旦自制了管理器，原来的管理器就自动失效了（就算名字不是objects，原objects也会失效）。 元选项在数据库中，数据表的命名是项目名_模型名，但是一旦项目名发生变化，所有的表的命名都会受到影响。如果消除这种影响，可以在模型类里面定义一个元类： 12345class AuthorModel(models.Model): ... class Meta: # 指定表名 db_table = 'author_table' 在某些版本的SQLite中不支持数据表改名，所以这一步操作要注意。 导入导出数据12python manage.py dumpdata &gt; data.jsonpython manage.py loaddata data.json Django 视图静态视图在my_app下创建templates文件夹，在该文件夹下创建index.html，编辑index.html。12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 编辑视图函数：123456789101112from django.http import HttpResponsefrom django.shortcuts import render# 第一种方式，直接返回纯文本def hello(request): return HttpResponse('Hello')# 第二种方式，返回模板def index(request): return render(request, 'index.html') 修改后记着修改对应的urls：12345678from django.urls import path, includeimport my_app.viewsurlpatterns = [ path('hello', my_app.views.hello), path('index', my_app.views.index)] 动态视图模板系统基本语法：123变量标签：&#123;&#123; 变量 &#125;&#125;for循环标签：&#123;% for x in list %&#125;, &#123;% endfor %&#125;if-else标签：&#123;% if %&#125;, &#123;% else %&#125;, &#123;% endif %&#125; 首先编辑好前端页面，label_list是要输出的标签。这里我们创建books.html文件，编辑如下：123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#123;% for x in label_list %&#125;&lt;h1&gt;&#123;&#123; x.title &#125;&#125;&lt;/h1&gt;&#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 模板渲染：后台给要输出的标签赋值：12345def get_them(request): get_all = MyBookModel.objects.all() return render(request, 'books.html', &#123; 'label_list': get_all &#125;) 修改后，别忘了修改urls.py文件。1234urlpatterns = [ path('index/', my_app.views.index), path('get_books/', my_app.views.get_books),] 如果想自己做一个渲染器，可以这样做：1234567from django.template import loader, RequestContextdef my_render(request, template, args): temp = loader.get_template(template) context = RequestContext(request, args) res_html = temp.render(context) return HttpResponse(res_html) http://127.0.0.1:8080/my_app/index/http://127.0.0.1:8080/my_app/get_books/ 依据ID进行路由跳转首先建立模板one_book.html：123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;&#123;&#123; item.title &#125;&#125;&lt;/h1&gt;&lt;h2&gt;&#123;&#123; item.author &#125;&#125;&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; 在my_app的urls里面修改：1path('get_the_book/&lt;int:bid&gt;', my_app.views.get_the_book) 相应修改views.py：123456def get_the_book(request, bid): bid = int(bid) get_one = MyBookModel.objects.get(id=bid) return render(request, 'one_book.html', &#123; 'item': get_one &#125;) 页面重定向跳转方法：123456789def create(request): a = AuthorModel.objects.get(id=1) m = MyBookModel() m.title = "Second Book" m.author = a m.save() return HttpResponseRedirect('/my_app/index') 自定义 404 等错误页面在项目urls.py中配置：1234import django.conf.urlsdjango.conf.urls.handler404 = 'my_app.views.error404'django.conf.urls.handler500 = 'my_app.views.error500' 同时设计相应的错误页面。要查看效果，就要关闭DEBUG模式才可以。123456def error404(request): return HttpResponse('Error handler content', status=404) # return render(request, 'error404.html', status=404)def error500(request): return HttpResponse('Error handler content', status=500) 管理静态文件通常一些静态文件，如网站logo等资源需要单独存放到一个固定的位置，一般是存放到静态文件目录下。配置静态文件目录过程为： 确保 INSTALLED_APPS 包含了 django.contrib.staticfiles。 在配置文件中，定义 STATIC_URL，例子:STATIC_URL = &#39;/static/&#39; 在模板中，用 static 模板标签基于配置 STATICFILES_STORAGE 位给定的相对路径构建 URL。 12&#123;% load static %&#125;&lt;img src="&#123;% static 'image/example.jpg' %&#125;" alt="My image"&gt; 将你的静态文件保存至程序中名为 static 的目录中。例如 my_app/static/image/example.jpg。 表单表单的提交常见有两种方式：GET与POST。在Request中包含了浏览器的请求信息，Request的属性包括： POST：POST请求参数，查询字典（QueryDict）类型 GET：GET请求参数，查询字典（QueryDict）类型 FILES：上传的文件，类似于字典的对象 COOKIES：客户端的cookies，一个Python字典 path：表示请求路径，不包括域名与参数 method：表示请求方式 encoding：提交数据的编码，默认utf8 session：服务端session 用法如下123456789def set_author(request): args = request.POST # 写法 1：如果没有该参数则返回None name = args.get('name') name = args.get('name', "Anonymous") # 第二个参数表示默认值，即没有参数的时候返回该默认值 name = args.getlist('name') # 返回name参数的多个值，因为允许一个参数含有多个值 # 写法 2：如果没有该参数则抛出异常KeyError name = args['name'] return HttpResponseRedirect('/my_app/index') Ajax 请求123456789from django.http import JsonResponsedef get_author(request): a = AuthorModel.objects.get(id=1) j = &#123; 'name': 'Wang' 'age': 20 &#125; return JsonResponse(j) Cookie 与 SessionCookie：保存在客户端，由服务器生成，客户端访问服务器时会附带Cookies。另外Cookies是会过期的，如果不指定，则有效期为关闭浏览器时。Session：保存在服务端，也是由服务器生成，依赖于Cookie，因为客户标识码SessionID存储在Cookie里面。Session存储位置在数据库中。 Cookie12345678910# 设置 Cookiesresponse = HttpResponse('')response.set_cookie('num', 1, max_age=7*24*3600) # 从现在开始计算过期时间，单位：秒response.set_cookie('num', 1, expires=timedelta(days=7)+datetime.now()) # 从指定时间计算，单位：秒return response# 读取 Cookiesif 'num' in request.COOKIES['num']: num = request.COOKIES['num']else: num = 0 Session123456789101112131415161718# 设置 Sessionrequest.session['num'] = 1return HttpResponse('...')# 读取 Sessionif 'num' in request.session['num']: num = request.session['num']else: num = 0# 或num = request.session.get('num', '0') # 也可以设置默认值# 清除 Session 的值request.session.clear()# 删除 Session 记录request.session.flush()# 删除 某一个键del request.session['key']# 设置会话超时时间，单位：秒。默认两周；为0，则关闭浏览器过期request.session.set_expiry(24*3600) 设计分页我们也可以使用index?page=1的方式传递GET参数，分页也一般采用这种方式查看当前访问的是第几页。通过GET参数获取请求的分页，为了获取GET参数，可以使用如下：12345page = request.GET.get('page') # 字符串，可能没有这个参数if page: page = int(page)else: page = 1 Django自带了分页组件。分页组件及其常用方法如下：1234567891011121314from django.core.paginator improt Paginatorp = Paginator(one_list, 3) # one_list列表, 每页3个记录p.num_pages # 分了几页 p.page_range # 总记录数page = p.page(1) # 获取第一页page.number # 当前页页码page.object_list # 第一页的查询集page.paginator # 对应的分页器page.has_next() # 是否有下一页page.has_previous() # 是否有上一页page.previous_page_number # 前一页页码page.next_page_number # 后一页页码 Django 路由Path 语法Django Path默认支持五个转化器： 12345str：匹配除了路径分隔符（/）之外的非空字符串，这是默认的形式int：匹配正整数，包含0。slug：匹配字母、数字以及横杠、下划线组成的字符串。uuid：匹配格式化的uuid，如 075194d3-6885-417e-a8a8-6c931e272f00。path：匹配任何非空字符串，包含了路径分隔符 具体用法例如： 123456urlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles/&lt;int:year&gt;/', views.year_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/', views.month_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/&lt;slug&gt;/', views.article_detail),] 用户也可以自定义转化器，自定义的转化器需要使用实现转化器接口。实现方法如下：123456789101112131415161718192021222324252627282930# 例 1class IntConverter: # 正则表达式 regex = '[0-9]+' # value是匹配到的字符串，返回Python变量 def to_python(self, value): return int(value) # value是Python变量，返回字符串，用于url反向引用 def to_url(self, value): return str(value)# 例 2class StringConverter: regex = '[^/]+' def to_python(self, value): return value def to_url(self, value): return value# 例 3：匹配4位整数class FourDigitYearConverter: regex = '[0-9]&#123;4&#125;' def to_python(self, value): return int(value) def to_url(self, value): return '%04d' % value 定义完成后，将其注册到配置中。在需要的urls.py中添加：12345678from django.urls import register_converterfrom . import converters # 自制转化器，不嫌乱也可以把自制转化器放到urls.py中。register_converter(converters.FourDigitYearConverter, 'yyyy')urlpatterns = [ path('articles/&lt;yyyy:year&gt;/', views.year_archive),] 如果嫌自制转化器太繁琐，可以使用兼容Django 1中的正则表达式的方式直接匹配。123456urlpatterns = [ path('articles/2003/', views.special_case_2003), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/', views.year_archive), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/', views.month_archive), re_path('articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;slug&gt;[^/]+)/', views.article_detail),] Django 模板模板加载顺序加载一个模板，首先是查找配置的模板目录，如果找不到，再去INSTALLED_APPS下的templates查找。这一过程是Django自动的。 模板变量模板变量，不能以下划线开头。1&#123;&#123; num &#125;&#125; 下面两种情况，有两种解析顺序。1&#123;&#123; author.name &#125;&#125; 其解析顺序为: 作为字典，取键值 作为对象，取属性 作为对象，当作对象的方法 都无法匹配，则替换为空字符串 1&#123;&#123; author_list.0 &#125;&#125; 其解析顺序为: 作为字典，取键值 作为列表，取下标 都无法匹配，则替换为空字符串 模板标签后端给标签变量赋值可以使用render函数。123render(request, 'index.html', &#123; 'author_list': AuthorModel.objects.all()&#125;) 前端的模板标签主要如下1234567891011121314151617181920for循环标签&#123;% for x in author_list %&#125;列表不为空时&#123;&#123; forloop.counter &#125;&#125; 记录循环第几次&#123;% empty %&#125;列表为空时&#123;% endfor %&#125;if标签&#123;% if 条件 %&#125;操作符旁边必须有空格&#123;% elif %&#125;&#123;% else %&#125;&#123;% endif %&#125;注释&#123;# 单行注释 #&#125;&#123;% comment %&#125;多行注释&#123;% endcomment %&#125; 模板过滤器过滤器是用在前端的标签函数，用于对模板变量做操作。12345678910过滤器格式为&#123;&#123; 变量|过滤器:参数 &#125;&#125;改变日期的显示格式&#123;&#123; book.publish_date|date:"Y年-m月-d日" &#125;&#125;求长度&#123;&#123; book.title|length &#125;&#125;设置默认值&#123;&#123; book.title|default:"No Title" &#125;&#125;自定义过滤器（是否是奇数）&#123;&#123; author.age|mod:1 &#125;&#125; 自定义过滤器的定义应在my_app目录下的templatetags下。templatetags应该有一个__init__.py文件，保证该目录可以被Python识别。 这里创建一个filters.py文件用于开发自定义过滤器。自定义标签也可以写到这里。filters.py123456789101112131415from django import templateregister = template.Library()# value：被判断的变量；arg：传入的参数def mod(value, arg): return value % arg# 完成后，注册过滤器register.filter('mod', mod)# 另外，只有一个参数的过滤器如下，外加另外一种注册方式@register.filter(name='lower')def lower(value): # Only one argument. return value.lower() 在需要使用的模板上加载过滤器。1&#123;% load filters %&#125; 模板继承网页往往会有很多重复的内容，因此我们可以制作一个父页面，子页面继承主页面显示以减少重复代码。 父页面base.html12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;&#123;% block topics %&#125;默认显示内容&#123;% endblock topics %&#125;&lt;/body&gt;&lt;/html&gt; 子页面sub_page.html123456789&#123;% extends 'base.html' %&#125;&#123;% block topics %&#125;新内容获取父模板的内容&#123;&#123; block.super &#125;&#125;&#123;% endblock topics %&#125; 模板转义默认情况下，模板上下文（由后端传递过来）中的html标记会被转义显示，即模板中的&lt;&gt;会被转化为&amp;lt;&amp;gt。因此要关闭转义显示，可以使用标签1234567方式 1&#123;&#123; 变量|safe &#125;&#125;方式 2&#123;% autoescape off %&#125;模板语言代码&#123;% endautoescape %&#125; Django 用户登录登录装饰器有些页面是用户登录之后才可以访问的，例如修改密码，修改昵称等，也就是这些页面首先要进行用户登录的判断，否则让用户跳转回登录页面。 我们可以通过函数装饰器的方式：12345678910111213141516# 定义一个闭包函数def login_required(view_func): def wrapper(request, *view_args, **view_kwargs) # 判断用户是否登录 if true: return view_func(request, *view_args, **view_kwargs) else: return redirect('/login') pass return wrapper# 使用函数装饰器，使用该函数会先调用login_required，相当于# login_required(change_pwd)(request, *view_args, **view_kwargs)@login_requireddef change_pwd(request): return HttpResponse('Change Password') CSRF 攻击CSRF 攻击即跨站请求伪造攻击。我们在访问某一网站时，例如银行网站，在访问的结束后再去访问其他的网站，就会致使我们所有保存在浏览器上的数据包都会暴露给第三方网站，如果第三方网站上有某些攻击脚本，例如在用户不知情的情况下，再次利用刚才的数据包（SessionID）访问银行网站进行一些危险的操作，我们的数据就会产生泄露甚至丢失的危险。 由于伪造的网站与真实的网站的IP或主机名是不一样的，所以根据这一特性，我们可以也防止这种跨站请求伪造攻击。 Django 默认是启用这种 CSRF 攻击保护的（只针对POST），但同时也带来了不便，因为我们有时自己的网站也会被防护，导致自己的网站都无法正常浏览。 解决这一问题，可以在模板中的表单里添加如下内容即可。1&#123;% csrf_token %&#125; 内置表单Django中内置了表单。用户可以通过Django内置的表单生成器自动生成表单。 1234567891011121314151617181920212223from django import formsclass LoginForm(forms.Form): username = forms.TextField() password = forms.TextField(widget=forms.PasswordInput)def login_handler(request): if request.method == "POST": login_form = LoginForm(request.POST) if login_form.is_valid(): user = login_form.cleaned_data['username'] pswd = login_form.cleaned_data['password'] if user: # 验证用户名，密码 return HttpResponse('成功登录') else: return HttpResponse('登录失败') else: return HttpResponse("输入不合法")def login(request): login_form = LoginForm() return render(request,'login.html', &#123;"forms":login_form&#125;) 12345&lt;form action="." method="post"&gt; &#123;% csrf_token %&#125; &#123;&#123; forms &#125;&#125; &lt;input type="submit" value="Login"&gt;&lt;/form&gt; 验证码django-simple-captcha 官方文档首先按照验证码库： 1pip install django-simple-captcha 在项目settings.py中配置：123456789101112131415161718192021INSTALLED_APPS = [ ... "captcha",]# Captcha 二者选其一# 字母验证码CAPTCHA_IMAGE_SIZE = (80, 45) # 设置 captcha 图片大小CAPTCHA_LENGTH = 4 # 字符个数CAPTCHA_TIMEOUT = 1 # 超时(minutes) # 加减乘除验证码CAPTCHA_OUTPUT_FORMAT = '%(image)s %(text_field)s %(hidden_field)s 'CAPTCHA_NOISE_FUNCTIONS = ('captcha.helpers.noise_null', 'captcha.helpers.noise_arcs', # 线 'captcha.helpers.noise_dots', # 点)CAPTCHA_CHALLENGE_FUNCT = 'captcha.helpers.random_char_challenge'CAPTCHA_CHALLENGE_FUNCT = 'captcha.helpers.math_challenge'CAPTCHA_TIMEOUT = 1 在项目urls.py中配置：1path('captcha/', include('captcha.urls')) 完成后迁移数据库12python manage.py makemigrationpython manage.py migrate 创建登录表单，验证码在登录时由表单自动完成验证。123456789101112131415161718192021222324from django import formsfrom captcha.fields import CaptchaFieldclass LoginForm(forms.Form): username = forms.TextField() password = forms.TextField(widget=forms.PasswordInput) captcha = CaptchaField()def login_handler(request): if request.method == "POST": login_form = LoginForm(request.POST) if login_form.is_valid(): user = login_form.username if user: '''用户登陆后，Django会自动调用默认的session应用，将用户的id存至session中''' return HttpResponse('成功登录') else: return HttpResponse('登录失败') else: return HttpResponse("输入不合法")def login(request): login_form = LoginForm() return render(request,'login.html', &#123;"forms":login_form&#125;) 如果想要点击验证码实现验证码更新，则可以使用如下操作（需要jQuery）。 123456789101112131415from captcha.helpers import captcha_image_urlfrom captcha.models import CaptchaStoreimport jsondef captcha_refresh(request): """ Return json with new captcha for ajax refresh request """ if not request.is_ajax(): # 只接受ajax提交 raise Http404 new_key = CaptchaStore.generate_key() to_json_response = &#123; 'key': new_key, 'image_url': captcha_image_url(new_key), &#125; return HttpResponse(json.dumps(to_json_response), content_type='application/json') 123456789101112131415161718192021222324252627282930&lt;script&gt; $(function()&#123; # 改变鼠标箭头 $('.captcha').css(&#123; 'cursor': 'pointer' &#125;) # ajax 刷新 $('.captcha').click(function()&#123; console.log('click'); $.getJSON("/captcha/refresh/", function(result)&#123; $('.captcha').attr('src', result['image_url']); $('#id_captcha_0').val(result['key']) &#125;);&#125;); # ajax动态验证 $('#id_captcha_1').blur(function()&#123; // #id_captcha_1为输入框的id，当该输入框失去焦点是触发函数 json_data=&#123; 'response':$('#id_captcha_1').val(), // 获取输入框和隐藏字段id_captcha_0的数值 'hashkey':$('#id_captcha_0').val() &#125; $.getJSON('/ajax_val', json_data, function(data)&#123; //ajax发送 $('#captcha_status').remove() if(data['status'])&#123; //status返回1为验证码正确， status返回0为验证码错误， 在输入框的后面写入提示信息 $('#id_captcha_1').after('&lt;span id="captcha_status" &gt;*验证码正确&lt;/span&gt;') &#125;else&#123; $('#id_captcha_1').after('&lt;span id="captcha_status" &gt;*验证码错误&lt;/span&gt;') &#125; &#125;); &#125;); &#125;)&lt;/script&gt; 当然，高级玩家可以自己画验证码。下面自制验证码： 安装Pillow包1pip install Pillow 定义一个验证码生成函数12345678910111213141516171819202122232425262728293031323334353637383940414243from PIL import Image, ImageDraw, ImageFontfrom django.utils.six import BytesIOdef verify_code(request): import random # 背景色，宽，高 bgcolor = (random.randrange(20, 100), random.randrange(20, 100), 255) width = 100 height = 25 # 创建画面 img = Image.new('RGB', (width, height), bgcolor) draw = ImageDraw.Draw(img) # 绘制噪点 for i in range(0, 100): xy = (random.randrange(0, width), random.randrange(0, height)) fill = (random.randrange(0, 255), 255, random.randrange(0, 255)) draw.point(xy, fill=fill) # 准备字符串 str_back = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890' rand_str = '' for i in range(0, 4): rand_str += str_back[random.randrange(0, len(str_back))] # 绘制字符串 font = ImageFont.truetype('FreeMono.ttf', 23) fontcolor = (255, random.randrange(0, 255), random.randrange(0,255)) for i in range(0, 4): draw.text((5 + 24*i, 2), rand_str[i], font=font, fill=fontcolor) # 释放画笔 del draw # 存储验证码到后端 request.session['verify_code'] = rand_str # 保存到内存文件 buf = BytesIO() im.save(buf, 'png') # 返回验证码 return HttpResponse(buf.getvalue(), 'image/png') URL 反向解析在模板里面，可以将链接到其他页面的超链接写成动态的，这样可以保证修改链接后自动修改所有链接到某页的路径。 在项目urls.py中，添加namespace属性：1234url_patterns = [ ... path('my_app/', include('my_app.urls', namespace='my_app'))] 在应用urls.py配置中，添加name属性：1234url_patterns = [ ... path('index_renamed/', views.index, name='index')] 在模板中：12345用法：url 'namespace:name' 参数&lt;a href="&#123;% url 'my_app:index' %&#125;"&gt;首页&lt;/a&gt;&lt;a href="&#123;% url 'my_app:index' arg1 arg2 %&#125;"&gt;带位置参数的首页&lt;/a&gt;&lt;a href="&#123;% url 'my_app:index' a=arg1 b=arg2 %&#125;"&gt;带关键字参数的首页&lt;/a&gt; 在视图中使用反向解析：1234567from django.core.urlresolvers import reversedef test_redirect(request): # 'namespace:name' url = reverse('my_app:index', args=('arg1', 'arg2')) url = reverse('my_app:index', kwargs=&#123;'a'='arg1', 'b'='arg2'&#125;) return redirect(url) 中间件是Django预留的函数接口，允许我们干预请求和应答。例如对客户端进行过滤，防止DDoS攻击等。 中间件可以允许我们在执行视图函数之前自动执行中间件。中间件的执行流程如下：1234567891011st=&gt;start: 请求到达服务器op1=&gt;operation: 产生Request对象op2=&gt;operation: 调用process_requestop3=&gt;operation: 匹配URLop4=&gt;operation: 调用process_viewop5=&gt;operation: 调用视图函数op6=&gt;operation: 调用process_responseop6=&gt;operation: 返回给浏览器e=&gt;endst-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;op5-&gt;op6-&gt;e 在setting.py中注册中间件，注册顺序与执行顺序相反。1234MIDDLEWARE = [ ... 'my_app.middleware.Block_Middleware'] 在my_app目录下建立middleware.py文件，编辑此文件：12345678910111213141516171819202122# 中间件类class Block_Middleware(object): # 匹配url之后，在进入视图函数之前调用 def process_view(self, request, view_func, *view_args, **view_kwargs): # 获取浏览器端的IP地址： user_ip = request.META('REMOTE_ADDR') if user_ip in ['127.0.0.1']: return HttpRequest('Go Back') # 服务器启动后接受第一个请求的时候调用 def __init__(self): pass # 产生request之后，匹配url路由之前调用 def process_request(self, request): pass # 调用视图函数之后，返回浏览器之前调用 # view_func 为将要调用的视图函数 def process_response(self, request, response): return response # 视图函数异常时候调用 def process_exception(self, request, exception): pass 注意：如果在中间件的任意一个函数返回response，后续的过程将不会执行，而是直接将结果交给process_response，再返回浏览器。 Django Shell就是带Django相关功能的Python Shell。可以方便开发者调试代码。例如，使用Django Shell添加一条数据库的记录。首先进入Shell1python manage.py shell 进入后，可以执行如下常用操作：12345from my_app.models import AuthorModel, MyBookModelfrom datetime import date# 获取作者A的所有书 的 第0本，注意要所有字母小写print(a.mybookmodel_set.all()[0]) Django Admin 模块Django标配的后台管理工具，使用方便，可以快速编辑很多内容。 首先创建用户：1python manage.py createsuperuser 填写用户名与密码，这里可能要求密码长度大于8位且不能为纯数字。 之后运行查看效果：1python manage.py runserver 8080 http://127.0.0.1:8080/admin/ 进入后台后，可以看到管理页面中出现 Groups 与 Users，编辑这两项添加用户与用户组。如果想将my_app的模型MyModel也加入其中，可以到my_app下的admin.py中编辑： 123from my_app.models import MyBookModel, AuthorModeladmin.site.register(MyBookModel)admin.site.register(AuthorModel) 也可以使用自定义管理页面：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class MyBookModelAdmin(admin.ModelAdmin): # 浏览页 # 显示的字段，方法 list_display = ['id', 'title', 'title_func'] # 如果想让传过来的方法也可以排序，要做模型里面添加 # title_func.admin_order_field = 'title' # 如果想改变显示内容 # title_func.short_description = 'T' # 如果想改变字段的显示内容 # title = models.CharField(verbose_name='T', max_length=20) # 每一页显示多少条 list_per_page = 10 # 动作 actions_on_bottom = True actions_on_top = False # 过滤栏 list_filter = [ 'title' # 列表页右侧的过滤栏 ] # 搜索框 search_fields = [ 'title' # 列表页上方的搜索框 ] # 编辑页 # 字段显示顺序 fields = [ 'title', 'id' ] # 分组显示 fieldsets = [ ('Base', &#123;'fields': ['title', 'id']&#125;), ('Advance', &#123;'fields': []&#125;) ] # 关联对象 inlines = [ AreaStackedInline, AreaTabularInline ]# 块状class AreaStackedInline(admin.StackedInline): # 写多类的名字 model = AreaInfo extra = 2 # 额外新建编辑2个子对象# 表状class AreaTabularInline(admin.TabularInline): # 写多类的名字 model = AreaInfo extra = 2 # 额外新建编辑2个子对象admin.site.register(MyBookModel, MyBookModelAdmin)admin.site.register(AuthorModel) 如果要重写模板，可以在templates下建立base_site.html文件：1234567891011121314151617181920&#123;% extends "admin/base.html" %&#125;&#123;# 标题 #&#125;&#123;% block title %&#125;&#123;&#123; title &#125;&#125; | &#123;&#123; site_title|default:_('Django site admin') &#125;&#125;&#123;% endblock %&#125;&#123;# 展框 #&#125;&#123;% block branding %&#125;&lt;h1 id="site-name"&gt; &lt;a href="&#123;% url 'admin:index' %&#125;"&gt; &#123;&#123; site_header|default:_('Django administrator') &#125;&#125; &lt;/a&gt;&lt;/h1&gt;&#123;% endblock %&#125;&#123;# 导航栏 #&#125;&#123;% block nav-global %&#125;&#123;% endblock %&#125; Django 上传配置settings.py文件：12MEDIA_URL = '/static/media'MEDIA_ROOT = os.path.join(BASE_DIR, 'my_app/static/media') 模板上，上传图片的表单配置如下：12345&lt;form method="post" action="/my_app/upload_action" enctype="multipart/form-data"&gt; &#123;% csrf_token %&#125; &lt;input type="file" name="pic"/&gt;&lt;br/&gt; &lt;input type="submit" value="upload file"/&gt;&lt;/form&gt; 视图中，获取文件并保存：12345678910111213141516def upload_handle(request): # 如果是小文件（&lt;2.5MB），则文件存储在内存中；如果是大文件（&gt;2.5MB），则文件存储在临时文件中。 image = request.FILES['pic'] # image.name：文件名 # image.chunks()：返回一个列表，里面存储文件的每一个区块 # image.size：文件大小 # image.content_type：文件类型，但是不确定 # 创建一个文件 save_path = '%s/my_book_model/%s'%(settings.MEDIA_ROOT, image.name) with open(save_path, 'wb') as f: for chk in image.chunks(): f.write(chk) # 将路径保存至数据库中 m = MyBookModel.objects.get(id=1) m.picture = 'my_book_model/%s'%image.name m.save() 开发流程总结需求分析网站设计数据库设计URL设计 URL 视图 模板文件 /login login login.html 创建项目模型编辑视图编辑路由配置其他虚环境虚环境的安装12sudo pip install virtualenv # 虚环境sudo pip install virtualenvwrapper # 虚环境扩展 虚环境的常用命令1234mkvirtualenv -p python3 name # 创建虚环境deactivate # 退出虚环境workon name # 进入虚环境rmvirtualenv name # 删除虚环境 查看虚环境下已安装的包12pip list # 列出所有的包pip freeze &gt; requirements.txt # 输出安装的包（到文件） MySQL基本操作开启日志文件，需要修改mysql.conf文件。12# 实时查看日志文件tail -f mysql.log]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode 开发调试C++ 程序]]></title>
    <url>%2F2020%2F01%2F25%2FVSCodeCPPInit%2F</url>
    <content type="text"><![CDATA[配置编译环境 MinGW-64点击进入MinGW-64下载页面，下载完毕后，解压到一个固定的目录下，并将该目录的../bin目录添加至环境变量中。 打开CMD（或Power Shell）输入gcc测试环境是否配置成功。如果成功，则显示： 12gcc: fatal error: no input filescompilation terminated. 下载 Visual Studio Code点击下载Visual Studio Code，下载完毕后安装打开。进入程序后，在插件栏中安装Code Run，C/C++两款插件。安装完毕后重启编辑器。 Tips: 可以安装一个Chinese插件可以进行汉化。 创建第一个项目打开一个空文件夹，在其下面创建.vscode文件夹（注意有个点），依次点击菜单栏的调试-&gt;添加配置选项，添加一个C++(GDB/LLDB)配置，第二步选择g++.exe build and debug active file，之后会启动调试，并显示调试失败。这里点击取消，编辑器将自动创建launch.json文件和tasks.json文件，这个文件中可以配置启动程序和调试程序所需的相关内容。这两个文件默认情况下是不需要修改的。如果调试失败，可以参考如下两个配置文件进行修改。文件内容如下： launch.json1234567891011121314151617181920212223242526&#123; "version": "0.2.0", "configurations": [ &#123; "name": "(gdb) Launch", // 配置名称 "type": "cppdbg", // 这里只能为cppdbg "request": "launch", // 请求配置类型，可以为launch（启动）或attach（附加） "program": "$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe",// 将要进行调试的程序的路径 "args": [], // 程序调试时传递给程序的命令行参数，一般设为空即可 "stopAtEntry": false, // 设为true时程序将暂停在程序入口处，一般设置为false "cwd": "$&#123;workspaceFolder&#125;", // 调试程序时的工作目录，一般为$&#123;workspaceFolder&#125;即代码所在目录 "environment": [], "externalConsole": true, // 调试时是否显示控制台窗口，一般设置为true显示控制台 "MIMode": "gdb", "miDebuggerPath": "gdb.exe", // miDebugger的路径，注意这里要与MinGw的路径对应 "preLaunchTask": "g++", // 调试会话开始前执行的任务，一般为编译程序，c++为g++, c为gcc "setupCommands": [ &#123; "description": "Enable pretty-printing for gdb", "text": "-enable-pretty-printing", "ignoreFailures": true &#125; ] &#125; ] &#125; tasks.json12345678910111213141516171819202122232425&#123; // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format "version": "2.0.0", "tasks": [ &#123; "type": "shell", "label": "g++", "command": "g++.exe", "args": [ "-g", "$&#123;file&#125;", "-o", "$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe" ], "options": &#123; "cwd": "" &#125;, "problemMatcher": [ "$gcc" ] &#125; ]&#125; 配置完成后，添加一个简单的CPP文件，分别调试、直接运行一次测试功能是否正确。如果发现不能调试程序，可尝试重启编辑器。 main.cpp1234567#include &lt;iostream&gt;int main(void)&#123; std::cout&lt;&lt;"Hello World..."&lt;&lt;std::endl; return 0;&#125;]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git的使用方法]]></title>
    <url>%2F2020%2F01%2F17%2FGitUse%2F</url>
    <content type="text"><![CDATA[Git 的介绍与安装Git具有版本控制与合作开发的特点。它是一个分布式的版本控制系统，代码不仅在服务器上保存代码的完整版，还在各个客户端保存完整代码的副本。这个服务器可以是Github，也可以是自己搭建的代码管理系统，如Gitlab，码云等。 点击进入Git下载页面。 GIT的基本结构 工作区工作区就是当前的Git目录。 版本库版本库就是该目录下的.git目录。 暂存区暂存区就是用户执行add操作后，临时修改被放置的位置。暂存区的文件经过commit命令可以被提交到分支中（创建一个版本）。 GIT本地仓库的基本操作本节将介绍：Git仓库的初始化，版本切换，版本日志的查看，工作区修改情况查看，撤销等命令，命令如下：12345678910git init resp_name # 代码仓库初始化git add . # 添加所有改动到暂存区git commit -m "..." # 提交暂存区内容，形成版本git log # 打印当前版本库git reflog # 打印操作记录git reset --hard HEAD^ # 切换到上上个版本git checkout -- file_name # 将暂存区的文件恢复到工作区（丢弃工作区的改动）git reset HEAD file_name # 将版本库中的文件恢复到暂存区git diff HEAD -- file_name # 对比工作区文件与版本库文件的区别git diff HEAD HEAD^ -- file_name # 对比两个版本的某文件的区别 本地仓库的创建与提交新建一个目录，之后我们要在这里开发一个项目（编写代码）。首先使用Git Bash在该目录下执行，初始化一个Git仓库： 1git init 或1git init repository_name 完毕后，Git将创建一个版本控制系统在该目录下。之后我们创建一个文件，简单的编写一些内容，用于验证后面的版本控制的功能。例如，我们创建一个code.txt文件。内容如下： code.txt1Hello 保存退出，在Git Bash中执行以下命令，添加修改到工作区，并提交修改： 12git add . git commit -m '新增并初始化了code.txt文件' 这里的.表示该目录下的所有文件，也可以写某一个文件，还可以使用*.txt等格式书写；add操作表示将相应文件加入到版本控制系统中；commit命令表示提交修改，-m的参数表示相应的备注。 版本的切换输入如下命令，可以查看当前所有的代码版本。 1git log 或使log以简短形式呈现 12git log --pretty=onelinegit log --graph --pretty=oneline # 含有图形展示 下面我们创建第二个版本。修改刚刚的code.txt文件，内容如下 code.txt12HelloWorld 再次执行 12git add . git commit -m '修改了code.txt文件内容' 则我们添加了一个新的版本到我们的版本库中。执行git log即可查看到两个版本。 图中的commit 后的 1f96fe… 与 2f88a26… 则是对应的两个版本的版本代号。 那么如何回退到某一个版本？Git的版本是后一个版本依赖于前一个版本的，也就是后面的版本只记录修改的部分。所有的版本组成了一个链表，而HEAD指针永远指向的最新的版本。如果想找到上一个版本，可以使用HEAD^或HEAD~1；上两个版本，可以使用HEAD^^或HEAD~2。 Tips：HEAD实际上会指向master，而master才指向最新的版本。关于分支的部分可以到下一节查看。这里可以暂时理解为HEAD指向最新的版本。 回退到上一个版本，可以使用命令 1git reset --hard HEAD^ 打开文件code.txt可以看到，文件内容已经恢复到最初的版本了。如果又想切换到最新的版本，则可以使用命令 1git reset --hard 版本编号 版本编号可以使用git reflog命令，通过查看操作记录寻找版本编号。 恢复工作区的文件当工作区被编辑后，如果不知道已经做过哪些修改了，可以通过下面的命令查看当前工作区被修改的情况。 1git status 如果想撤销工作区中某一个文件的修改，可以使用如下命令 1git checkout -- 文件名 如果想撤销暂存区中某一个文件的修改，可以使用如下命令，使修改回归暂存区。回归暂存区后，再使用checkout命令使其回到工作区。 1git reset HEAD 文件名 如何对比文件与文件的不同？ 对比工作区与版本库中的文件的不同：使用diff命令，需要给出被对比的版本和文件名。1git diff HEAD -- 文件名 会输出其中的---表示版本库中的文件，+++表示工作区中的文件。下方的红色部分表示工作区中的文件相对于版本库删掉的部分，绿色的是添加的部分。 对比版本库中两个版本的文件的不同：使用diff命令，并给出被对比的两个版本和文件名。1git diff HEAD HEAD^ -- 文件名 这里输出的时候，---表示版本库中的HEAD版本，+++表示HEAD^版本。如果命令写成git diff HEAD^ HEAD，则---与+++所表示的内容也相反。 其他命令如果想删除某一个文件，并将这一改动添加到暂存区，可以使用git add命令，表示添加改动到暂存区；也可以使用git rm命令，表示添加删除操作到暂存区。示例如下： 1git rm 文件名 Git 的分支管理在Git中，所谓分支就是一个指针。例如master分支，就是一个master指针指向了该版本链表的某一个节点。如果是其他分支，例如dev分支，则是在这个链表上添加一个叫dev的指针，指向某一个版本节点。最终再由HEAD指针指向当前编辑的分支指针，也就是HEAD指向了当前编辑的分支。 分支的合并，就是将master指针指向dev所指节点，即图中第四个节点。这样就将dev分支合并到master分支当中了。 分支的删除，就是直接删除dev指针，这样就删掉了该分支。 分支的基本操作如下：123456789git branch # 查看所有分支git branch dev # 创建dev分支git branch -d dev # 删除dev分支git checkout master # 切换到master分支git checkout -b dev # 创建并切换到dev分支git merge dev # 合并dev分支到当前分支git stash # 临时存储工作区git stash list # 列出所有的工作区git stash pop # 恢复顶层的工作区 分支的查看，创建与切换使用下述命令，可以查看当前的所有分支。1git branch 如果要创建某一分支，可以使用这个命令（dev为分支名称）。1git branch dev 进行分支切换，可以直接使用如下命令。 1git checkout master 或创建并切换分支，可以一步到位，使用这个命令。1git checkout -b dev 切换的过程，就是由HEAD指向master指针变为了HEAD指向dev指针。新建的分支保留了原有分支的所有版本，也就是版本链表前边的部分，dev与master是共同享有的。这时，我们不论是add与commit操作，还是log操作，均是在dev分支上进行的。 分支的合并与分支管理当要进行分支合并，使用如下命令，但是分支合并，必须要在被合并的分支上进行，例如要将dev分支合并到master上，需要先切换到master分支上再执行合并操作。 1git merge dev 合并分为三种情况：有冲突的合并；没有冲突的快速合并；没有冲突的普通合并。 快速合并：只修改新的分支，原有分支不动。例如master指针可以直接指向dev指针的位置上，无需产生新的版本，也不会留下分支创建的记录。 没有冲突的普通合并（recursive合并）：两个分支上都有新版本产生，但是没有修改同一个文件。这种情况会在合并后产生一个新的版本。在执行合并操作后会提示提交新版本需要填写的信息。 有冲突的合并：两个分支上都有新版本产生，且修改了同一个文件。这会在合并后先产生合并失败，需要待手动修改冲突后再手动提交新的版本。 对于有冲突的合并，合并失败后，有冲突的文件会产生类似于如下内容的部分。通过手动修改这部分的内容，可以解决合并冲突。修改后，再次执行add与commit操作即可完成合并。 12345&lt;&lt;&lt;&lt;&lt;&lt; HEAD # 删除多余部分，保留需要的部分原分支的更改（被合并的分支）========新传入的更改&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev 有时为了保留分支的创建与合并的记录，我们会在合并时候禁用快速合并模式。执行方式如下：1git merge --no-ff -m "提交信息" dev 合并后，就可以删除dev分支了。这里使用如下命令删除dev分支。 1git branch -d dev Bug 分支与 stash 功能当我们遇到紧急Bug需要修复时，但又不能将当前的工作区提交到版本控制系统中，就可以使用stash功能。 1git stash stash功能可以将我们的工作区临时存储起来，存储完成后，工作区恢复到最近版本，就可以先去完成修复Bug的工作了。 修复bug时，首先创建bug分支，其次完成bug修复工作，完成后将bug分支合并到master分支即可。 待完成修复Bug的工作后，再去将我们原来的工作区恢复，继续进行工作。使用如下命令可以看到我们保存的所有的工作现场。 1git stash list 使用如下命令可以恢复工作现场。 1git stash pop Github 的使用之前的操作都是在本地计算机上所做的。但是我们合作开发的时候，往往需要借用Github之类的代码托管系统。Github的使用，与我们在本地使用Git类似，只是多了拉取与推送等操作。 创建代码仓库首先需要有一个Github账号，登录后点击New repository，输入仓库名称，配置相应设置后，点击Create repository即可。 .gitignore文件：保存了不需要同步的文件列表。 添加SSH如果是初次使用Github，需要配置SSH。 点击用户头像-&gt;settings-&gt;ssh and gpg keys-&gt;new ssh key，在这里添加SSH标题与电脑的SSH公钥。 电脑的SSH公钥生成方式：12cd ~/.ssh/ # 如果提示`No such file or directory`，可以手动的创建一个.ssh文件夹ssh-keygen -t rsa -C "your_email@youremail.com" 之后按提示输入两遍密码，这个密码可以自己设置一个。也可以什么都不写，直接两次回车键。 用记事本打开.ssh目录下的id_rsa.pub文件，复制里面的内容，到github添加即可。这个公钥也可以移动到其他电脑上使用，用于用户在push时登录Github账号使用，这里建议每台计算机一个公钥。 使用这个命令可以测试SSH是否配置正确。1ssh -T git@github.com 使用这两个命令填写用户的用户名和用户邮箱，这里主要是为了在commit时显示是谁提交的代码。这个配置会被保存到用户目录/.gitconfig文件中。12git config --global user.name "account" git config --global user.email "your_email@youremail.com" 后面的Push操作中，还会需要输入一次Github账号密码，这个账号密码与上面的邮箱和账号并不冲突，这个信息只会显示在commit记录上，而Push时输入的账号密码则是用来保证用户访问Github使用的。如果要修改本机上用于Push代码的Github账号密码，可到控制面板-&gt;用户账户-&gt;管理Windows凭据-&gt;普通凭据-&gt;git:https://user_name@github.com下修改。 Clone 代码我们先找到放置项目的目录，使用clone命令将项目克隆到本地。1git clone git@github.com:user_name/repo_name 或1git clone https://github.com/user_name/repo_name 如果在克隆的过程中出现错误，可以使用如下命令修复。 12eval "$(ssh-agent -s)"ssh-add Push 代码当代码克隆下来后，首先创建一个自己的分支进行开发。开发完成后，再提交到本地代码库。 12git add .git commit -m "..." 积累到一定的开发量，如果要推送到远程服务器，则使用如下命令进行远程推送。 1git push origin dev 其中origin是远程分支（这个名字固定），dev为本地的分支（这个名字随便起）。执行完毕后，远程仓库将创建dev分支。 首次Push时，可能会提示填写Github账号与密码。 如果本地仓库和远程仓库都有代码，且不是一套代码，这里可以使用强推操作。这样的强制操作应该尽量慎重使用。 1git push -f 也可以先将远程仓库代码与本地代码合并再推送。12git fetchgit merge 跟踪远程分支将本地分支跟踪服务器分支。跟踪后，Git将智能提示用户当前分支与服务器分支的进度差别。1git branch --set-upstream-to=origin/远程分支名称 本地分支名称 跟踪后，可以直接使用如下代码推送代码。1git push 拉去远程分支1git pull origin 远程分支名 拉去后，分支会默认进行跟踪。 管理远程分支 Remote 命令查看远程已存在的分支：1git remote 添加远程仓库，将远程仓库绑定到origin上：1git remote add origin 远程仓库 查看远程仓库：1git remote -v 可以删除远程主机：1git remote rm 主机名 可以修改主机名：1git remote rename 原主机名 新主机名 工作中使用Git 项目经理搭建项目框架，并放入代码管理工具。 普通员工在自己电脑上生成SSH公钥，交给项目经理。项目经理将SSH公钥上传至服务器。 项目经理给组员分发代码的克隆地址。组员将代码克隆到自己的电脑上。 普通员工创建自己的分支，在分支中进行每天的开发。 注意Master分支要保持发布的代码，Dev分支用于保存开发中的代码。 组员要把自己的Dev分支发布到远程Dev分支当中，但是发布之前需要确认代码可用，需要经过经理确认。 VS Code GIT在VS Code中可以看到如下图标，这个图标就是VS Code的Git可视化管理工具。 点击该按钮（源代码管理），点击+，选择当前文件夹，初始化Git本地仓库。这时，Git本地仓库就建立好了。 修改文件夹中的文件，再切换到源代码管理中，将鼠标移动到被修改的文件，可以看到右侧出现了+，点击+可以将操作暂存到暂存区。如果想取消暂存，可以再点-即可。如果选中了某个文件，可以在右侧预览该文件与工作区文件的区别。 最上方有一个√，这个是提交按钮，点击√后即可提交该版本到版本控制中。 如果想回退到某版本，还是需要借助命令行来实现。这里可以使用插件Git History查看某个版本，复制其ID，方便在命令行操作。 如果想添加远程仓库，也需要借助命令行。可以先执行初始化本地仓库操作，在本地版本库还是空的时候去pull远程代码。也可以跳过初始化操作，直接克隆远程代码。如果在本地版本库不是空的时候直接去pull代码，会出现下面的错误。 1fatal: refusing to merge unrelated histories 这时可以使用下面的命令强行拉取，这样Git就会不论之前的版本库是否一致，都会去拉去远程分支。 1git pull https://github.com/用户名/仓库名.git master --allow-unrelated-histories Visual Studio 2017（待更新）PyCharm GIT（待更新）创建本地Git仓库。VCS-&gt;VCS Operation Popup-&gt;Create Git Repositry 再次点击VCS，会与之前有所区别。左侧的文件菜单，文件名也会有颜色的变换。 右键左侧某文件或文件夹-&gt;Git-&gt;Add，将选中文件添加到版本控制中；或者在提交的时候，可以在上方的文件管理器中勾选。 查看版本历史VCS-&gt;Browse VCS Repository-&gt;Show Git Repository Log 如果想回退到某一个版本，可以右键一个版本，选择Checkout Revision。 如果想切换分支VCS-&gt;Git-&gt;Branches 使用远程仓库添加远程仓库：VCS-&gt;Checkout from Version Control 填写远程仓库地址与本地目录：https://github.com/用户名/仓库名.git 会有提示：Would you like to open ...这样就可以打开下载的代码了。 右键左侧某文件或文件夹-&gt;Git-&gt;Repository-&gt;Push推送代码到远程仓库。 PyCharm 其他技巧VCS-&gt;Git-&gt;Annotate 可以看到每一行代码的作者和日期。 自带版本控制，可以查看本地代码版本。在这里可以直接切换代码版本。VCS-&gt;Local History 参考视频 Git 版本管理链接：https://pan.baidu.com/s/1ua94DTk1MkUBlILNDN7LHQ提取码：m4un]]></content>
      <categories>
        <category>开发技巧与开发工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发信息汇总]]></title>
    <url>%2F2020%2F01%2F14%2FWebInfoA%2F</url>
    <content type="text"><![CDATA[设计模式MVC 架构MVC 架构是Web前端，Web后端的常用架构，也是一些桌面端应用程序，手机程序的常用架构。 Model：模型，是网站访问数据库的接口。View：视图，用户能够看到的页面。Controller：控制器，用于操作数据库，处理用户业务，控制用户行为的程序。 三者的划分即是从功能的角度划分，也是从数据的处理流程的划分。一般流程为：用户发出请求-&gt;控制器处理请求-&gt;模型获取数据-&gt;视图渲染界面-&gt;用户得到反馈 ORM 框架Object：对象Relatioin：关系，MySQL中的表Mapping：映射 利用ORM框架，使对象与关系表对应，对象的属性与关系表中的字段对应，通过操作类和对象的方式来编辑修改数据库。 事件驱动Web 概念前端后端前后端分离Ajax 技术Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。 这里就要建议用户使用IE6+以上的版本，因为之前的版本的Ajax技术的使用方法和主流浏览器不一样。如果非得使用旧版IE，那就要单独为旧版IE写一套代码了（使用jQuery框架可以屏蔽这种差异）。当然不止是Ajax，一些CSS也需要另外写一套。 CGI，WSGI 与 ASGICGI：CGI脚本简单地讲是个运行在Web服务器上的程序, 由浏览器的输入触发。这个脚本通常象服务器和系统中其他程序如数据库的桥梁。CGI是一种古老的Web技术，一般有C/C++编写，是PHP等语言出现之前就有的产物。当然，也可以用Lua，Python来编写。 WSGI：是一种服务器和客户端交互的接口规范，规定客户与服务器如何通信。 ASGI：由Django团队首创，支持WebSocket，HTTP2等服务。 运维理念GIT敏捷开发CI CD数据库常用数据库介绍数据库分类数据库分为关系型数据库和非关系型数据库。关系型数据库如MySQL，Oracle，SQL Server，SQLite等，是基于关系表的存储结构存储数据。而非关系型数据库如Redis，MongoDB等采用键值对、图等各种方式存储数据。这两类没有优劣之分，只有适用场景之分。 在关系型数据库中，一个关系（表）代表一个对象，每个关系都有多个属性（字段）。关系与关系之间也有着一对一、一对多、多对多的关联，例如老师与课程是一对多的关联，课程与学生是多对多的关联等。 关系型数据库的属性属性也分为超键，主键，候选键，外键以及普通字段。 假设有如下两个表： 学生（学号，姓名，性别，身份证号，教师编号）教师（教师编号，姓名，工资） 超键：在表中能唯一标识记录的属性集称为超键。学生表中含有学号或者身份证号的任意组合都为此表的超键。如（学号）（学号，姓名）（身份证号，性别）等。 候选键：不含有多余属性的超键称为候选键。也就是候选键属于超键，它是最小的超键，就是说如果再去掉候选键中的任何一个属性它就不再是超键了。学生表中的候选键为（学号）（身份证号）。 主键：用户选作元组标识的一个候选键程序主键。主键就是候选键里面的一个，是人为规定的，例如学生表中，我们通常会让“学号”做主键，教师表中让“教师编号”做主键。 外键：如果关系模式R1中的某属性集不是R1的主键，而是另一个关系R2的主键则该属性集是关系模式R1的外键。学生表中的外键就是“教师编号”。外键主要是用来描述两个表的关系。 关系型数据库的属性依赖字段直接含有依赖关系。一般分为三种依赖关系：部分依赖，完全依赖，传递依赖。 部分依赖：设X，Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分依赖于X。例如：通过AB能得出C，通过A也能得出C，通过B也能得出C，那么说C部分依赖于AB。 完全依赖：设X，Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全依赖于X。例如：通过AB能得出C，但是AB单独得不出C，那么说C完全依赖于AB. 传递依赖：设X，Y，Z是关系R中互不相同的属性集合，存在X→Y，Y→Z，，Y !→X，Z !→Y则称Z传递依赖于X。例如：通过A得到B，通过B得到C，但是C得不到B，B得不到A，那么成C传递依赖于A。 关系型数据库的设计范式设计数据库也要讲究原则，我们把这些原则叫做范式。一般情况下，我们设计数据库只需满足五大范式中的前三个范式。五大范式有： 第一范式 1NF：强调的是列的原子性，即列不能够再分成其他几列。每一列只代表一个属性，不能是多个属性的合并。例如，姓名和性别不能存储到一列中，而是应该存储在两列中。 第二范式 2NF：所有的非主属性都完全依赖于关键字。第二范式不存在非主属性对于部分候选关键字的部分依赖，不过允许非主属性之间存在着传递依赖。 下面是第二范式的优化实例： 假定选课关系表为： SelectCourse(学号，姓名，年龄，课程名称,成绩，学分)关键字为组合关键字：(学号，课程名称)因为存在如下决定关系：(学号，课程名称) → (姓名，年龄，成绩，学分) 这个数据库表不满足第二范式，因为存在如下决定关系： (课程名称) → (学分)(学号) → (姓名，年龄) 即存在组合关键字中的字段决定非关键字的情况。 由于不符合2NF，这个选课关系表会存在如下问题： (1) 数据冗余：同一门课程由n个学生选修，”学分”就重复n-1次；同一个学生选修了m门课程，姓名和年龄就重复了m-1次。 (2) 更新异常：若调整了某门课程的学分，数据表中所有行的”学分”值都要更新，否则会出现同一门课程学分不同的情况。 (3) 插入异常：假设要开设一门新的课程，暂时还没有人选修。这样，由于还没有”学号”关键字，课程名称和学分也无法记录入数据库。 (4) 删除异常：假设一批学生已经完成课程的选修，这些选修记录就应该从数据库表中删除。但是，与此同时，课程名称和学分信息也被删除了。很显然，这也会导致插入异常。 因此，把选课关系表SelectCourse改为如下三个表： 学生：Student(学号,姓名，年龄)；课程：Course(课程名称，学分)；选课关系：SelectCourse(学号，课程名称，成绩)。 这样的数据库表是符合第二范式的，消除了数据冗余、更新异常、插入异常和删除异常。 另外，所有单关键字的数据库表都符合第二范式，因为不可能存在组合关键字。 第三范式 3NF：每一个非主属性既不部分依赖于也不传递依赖于关键字，也就是在第二范式的基础上消除传递依赖（A＞B＞C）。 假定学生关系表为： Student(学号，姓名，年龄，所在学院,学院地点，学院电话) 关键字为单一关键字： “学号” 因为存在如下决定关系： (学号) → (姓名，年龄，所在学院，学院地点，学院电话) 这个数据库是符合2NF的，但是不符合3NF，因为存在如下决定关系： (学号) → (所在学院) → (学院地点，学院电话) 即存在非关键字段”学院地点”、”学院电话”对关键字段”学号”的传递依赖。 它也会存在数据冗余、更新异常、插入异常和删除异常的情况，读者可自行分析得知。 把学生关系表分为如下两个表： 学生：(学号，姓名,年龄，所在学院) 学院：(学院，地点，电话) 这样的数据库表是符合第三范式的，消除了数据冗余、更新异常、插入异常和删除异常。 BCNF：在第三范式的基础上进一步消除主属性对于码的部分依赖和传递依赖。BCNF需要符合3NF，并且，主属性不依赖于主属性。 假设仓库管理关系表为 StorehouseManage(仓库ID,存储物品ID,管理员ID,数量)且有一个管理员只在一个仓库工作；一个仓库可以存储多种物品。这个数据库表中存在如下决定关系：(仓库ID,存储物品ID) →(管理员ID,数量) (管理员ID,存储物品ID) → (仓库ID,数量) 所以，(仓库ID,存储物品ID)和(管理员ID,存储物品ID)都是StorehouseManage的候选关键字，表中的唯一非关键字段为数量，它是符合第三范式的。但是，由于存在如下决定关系： (仓库ID) → (管理员ID) (管理员ID) → (仓库ID) 即存在关键字段决定关键字段的情况，所以其不符合BCNF范式。它会出现如下异常情况： (1) 删除异常： 当仓库被清空后，所有”存储物品ID”和”数量”信息被删除的同时，”仓库ID”和”管理员ID”信息也被删除了。 (2) 插入异常： 当仓库没有存储任何物品时，无法给仓库分配管理员。 (3) 更新异常： 如果仓库换了管理员，则表中所有行的管理员ID都要修改。 因此，把仓库管理关系表分解为二个关系表： 仓库管理：StorehouseManage(仓库ID,管理员ID) 仓库：Storehouse(仓库ID,存储物品ID,数量) 这样的数据库表是符合BCNF范式的，消除了删除异常、插入异常和更新异常。 但是也有例外。又如，有这样一个配件管理表： WPE(仓库号，配件号，职工号，QNT) 有以下约束要求： （1）一个仓库有多名职工； （2）一个职工仅在一个仓库工作； （3）每个仓库里一种型号的配件由专人负责，但一个人可以管理几种配件； （4）同一种型号的配件可以分放在几个仓库中。 分析表中的依赖关系，可以得到： （1）职工号 -&gt; 仓库号; （2）（仓库号，配件号）-&gt; 数量 （3）（仓库号，配件号）-&gt; 职工号 （4）（职工号，配件号）-&gt; 数量 可以看到，候选键有：（职工号，配件号）(仓库号，配件号)。所以，职工号，配件号，仓库号均为主属性，数量为非主属性。显然，非主属性是直接依赖于候选键的。所以此表满足第三范式。 而我们观察一下主属性：（仓库号，配件号）-&gt; 职工号；职工号 -&gt; 仓库号。显然仓库号对于候选键（仓库号，配件号）存在传递依赖，所以不符合BCNF. 解决这个问题的办法是分拆为两个表 管理表EP（职工号，配件号，数量）工作表EW（职工号，仓库号）但这样做会导致依赖（仓库号，配件号）-&gt; 职工号丢失。虽然，不满足BCNF，也会导致一些冗余和一致性的问题。但是，将表分解成满足BCNF的表又可能丢失一些依赖。所以，一般情况下不会强制要求关系表要满足BCNF。&gt; 第四范式 4NF：当一个表中的非主属性互相独立时（3NF），这些非主属性不应该有多值。若有多值就违反了第四范式。有这样一个用户联系方式表TELEPHONE(CUSTOMERID,PHONE,CELL)CUSTOMERID为用户ID，PHONE为用户的固定电话，CELL为用户的移动电话。本来，这是一个非常简单的第3范式表。主键为CUSTOMERID，不存在传递依赖。但在某些情况下，这样的表还是不合理的。比如说，用户有两个固定电话，两个移动电话。这时，表的具体表示如下：|CUSTOMERID|PHONE|CELL||———-|—–|—-||1000|88281234|149088888888||1000|88381234|149099999999|由于PHONE和CELL是互相独立的，而有些用户又有两个和多个值。这时此表就违反第四范式。在这种情况下，此表的设计就会带来很多维护上的麻烦。例如，如果用户放弃第一行的固定电话和第二行的移动电话，那么这两行会合并吗？等等解决问题的方法为，设计一个新表NEW_PHONE(CUSTOMERID,NUMBER,TYPE)这样就可以对每个用户处理不同类型的多个电话号码，而不会违反第四范式。显然，第四范式的应用范围比较小，因为只有在某些特殊情况下，要考虑将表规范到第四范式。所以在实际应用中，一般不要求表满足第四范式。&gt; 第五范式 5NF：是最终范式。消除了4NF中的连接依赖。第五范式有以下要求：（1）必须满足第四范式（2）表必须可以分解为较小的表，除非那些表在逻辑上拥有与原始表相同的主键。第五范式是在第四范式的基础上做的进一步规范化。第四范式处理的是相互独立的多值情况，而第五范式则处理相互依赖的多值情况。有一个销售信息表SALES（SALEPERSON，VENDOR，PRODUCT）SALEPERSON代表销售人员，VENDOR代表供和商，PRODUCT则代表产品。在某些情况下，这个表中会产生一些冗余。可以将表分解为PERSON_VENDOR表（SALEPERSON，VENDOR）PERSON_PRODUCT表（SALEPERSON，PRODUCT）VENDOR­_PRODICT表（VENDOR，PRODUCT） 参考 1：超键，主键，候选键，外键参考 2：五大范式参考 3：依赖关系 视图触发器悲观锁与乐观锁]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS 基础]]></title>
    <url>%2F2019%2F04%2F13%2FRosBase-1%2F</url>
    <content type="text"><![CDATA[近期做的东西和ROS有关，因此想做一些关于ROS的笔记。这篇文章主要分为以下几个部分。 ROS简介 ROS的工程架构 ROS的计算图集 ROS工具包 未完结 1. ROS简介ROS（Robot OS）是运行在Ubuntu上的次级系统，它内部由多个节点构成，每个节点即一个进程。这些节点之间各自分工，又相互合作，共同完成一些列任务。一般一个ROS工程由master节点和多个子节点构成，master负责管理各个节点，而子节点则负责各自具体的任务。 2. ROS的工程架构对于一个ROS工程，它一般分为三部分： build：编译产生的中间文件； devel：编译的结果文件； src：源代码目录。 项目架构概览 /catkin_ws /build /devel /src /folder_1 /package_1 /package_2 /folder_2 /package_3 /package_4 /metapackage 一个ROS工程的src部分，是由一个个Package组成的。每个Package一般对应一个应用或是一个节点。另外还有一类特殊的Package，叫做Metapackage，即虚包，它们没有自己的内容，但是由很多依赖，因此常用来做功能集使用。 Package架构概览： /package /msg x.msg /srv x.srv /action x.action /scripts x.py x.sh /launch x.launch /config x.yaml /include x.h /src x.cpp /other_dirs other_files CMakeLists.txt package.xml ROS支持C++和Python开发。在一个Package下，script下一般存放python文件，src、include文件夹下面分别存放了c++的.cpp文件和.h文件。launch文件夹下存放了ROS的启动文件，这些启动文件描述了这个包的启动过程中需要定义的参数，需要依赖的其它的包等内容。config文件夹下存放了一些配置文件，通过yaml语言定义。ROS自带了三种通信方式，其中msg描述了通过topic方式通信过程中的数据格式，srv、action则分别保存了service和action通信的数据格式。 3. ROS的计算图集计算图集，也叫通信架构，是ROS节点之间通信的工具。ROS节点之间的通信方式共有三种。 TopicTopic是最常见的通信方式，topic是一个独立于节点的存在。每个节点既可以发布topic，也可以订阅topic。发布者会始终无条件的发布消息，所以不论有没有其他节点在订阅消息，都会按照一定频率发布topic。并且topic的发布者可以不只是一个节点，偶尔也会有多个节点在同一个topic上发布消息。当然，订阅topic的节点也可以是多个。 一个节点如果想发布topic，必须先创建一个msg，这个msg就像是一个结构体，节点可以在这个msg中存放一些数据，然后发布到topic上。另一个节点如果想订阅这个topic，就必须按照这个msg的结构进行监听。 msg文件结构12float32 xfloat32 y Service当进行一些复杂的，计算量大的任务时，Topic却无法胜任这种情况了，因为Topic是不论有没有订阅者，发布者都会无条件发布消息，这就会导致大量的计算资源被浪费了。而Service这种通信方式正是弥补了这一缺陷。Service会根据服务请求者的请求，按需执行，因此大大节约了计算资源。 Service由服务的提供方提供相应服务，而请求方需要按照srv文件中定义的格式向服务提供方请求服务。 srv文件结构123456// 请求格式uint32 id---// 响应格式float32 xfloat32 y Action对于一些执行时间较长的服务，服务的请求方还需要知道服务的实时进度。这时候Action就派上用场了。Action除了像服务那样按需执行外，在执行的过程中，也会按照一定的频率向请求方发送一些其他的数据，这些数据都是在action文件中定义的。 action文件结构123456789// 请求格式uint32 id---// 结果格式float32 xfloat32 y---// 中间反馈格式string state 数据格式文件中的数据类型12345678boolstringint8, int16, int32, int64uint8, uint16, uint32, uint64float32, float64time, durationvariable-length array[], fixed-length array[C]other msg files 4. ROS工具包Gazebo 物理仿真工具可以对机器人进行物理仿真，可以对机器人设置重量，碰撞模型，转动惯量等设置。 Rviz 机器人可视化工具主要用于机器人调试，数据可视化操作。 MoveIt! 机械臂路径规划工具专门用于机械臂控制使用，里面集成了大量的关于机械臂的工具包。 Rqt ROS代码调试工具提供了一系列代码调试工具： rqt_graph 绘制计算图（通信架构图）rqt_plot 绘制数据变化曲线rqt_console 查看日志的工具rqt_* 其他工具 5. 未完结（停止更新）]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 博客搭建]]></title>
    <url>%2F2019%2F03%2F29%2FGitBlogInit%2F</url>
    <content type="text"><![CDATA[经过几天的研究，我终于搭起了一个Github博客网站。这篇文章将从以下几个步骤分别介绍博客的搭建。 前期准备 环境部署 配置域名（可选） 配置到个人服务器（可选） 附录 1. 前期准备首先，你需要拥有以下内容： Github账号个人域名（可选）个人服务器（可选） Github账号可以到Github官网申请，过程很简单，这里就不赘述了。个人域名可以选择阿里云，腾讯云等域名产品，申请过程也就不说了，这个不是必选，有需要的可以搞一个。 2. 环境部署这一步就正式开始搭建自己的博客了。首先是安装一些软件： GitNodeJS Git的安装过程首先到Git下载页面下载Git，这里建议下载64-bit Git for Windows Setup版本，涉及到一些环境变量的配置，安装版可以自动配置环境变量，省去手动配置的烦恼（32位系统则选择32-bit版）。 NodeJS的安装过程到NodeJS下载页面下载NodeJS，可以选择Windows 安装包 (.msi) x64版，原因同上。 安装博客框架可以选择Hexo，Jekyll等博客框架。这里以Hexo为例(参考文档，博客主题在这个官网中可以查看）。打开终端，执行如下命令安装（这一步需要管理员模式）：1npm install -g hexo 在本地新建一个目录，执行init命令初始化Hexo和Git： 12hexo initgit init 配置Github创建一个Repository，名字必须为your_user_name.github.io。（加粗部分替换为自己的用户名）下面配置SSH Key方便后续上传博客代码。在本地Git Bash中输入如下命令建立SSH Key：1ssh-keygen -t rsa -C "邮箱地址" -f ~/.ssh/github_blog_keys 中间会提示你输入文件，密码，可以不用管，直接回车即可。配置成功后，打开生成的ssh-key，新生成的公钥就是~/.ssh/github_blog_keys.pub。到在自己的账户设置中，找到 SSH and GPG keys ，点击New SSH Key 添加新的Key。将刚刚生成的公钥文件中的内容复制这里即可。 之后我们需要配置自己的Username和Email：12git config --global user.name "your_user_name" git config --global user.email "your_email" 之后将本地仓库再关联到远程仓库，首先复制远程仓库地址，到Git Bash中执行下述命令，这一步要保证当前打开的路径是Hexo的路径：1git remote add origin https://github.com/your_user_name/your_user_name.github.io.git 配置Hexo在Hexo目录下执行下面这句，安装该扩展程序。1npm install hexo-deployer-git --save 打开Hexo下的_config.yml文件，在文件末尾添加：1234deploy: type: git repository: git@github.com:your_user_name/your_user_name.github.io.git branch: master 并修改title，url，theme等配置。 开始编写下面就可以开始编写自己的博客了。执行下面命令新建Hexo页面。1hexo new "HelloWorld" 之后会在项目的/source/_post/下看到HelloWorld.md文件，使用MarkDown语言编辑这个文件即可。编辑完毕保存退出，执行下述命令开始编译项目并上传：1hexo g -d 打开连接https://your_user_name.github.io 就能看到你的博客了。也可以在本地看看效果：1hexo s 打开连接http://localhost:4000 即可看到效果。 3. 配置域名（可选）首先得需要一个域名（还得是备案过的）。这里以腾讯云的域名为例。在云解析服务中，选择你的域名点击右侧的解析，进入域名的配置页面。点击上方的添加记录，主机类型可以选www或者@，记录类型选择CNAME，记录值为your_user_name.github.io. （注意末尾有个点），之后保存即可。在你的项目中的/source/目录下创建CNAME文件，文件内容是你的一级域名，如下所示： your_user_name.cn 保存编译上传项目，过几分钟后即可配置成功。如果要开启HTTPS，则还需要购买SSH证书（有免费的证书），例如可以选择阿里云，腾讯云或CloudFlare的免费HTTPS服务。这里以腾讯云为例，选择为期一年的免费版SSH证书。在云产品中找到SSH 证书管理，点击申请免费证书，选择左侧的免费一年的证书。按照上面的要求输入相关信息，点击下一步，等待几分钟审核通过（也可能好久）。回到https://github.com/your_user_name/your_user_name.github.io 中，进入仓库设置页面，下拉找到GitHub Pages，在Custom domain中输入自己的域名，并开启Enforce HTTPS。 4. 配置到个人服务器（可选，Ubuntu版）当然，首先需要一台个人服务器。配置过程主要分为几个步骤： 安装Git-core安装Nginx配置Https 首先安装Git-core和Nginx。登入服务器执行如下代码1sudo apt-get install git-core nginx openssh-server 安装成功后，开始配置Nginx。在这里我们可以使用SSL给网站加点安全措施。首先从腾讯云上下载SSL证书（笔者用Chrome下载证书时浏览器会崩溃，于是换了一个浏览器才下载下来），压缩包下会有Nginx版对应的证书。复制里面的证书到服务器上，这里可以使用xftp或MobaXterm的sftp上传，放到 /etc/nginx/cert 目录下。在 /etc/nginx 下执行下述代码:1234sudo cp sites-available/default sites-available/default-sslsudo ln -s sites-available/default-ssl sites-enabled/sslsudo rm sites-enabled/defaultsudo vim sites-enabled/ssl 开始使用vim编辑刚刚得到的ssl文件，配置ssl访问，并设置80端口重定向到443端口。12345678910111213141516171819202122232425262728293031server &#123; # SSL configuration listen 443 ssl default_server; listen [::]:443 ssl default_server; root /home/git/tmp/blog; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name www.your_domain.com; ssl on; ssl_certificate /etc/nginx/cert/your_crt_file.crt; ssl_certificate_key /etc/nginx/cert/your_key_file.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; try_files $uri $uri/ =404; &#125;&#125;server &#123; listen 80; listen [::]:80; location / &#123; rewrite ^(.*)$ https://$host$1 permanent; &#125;&#125; 配置完成后，记得在腾讯云的域名解析上添加一条A记录，来指向自己的服务器IP地址。完成后别忘了访问一下自己的网站，看看是否能够访问成功。下面开始部署网站到自己的服务器上了。在自己的服务器上，首先搭建一个Git的服务器。首先将之前的github_blog_keys.pub中的公钥上传到服务器上，保存到 ~/.ssh/authorized_keys 文件中。在自己的服务器中创建git账号。12sudo useradd gitsudo passwd git 输入git账号的密码，之后登陆到git账号中，创建仓库。123456su gitcd ~git --bare init blog.git# 这两步后面有用mkdir tmpmkdir tmp/blog 这里回到本地，先测试一下能否正常访问自己的git。1git clone git@your_server_ip:~/blog.git 成功后利用hexo将博客代码部署到自己的服务器上。首先先配置自己的_config.yml文件。打开_config.yml文件，修改deploy部分的代码：1234567deploy: - type: git repository: git@github.com:your_user_name/your_user_name.github.io.git branch: master - type: git repository: git@your_server_ip:~/blog branch: master 保存后使用hexo提交博客代码。12hexo cleanhexo g -d 这样就可以提交代码到服务器上保存了。但是目前网站依然是无法访问的，需要再编写一个自动部署网站的脚本。进入服务器，进入到目录 /home/git/blog.git/hooks 下，创建提交后执行的脚本。12345#!/bin/bash -lGIT_REPO=/home/git/blog.gitTMP_GIT_CLONE=/home/git/tmp/blogrm -rf $&#123;TMP_GIT_CLONE&#125;git clone $GIT_REPO $TMP_GIT_CLONE 创建完成后，修改一下权限，并重启Nginx。123chmod +x post-receivechmod 777 -R /home/git/tmp/blogservice nginx restart 这次在客户端用hexo重新部署一次代码。1hexo d 到此结束，可以收工了。 附录A Hexo常用命令Hexo初始化1hexo init 编译到静态页面12hexo generate # 简写 hexo g 部署到Github上12hexo deploy # 简写 hexo d 使用本地浏览器查看 ( http://localhost:4000 )12hexo server # 简写 hexo s 创建新的Page1hexo new 配置主题 _config.yml首先给Hexo配置一个主题，之后就可以在Hexo的主题的目录下看到_config.yml文件。以NexT主题为例，目录下的_config.yml文件中有如下选项： Site Information Settings 站点信息设置 SEO Settings SEO设置 Menu Settings 菜单设置，包括显示的栏目，栏目图标等 Scheme Settings 主题风格设置 Sidebar Settings 菜单栏设置，包括友情链接，个人头像，侧边栏位置等 Post Settings 主页文章显示设置 Misc Theme Settings 主题其他设置，字体，代码风格等 Third Party Services Settings 第三方服务，数学插件，评论插件，统计插件，搜索插件等 Tags Settings 标签设置 Animation Settings 动画设置 创建分类与标签使用如下两个命令分别创建分类与标签：1234# 创建分类hexo new page categories# 创建标签hexo new page tags 创建完成后，需要在主题配置中开启相应的选项（例如NexT主题中的menu）。 安装插件图片本地化插件在Hexo目录下执行下面语句：1npm install https://github.com/CodeFalling/hexo-asset-image --save 之后配置根目录下的_config.yml中：1post_asset_folder:true 之后再创建文章的时候，就会同时在同一目录下创建一个与文章同名的文件夹，里面可以存放文章中使用到的图片。在文章中引用文件夹下的图片pic.jpg方法如下：1![image](pic.jpg) 评论插件这里推荐两款评论插件，来必得与LeanCloud。来必得支持多账号登录，但是评论数据无法导出，而LeanCloud是匿名评论，提供的对象存储支持每日30,000次请求，总共10GB存储。 搜索插件这里使用Local Search，直接安装即可实现本地搜索。安装代码如下：1npm install hexo-generator-searchdb --save 回到博客的_config.yml中添加如下设置：12345search: path: search.xml field: post format: html limit: 10000 在主题的_config.yml中找到local_search，并启用该功能：123# Local searchlocal_search: enable: true 动态壁纸线条背景：在主题文件夹下找到layout/_layout.swig文件，在&lt;/body&gt;上方添加代码123&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125; Live2D插件首先安装Live2D插件：1npm install --save hexo-helper-live2d 这里推荐到xiazeyu这里找一个喜欢的模型安装一下，我随便选一个为例：1npm install --save live2d-widget-model-hibiki 回到博客的_config.yml文件中，在最后添加代码，具体可以看EYHN里面的介绍：12345678910111213141516171819# Live2D## https://github.com/EYHN/hexo-helper-live2dlive2d: enable: true # enable: false scriptFrom: local # 默认 pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径) pluginJsPath: lib/ # 脚本文件相对与插件根目录路径 pluginModelPath: assets/ # 模型文件相对与插件根目录路径 # scriptFrom: jsdelivr # jsdelivr CDN # scriptFrom: unpkg # unpkg CDN # scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # 你的自定义 url tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中 debug: false # 调试, 是否在控制台输出日志 model: use: live2d-widget-model-hibiki # npm-module package name # use: wanko # 博客根目录/live2d_models/ 下的目录名 # use: ./wives/wanko # 相对于博客根目录的路径 # use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # 你的自定义 url]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
        <tag>博客</tag>
      </tags>
  </entry>
</search>
